<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hello！Welcom to Tumy-Time！</title>
  
  
  <link href="http://tumytime.github.io/atom.xml" rel="self"/>
  
  <link href="http://tumytime.github.io/"/>
  <updated>2024-03-25T13:05:25.698Z</updated>
  <id>http://tumytime.github.io/</id>
  
  <author>
    <name>tumytime</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图像处理笔记（二）灰度变换和空间滤波基础</title>
    <link href="http://tumytime.github.io/2024/03/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E7%81%B0%E5%BA%A6%E5%8F%98%E6%8D%A2%E5%92%8C%E7%A9%BA%E9%97%B4%E6%BB%A4%E6%B3%A2%E5%9F%BA%E7%A1%80/"/>
    <id>http://tumytime.github.io/2024/03/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E7%81%B0%E5%BA%A6%E5%8F%98%E6%8D%A2%E5%92%8C%E7%A9%BA%E9%97%B4%E6%BB%A4%E6%B3%A2%E5%9F%BA%E7%A1%80/</id>
    <published>2024-03-25T13:04:31.000Z</published>
    <updated>2024-03-25T13:05:25.698Z</updated>
    
    <content type="html"><![CDATA[<h2 id="灰度变换和空间滤波基础"><a href="#灰度变换和空间滤波基础" class="headerlink" title="灰度变换和空间滤波基础"></a>灰度变换和空间滤波基础</h2><h3 id="灰度变换（灰度反转，对数变换，幂律变换）"><a href="#灰度变换（灰度反转，对数变换，幂律变换）" class="headerlink" title="灰度变换（灰度反转，对数变换，幂律变换）"></a>灰度变换（灰度反转，对数变换，幂律变换）</h3><h4 id="灰度变换原理"><a href="#灰度变换原理" class="headerlink" title="灰度变换原理"></a>灰度变换原理</h4><p>变换原理：通过变换函数T将原图像像素灰度值r映射为灰度值s：</p><p>$s&#x3D;T(r)$</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;灰度变换和空间滤波基础&quot;&gt;&lt;a href=&quot;#灰度变换和空间滤波基础&quot; class=&quot;headerlink&quot; title=&quot;灰度变换和空间滤波基础&quot;&gt;&lt;/a&gt;灰度变换和空间滤波基础&lt;/h2&gt;&lt;h3 id=&quot;灰度变换（灰度反转，对数变换，幂律变换）&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    <category term="图像处理" scheme="http://tumytime.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    <category term="OpenCV" scheme="http://tumytime.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>图像处理笔记（一）基础操作</title>
    <link href="http://tumytime.github.io/2024/03/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://tumytime.github.io/2024/03/25/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0-1/</id>
    <published>2024-03-25T03:51:05.000Z</published>
    <updated>2024-03-25T13:05:31.723Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>前面一部分笔记都是学习一个大佬的教程做的，但是大佬用的python，我在笔记里都转换成了c++</p></blockquote><h2 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2kroj52zde.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2kroj52zde.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.pf3qismjr.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.pf3qismjr.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4g49bri91j.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4g49bri91j.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.1set1eq2uf.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.1set1eq2uf.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.58h4ti0gy2.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.58h4ti0gy2.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.1hrz89c5f9.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.1hrz89c5f9.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="图片基本读取操作"><a href="#图片基本读取操作" class="headerlink" title="图片基本读取操作"></a>图片基本读取操作</h2><p>电脑上的彩色图是以 RGB(红 - 绿-蓝，Red-Green-Blue) 颜色模式显示的，但 OpenCV 中彩色图是以 B-G-R 通道顺序存储的，灰度图只有一个通道。</p><p>图像坐标的起始点是在左上角，所以行对应的是 y，列对应的是 x：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.54xivstf47.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.54xivstf47.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="加载图片"><a href="#加载图片" class="headerlink" title="加载图片"></a>加载图片</h3><blockquote><span class='pbg info'>imread()</span><blockquote><p><strong>两个参数:</strong></p><ul><li>参数 1：图片的文件名<br> 如果图片放在当前文件夹下，直接写文件名就行，如”lena.jpg”<br> 否则需要给出绝对路径，如”C:&#x2F;Users&#x2F;lxcqm&#x2F;Desktop&#x2F;图片和视频&#x2F;11111.png”</li><li>参数 2：读入方式，省略即采用默认值<br> cv2.IMREAD_COLOR：彩色图，默认值(1)or(IMREAD_COLOR)<br> cv2.IMREAD_GRAYSCALE：灰度图(0)or(IMREAD_GRAYSCALE)<br> cv2.IMREAD_UNCHANGED：包含透明通道的彩色图(-1)or(IMREAD_UNCHANGED)</li></ul></blockquote></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//加载灰度图</span></span><br><span class="line">Mat  img = imread(<span class="string">&quot;C:/Users/lxcqm/Desktop/images/11111.png&quot;</span>,<span class="number">0</span>);</span><br></pre></td></tr></table></figure><blockquote><p>经验之谈：路径中不能有中文噢，并且没有加载成功的话是不会报错的，print(img)的结果为 None，后面处理才会报错，算是个小坑。</p></blockquote><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h2 id="显示图片"><a href="#显示图片" class="headerlink" title="显示图片"></a>显示图片</h2><p>使用<code>imshow()</code>显示图片，窗口会自适应图片的大小：</p><blockquote><p><code>imshow()</code></p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//加载灰度图</span></span><br><span class="line">Mat  img = imread(<span class="string">&quot;C:/Users/lxcqm/Desktop/images/11111.png&quot;</span>,<span class="number">0</span>);</span><br><span class="line">imshow(<span class="string">&quot;pic&quot;</span>, img);</span><br><span class="line">waitKey(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>参数 1 是窗口的名字，参数 2 是要显示的图片。不同窗口之间用窗口名区分，所以窗口名相同就表示是同一个窗口，显示结果如下：<br><strong>效果:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.32hq7r8seh.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.32hq7r8seh.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><blockquote><p><code>waitKey()</code>是让程序暂停的意思，参数是等待时间（毫秒 ms）。<br>时间一到，会继续执行接下来的程序，传入 0 的话表示一直等待。等待期间也可以获取用户的按键输入：k &#x3D; waitKey(0)</p></blockquote><p>我们也可以先用<code>namedWindow()</code>创建一个窗口，之后再显示图片：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">namedWindow(<span class="string">&quot;pic2&quot;</span>, WINDOW_NORMAL);</span><br><span class="line">imshow(<span class="string">&quot;pic2&quot;</span>, img);</span><br><span class="line">waitKey(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>参数 1 依旧是窗口的名字，参数 2 默认是<code>WINDOW_AUTOSIZE</code>，表示窗口大小自适应图片，也可以设置为<code>WINDOW_NORMAL</code>，表示窗口大小可调整。图片比较大的时候，可以考虑用后者。</p><h3 id="保存图片"><a href="#保存图片" class="headerlink" title="保存图片"></a>保存图片</h3><blockquote><p><code>imwrite()</code></p></blockquote><p>使用<code>imwrite()</code>保存图片，参数 1 是包含后缀名的文件名：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imwrite(<span class="string">&quot;pictest.jpg&quot;</span>, img);</span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.sypoa1fpo.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.sypoa1fpo.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>会保存在目录文件夹里</p><h2 id="摄像头"><a href="#摄像头" class="headerlink" title="摄像头"></a>摄像头</h2><h3 id="打开摄像头"><a href="#打开摄像头" class="headerlink" title="打开摄像头"></a>打开摄像头</h3><p>要使用摄像头，需要使用<code>VideoCapture capture(0);</code>参数 <code>0</code> 指的是摄像头的编号，如果你电脑上有两个摄像头的话，访问第 2 个摄像头就可以传入 <code>1</code>，依此类推。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    VideoCapture <span class="title function_">capture</span><span class="params">(<span class="number">0</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!capture.isOpened()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        Mat frame;</span><br><span class="line">        <span class="comment">//&gt;&gt; 是输入流提取运算符</span></span><br><span class="line">        <span class="comment">// 它通常用于从输入流中提取数据并将其存储在相应的变量中</span></span><br><span class="line">        <span class="comment">// 表示从 capture 输入流中读取数据，并将其存储在 frame 变量中</span></span><br><span class="line">        capture &gt;&gt; frame;</span><br><span class="line"></span><br><span class="line">        Mat gray;</span><br><span class="line">        cvtColor(frame, gray, COLOR_BGR2GRAY);</span><br><span class="line"></span><br><span class="line">        imshow(<span class="string">&quot;frame&quot;</span>, gray);</span><br><span class="line">        <span class="keyword">if</span> (waitKey(<span class="number">1</span>) == <span class="string">&#x27;q&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>cv2.cvtColor()</code>用来转换颜色，这里将彩色图转成灰度图。<br>通过cap.get(propId)可以获取摄像头的一些属性，比如捕获的分辨率，亮度和对比度等。propId 是从 0~18 的数字，代表不同的属性，完整的属性列表可以参考：VideoCaptureProperties(<a href="https://docs.opencv.org/4.0.0/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d">https://docs.opencv.org/4.0.0/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d</a>)<br>也可以使用cap.set(propId,value)来修改属性值。比如说，我们在 while 之前添加下面的代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> width = capture.get(CAP_PROP_FRAME_WIDTH);</span><br><span class="line"><span class="type">double</span> height = capture.get(CAP_PROP_FRAME_HEIGHT);</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Original width: &quot;</span> &lt;&lt; width &lt;&lt; <span class="string">&quot;, height: &quot;</span> &lt;&lt; height &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">capture.<span class="built_in">set</span>(CAP_PROP_FRAME_WIDTH, width * <span class="number">2</span>);</span><br><span class="line">capture.<span class="built_in">set</span>(CAP_PROP_FRAME_HEIGHT, height * <span class="number">2</span>);</span><br></pre></td></tr></table></figure><details open><summary pointer> std::cout << Original width: << width << </summary>              <div class='content'>              <p>这行代码使用了C++中的流输出操作符”&lt;&lt;”，它用于将数据插入到输出流中。在这个语句中：</p><ul><li><code>std::cout</code>: 是C++标准库中的标准输出流对象，用于将数据输出到控制台。</li><li><code>&quot;Original width: &quot;</code>、<code>width</code>、<code>&quot;, height: &quot;</code>、<code>height</code>、<code>std::endl</code> 都是要输出的具体内容。</li><li><code>&lt;&lt;</code>：是流输出操作符，用于将后面的内容插入到输出流中。</li></ul><p>所以，<code>std::cout &lt;&lt; &quot;Original width: &quot; &lt;&lt; width &lt;&lt; &quot;, height: &quot; &lt;&lt; height &lt;&lt; std::endl;</code> 这行代码的作用是将描述原始宽度和高度的字符串以及相应的变量值输出到控制台，并在最后换行。</p>              </div>            </details><p><strong>输出</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.86texdkg7l.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.86texdkg7l.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><blockquote><p>经验之谈：某些摄像头设定分辨率等参数时会无效，因为它有固定的分辨率大小支持，一般可在摄像头的资料页中找到。</p></blockquote><h3 id="播放本地视频"><a href="#播放本地视频" class="headerlink" title="播放本地视频"></a>播放本地视频</h3><p>跟打开摄像头一样，如果把摄像头的编号换成视频的路径就可以播放本地视频了。回想一下<code>waitKey()</code>，它的参数表示暂停时间，所以这个值越大，视频播放速度越慢，反之，播放速度越快，通常设置为 <code>25</code> 或 <code>30</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    VideoCapture <span class="title function_">capture</span><span class="params">(<span class="string">&quot;C:/Users/lxcqm/Desktop/WeChat_20240325194731.mp4&quot;</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!capture.isOpened()) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;Error opening video file&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">     Mat frame, gray;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!capture.read(frame)) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        cvtColor(frame, gray, COLOR_BGR2GRAY);</span><br><span class="line"></span><br><span class="line">        imshow(<span class="string">&quot;frame&quot;</span>, gray);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (waitKey(<span class="number">30</span>) == <span class="string">&#x27;q&#x27;</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    capture.release();</span><br><span class="line">    destroyAllWindows();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="录制视频"><a href="#录制视频" class="headerlink" title="录制视频"></a>录制视频</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line">using namespace cv;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    VideoCapture <span class="title function_">capture</span><span class="params">(<span class="number">0</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义编码方式并创建 VideoWriter 对象</span></span><br><span class="line">    VideoWriter <span class="title function_">outfile</span><span class="params">(<span class="string">&quot;output.avi&quot;</span>, VideoWriter::fourcc(<span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;J&#x27;</span>, <span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;G&#x27;</span>), <span class="number">25.</span>, Size(<span class="number">640</span>, <span class="number">480</span>))</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (capture.isOpened()) &#123;</span><br><span class="line">        Mat frame;</span><br><span class="line">        capture.read(frame);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!frame.empty()) &#123;</span><br><span class="line">            outfile.write(frame); <span class="comment">// 写入文件</span></span><br><span class="line">            imshow(<span class="string">&quot;frame&quot;</span>, frame);</span><br><span class="line">            <span class="keyword">if</span> (waitKey(<span class="number">1</span>) == <span class="string">&#x27;q&#x27;</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h2><h3 id="Mat创建图像（矩阵）"><a href="#Mat创建图像（矩阵）" class="headerlink" title="Mat创建图像（矩阵）"></a>Mat创建图像（矩阵）</h3><h4 id="创建图像（矩阵）：Mat"><a href="#创建图像（矩阵）：Mat" class="headerlink" title="创建图像（矩阵）：Mat"></a>创建图像（矩阵）：Mat</h4><p>使用Mat创建图像（矩阵）的常用形式有：</p><ol><li><p>创建一个空图像，大小为0</p> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mat image1;</span><br></pre></td></tr></table></figure></li><li><p>指定矩阵大小，指定数据类型：</p> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mat <span class="title function_">image1</span><span class="params">(<span class="number">100</span>,<span class="number">100</span>,CV_8U)</span>;</span><br></pre></td></tr></table></figure><p> 参数:矩阵行数，矩阵列数，数据类型</p><p> 其中数据类型有很多种，常用的应该有：</p><p> CV_8U：8位无符号型（0~255），即灰度图像；</p><p> CV_8UC3：三通道8位无符号型，这里三通道指B（蓝）G（绿）R（红），与matlab中的RGB正好相反。</p><p> 这里创建矩阵时未指定矩阵的值，发现默认值的大小为205.</p></li><li><p>指定矩阵大小，指定数据类型，设置初始值：</p> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mat <span class="title function_">image1</span><span class="params">(<span class="number">100</span>,<span class="number">100</span>,CV_8U, <span class="number">100</span>)</span>;</span><br></pre></td></tr></table></figure><p> 这里包含四个参数：矩阵行数，矩阵列数，数据类型，初始值；<br> 对于灰度图像：可以直接给出初始值，也可以使用Scalar（）；</p> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> Mat <span class="title function_">image1</span><span class="params">(<span class="number">100</span>,<span class="number">100</span>,CV_8U, <span class="number">100</span>)</span>;</span><br><span class="line">Mat <span class="title function_">image1</span><span class="params">(<span class="number">100</span>,<span class="number">100</span>,CV_8U, Scalar(<span class="number">100</span>))</span>;<span class="comment">//Scalar:标量</span></span><br></pre></td></tr></table></figure><p> 对于三通道图像：使用Scalar（）；</p> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mat <span class="title function_">image1</span><span class="params">(<span class="number">100</span>,<span class="number">100</span>,CV_8UC3, Scalar(<span class="number">100</span>,<span class="number">100</span>,<span class="number">100</span>))</span>;</span><br></pre></td></tr></table></figure></li></ol><h3 id="获取图像信息"><a href="#获取图像信息" class="headerlink" title="获取图像信息"></a>获取图像信息</h3><p>获取图像的宽度（列数），高度（行数），尺寸和通道数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">Mat image1 = imread(<span class="string">&quot;lena.png&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line"><span class="keyword">if</span> (image1.empty())</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;读取错误&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);  <span class="comment">//显示图像；</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;图像的行数为： &quot;</span> &lt;&lt; image1.rows &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//获取图像的高度，行数；</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;图像的列数为： &quot;</span> &lt;&lt; image1.cols &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//获取图像的宽度，列数；</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;图像的通道数为： &quot;</span> &lt;&lt; image1.channels() &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//获取图像的通道数，彩色图=3，灰度图=1；</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;图像的尺寸为： &quot;</span> &lt;&lt; image1.size &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">//获取图像的尺寸，行*列；</span></span><br><span class="line"></span><br><span class="line">waitKey(<span class="number">0</span>);  <span class="comment">//暂停，保持图像显示，等待按键结束</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>输出</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.64dm9cq5y1.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.64dm9cq5y1.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="感兴趣区域"><a href="#感兴趣区域" class="headerlink" title="感兴趣区域"></a>感兴趣区域</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">Mat image1 = imread(<span class="string">&quot;fire.jpg&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line"><span class="keyword">if</span> (image1.empty())</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;读取错误&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);  <span class="comment">//显示图像；</span></span><br><span class="line"></span><br><span class="line">Mat <span class="title function_">imageROI</span><span class="params">(image1, Rect(<span class="number">0</span>, <span class="number">0</span>, <span class="number">10</span>, <span class="number">10</span>))</span>;  <span class="comment">//定义感兴趣区域</span></span><br><span class="line"></span><br><span class="line">waitKey(<span class="number">0</span>);  <span class="comment">//暂停，保持图像显示，等待按键结束</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中Rect（）有四个参数，Rect（a,b,c,d）:</p><ul><li>a：感兴趣区域列(cols)的起点；</li><li>b：感兴趣区域行(rows)的起点；</li><li>c：感兴趣区域的列数(cols)；</li><li>d：感兴趣区域的行数(rows)；</li></ul><h3 id="通过鼠标点击操作获取图像的像素坐标和像素值"><a href="#通过鼠标点击操作获取图像的像素坐标和像素值" class="headerlink" title="通过鼠标点击操作获取图像的像素坐标和像素值"></a>通过鼠标点击操作获取图像的像素坐标和像素值</h3><h4 id="创建鼠标操作函数的头文件"><a href="#创建鼠标操作函数的头文件" class="headerlink" title="创建鼠标操作函数的头文件"></a>创建鼠标操作函数的头文件</h4><details open><summary pointer> onMouse.h </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">onMouse</span><span class="params">(<span class="type">int</span> event, <span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> flags, <span class="type">void</span>* param)</span>;  <span class="comment">//evnet:鼠标事件类型 x,y:鼠标坐标 flags：鼠标哪个键</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">onMouse</span><span class="params">(<span class="type">int</span> event, <span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> flags, <span class="type">void</span>* param)</span>  <span class="comment">//evnet:鼠标事件类型 x,y:鼠标坐标 flags：鼠标哪个键</span></span><br><span class="line">&#123;</span><br><span class="line">Mat* im = reinterpret_cast&lt;Mat*&gt;(param);</span><br><span class="line"><span class="keyword">switch</span> (event) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> EVENT_LBUTTONDOWN:</span><br><span class="line"><span class="comment">//显示图像像素值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (static_cast&lt;<span class="type">int</span>&gt;(im-&gt;channels()) == <span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//若图像为单通道图像，则显示鼠标点击的坐标以及灰度值</span></span><br><span class="line"><span class="keyword">switch</span> (im-&gt;type())</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;uchar&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;<span class="type">char</span>&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;ushort&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;<span class="type">short</span>&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">4</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;<span class="type">int</span>&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">5</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;<span class="type">float</span>&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">6</span>:</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot; ) value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;<span class="type">double</span>&gt;(Point(x, y))) &lt;&lt; <span class="built_in">endl</span>; <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//若图像为彩色图像，则显示鼠标点击坐标以及对应的B, G, R值</span></span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;at (&quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; <span class="string">&quot;)&quot;</span></span><br><span class="line">&lt;&lt; <span class="string">&quot;  B value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;Vec3b&gt;(Point(x, y))[<span class="number">0</span>])</span><br><span class="line">&lt;&lt; <span class="string">&quot;  G value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;Vec3b&gt;(Point(x, y))[<span class="number">1</span>])</span><br><span class="line">&lt;&lt; <span class="string">&quot;  R value is: &quot;</span> &lt;&lt; static_cast&lt;<span class="type">int</span>&gt;(im-&gt;at&lt;Vec3b&gt;(Point(x, y))[<span class="number">2</span>])</span><br><span class="line">&lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//setMouseCallback(&quot;image1&quot;, onMouse, reinterpret_cast&lt;void*&gt;(&amp;image1)); //关联图像显示窗口和onMouse函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//Mat每个格子内的数据格式---------- - Mat定义</span></span><br><span class="line"><span class="comment">//Mat_&lt;uchar&gt;-------- - CV_8U（0-255）</span></span><br><span class="line"><span class="comment">//Mat&lt;char&gt;---------- - CV_8S（-128-127）</span></span><br><span class="line"><span class="comment">//Nat_&lt;short&gt;-------- - CV_16S（-32768-32767）</span></span><br><span class="line"><span class="comment">//Mat_&lt;ushort&gt;--------CV_16U（0-65535）</span></span><br><span class="line"><span class="comment">//Mat_&lt;int&gt;---------- - CV_32S（-2147483648-2147483647）</span></span><br><span class="line"><span class="comment">//Mat_&lt;float&gt;----------CV_32F（-FLT_MAX…FLT_MAX，INF，NAN）</span></span><br><span class="line"><span class="comment">//Mat_&lt;double&gt;--------CV_64F（-DBL_MAX…DBL_MAX，INF，NAN）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//Mat数据类型和通道对应的type()</span></span><br><span class="line"><span class="comment">//              C1          C2          C3          C4</span></span><br><span class="line"><span class="comment">//CV_8U         0           8           16          24</span></span><br><span class="line"><span class="comment">//CV_8S         1           9           17          25</span></span><br><span class="line"><span class="comment">//CV_16U        2          10           18          26</span></span><br><span class="line"><span class="comment">//CV_16S        3          11           19          27</span></span><br><span class="line"><span class="comment">//CV_32S        4          12           20          28</span></span><br><span class="line"><span class="comment">//CV_32F        5          13           21          29</span></span><br><span class="line"><span class="comment">//CV_64F        6          14           22          30</span></span><br></pre></td></tr></table></figure>              </div>            </details><h4 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h4><details open><summary pointer>  </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;onMouse.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">Mat image1 = imread(<span class="string">&quot;fire.jpg&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line"><span class="keyword">if</span> (image1.empty())</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;读取错误&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);  <span class="comment">//显示图像；</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setMouseCallback(<span class="string">&quot;image1&quot;</span>, onMouse, reinterpret_cast&lt;<span class="type">void</span>*&gt;(&amp;image1)); <span class="comment">//关联图像显示窗口和onMouse函数</span></span><br><span class="line">waitKey(<span class="number">0</span>);  <span class="comment">//暂停，保持图像显示，等待按键结束</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>              </div>            </details><p><strong>效果</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.6f0g2iecfm.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.6f0g2iecfm.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="访问图像像素"><a href="#访问图像像素" class="headerlink" title="访问图像像素"></a>访问图像像素</h3><h4 id="访问（j-i）处像素"><a href="#访问（j-i）处像素" class="headerlink" title="访问（j,i）处像素"></a>访问（j,i）处像素</h4><p>以8位（0~255）灰度图像和BGR彩色图像为例，用at可以访问图像像素：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//灰度图像：</span></span><br><span class="line">image.at&lt;uchar&gt;(j, i) <span class="comment">//j为行数，i为列数</span></span><br><span class="line"><span class="comment">//BGR彩色图像</span></span><br><span class="line">image.at&lt;Vec3b&gt;(j, i)[<span class="number">0</span>] <span class="comment">//B分量</span></span><br><span class="line">image.at&lt;Vec3b&gt;(j, i)[<span class="number">1</span>] <span class="comment">//G分量</span></span><br><span class="line">image.at&lt;Vec3b&gt;(j, i)[<span class="number">2</span>] <span class="comment">//R分量</span></span><br></pre></td></tr></table></figure><p><strong>例:</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">Mat image1 = imread(<span class="string">&quot;fire.jpg&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);  <span class="comment">//显示图像；</span></span><br><span class="line"><span class="type">int</span> i = <span class="number">50</span>, j = <span class="number">50</span>;</span><br><span class="line"><span class="type">int</span> b = image1.at&lt;Vec3b&gt;(j, i)[<span class="number">0</span>];</span><br><span class="line"><span class="type">int</span> g = image1.at&lt;Vec3b&gt;(j, i)[<span class="number">1</span>];</span><br><span class="line"><span class="type">int</span> r = image1.at&lt;Vec3b&gt;(j, i)[<span class="number">2</span>];</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;图像该点的像素(BGR):&quot;</span>&lt;&lt;b&lt;&lt;<span class="string">&quot;,&quot;</span> &lt;&lt; g &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; r &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">waitKey(<span class="number">0</span>);  </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>输出:</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7p22d7s7r.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7p22d7s7r.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="在图像中加入白色椒盐噪声"><a href="#在图像中加入白色椒盐噪声" class="headerlink" title="在图像中加入白色椒盐噪声"></a>在图像中加入白色椒盐噪声</h4><h5 id="创建Salt头文件"><a href="#创建Salt头文件" class="headerlink" title="创建Salt头文件"></a>创建Salt头文件</h5><details open><summary pointer> Salt.h </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;random&gt;</span>  <span class="comment">//随机数头文件</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Salt</span><span class="params">(Mat image, <span class="type">int</span> n)</span>; <span class="comment">//n：加入噪声点数</span></span><br></pre></td></tr></table></figure>              </div>            </details><h5 id="创建Salt源文件"><a href="#创建Salt源文件" class="headerlink" title="创建Salt源文件"></a>创建Salt源文件</h5><details open><summary pointer> Salt.cpp </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Salt.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Salt</span><span class="params">(Mat image, <span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//随机数生成器</span></span><br><span class="line">default_random_engine generater;</span><br><span class="line">uniform_int_distribution&lt;<span class="type">int</span>&gt;randomRow(<span class="number">0</span>, image.rows - <span class="number">1</span>);</span><br><span class="line">uniform_int_distribution&lt;<span class="type">int</span>&gt;randomCol(<span class="number">0</span>, image.cols - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> i, j;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; n; k++)</span><br><span class="line">&#123;</span><br><span class="line">i = randomCol(generater);</span><br><span class="line">j = randomRow(generater);</span><br><span class="line"><span class="keyword">if</span> (image.channels() == <span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">image.at&lt;uchar&gt;(j, i) = <span class="number">255</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (image.channels() == <span class="number">3</span>)</span><br><span class="line">&#123;</span><br><span class="line">image.at&lt;Vec3b&gt;(j, i)[<span class="number">0</span>] = <span class="number">255</span>;</span><br><span class="line">image.at&lt;Vec3b&gt;(j, i)[<span class="number">1</span>] = <span class="number">255</span>;</span><br><span class="line">image.at&lt;Vec3b&gt;(j, i)[<span class="number">2</span>] = <span class="number">255</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>              </div>            </details><h5 id="main"><a href="#main" class="headerlink" title="main"></a>main</h5><details open><summary pointer> main.cpp </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Salt.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123; </span><br><span class="line"></span><br><span class="line">Mat image1 = imread(<span class="string">&quot;lena.png&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line"><span class="keyword">if</span> (image1.empty())</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;读取错误&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);  <span class="comment">//显示原图像；</span></span><br><span class="line"></span><br><span class="line">Salt(image1, <span class="number">5000</span>); <span class="comment">//加入5000个噪声点</span></span><br><span class="line">imshow(<span class="string">&quot;image2&quot;</span>, image1);  <span class="comment">//显示噪声图像；</span></span><br><span class="line"></span><br><span class="line">waitKey(<span class="number">0</span>);  <span class="comment">//暂停，保持图像显示，等待按键结束</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>              </div>            </details><p><strong>效果</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.231muzt7o0.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.231muzt7o0.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="遍历图像像素"><a href="#遍历图像像素" class="headerlink" title="遍历图像像素"></a>遍历图像像素</h3><h4 id="指针扫描"><a href="#指针扫描" class="headerlink" title="指针扫描"></a>指针扫描</h4><p>以下面模板对图像进行扫描运算为例：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2h82lv6z7m.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2h82lv6z7m.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123; </span><br><span class="line">Mat image1, output_image;   <span class="comment">//定义输入图像和输出图像</span></span><br><span class="line">image1 = imread(<span class="string">&quot;lena.png&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line"><span class="keyword">if</span> (image1.empty())</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;读取错误&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">output_image = Mat(image1.size(), image1.type());  <span class="comment">//定义输出图像大小</span></span><br><span class="line">output_image = image1.clone();   <span class="comment">//克隆原图像素值</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> rows = image1.rows;    <span class="comment">//原图行数</span></span><br><span class="line"><span class="type">int</span> stepx = image1.channels();   <span class="comment">//原图通道数</span></span><br><span class="line"><span class="type">int</span> cols = (image1.cols) * image1.channels();  <span class="comment">//矩阵总列数，在BGR彩色图像中，每个像素的BGR通道按顺序排列，因此总列数=像素宽度*通道数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> row =<span class="number">1</span> ; row &lt; (rows - <span class="number">1</span>); row++)   <span class="comment">//对行遍历</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">const</span> uchar* previous = image1.ptr&lt;uchar&gt;(row - <span class="number">1</span>);  <span class="comment">//原图上一行指针</span></span><br><span class="line"><span class="type">const</span> uchar* current = image1.ptr&lt;uchar&gt;(row);       <span class="comment">//原图当前行指针</span></span><br><span class="line"><span class="type">const</span> uchar* next = image1.ptr&lt;uchar&gt;(row + <span class="number">1</span>);      <span class="comment">//原图下一行指针</span></span><br><span class="line">uchar* output = output_image.ptr&lt;uchar&gt;(row);        <span class="comment">//输出图像当前行指针</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> col = stepx; col &lt; (cols- stepx); col++)  <span class="comment">//对列遍历</span></span><br><span class="line">&#123;</span><br><span class="line">            <span class="comment">//卷积计算</span></span><br><span class="line">output[col] = saturate_cast&lt;uchar&gt;(<span class="number">5</span>*current[col] - (previous[col]+ current[col- stepx]+ current[col + stepx]+ next[col]));</span><br><span class="line"><span class="comment">//saturate_cast&lt;uchar&gt;(a)，当a在0—255时输出a，当a小于0输出0，当a大于255输出255，保证a的值在0~255之间</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);</span><br><span class="line">imshow(<span class="string">&quot;output_image&quot;</span>, output_image);</span><br><span class="line"></span><br><span class="line">waitKey(<span class="number">0</span>);  <span class="comment">//暂停，保持图像显示，等待按键结束</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>输出</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2a4uqfua0g.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2a4uqfua0g.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p><strong>把卷积核中间改成4：</strong><br><strong>输出</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8hg8qlrb43.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8hg8qlrb43.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="opencv自带的卷积运算：filter2D"><a href="#opencv自带的卷积运算：filter2D" class="headerlink" title="opencv自带的卷积运算：filter2D"></a>opencv自带的卷积运算：filter2D</h4><p>上面的方法可以简化为:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace cv;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123; </span><br><span class="line">Mat image1, output_image;   <span class="comment">//定义输入图像和输出图像</span></span><br><span class="line">image1 = imread(<span class="string">&quot;lena.png&quot;</span>);  <span class="comment">//读取图像；</span></span><br><span class="line"><span class="keyword">if</span> (image1.empty())</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;读取错误&quot;</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Mat kernel = (Mat_&lt;<span class="type">char</span>&gt;(<span class="number">3</span>,<span class="number">3</span>) &lt;&lt; <span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">5</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>);  <span class="comment">//创建滤波器</span></span><br><span class="line">filter2D(image1, output_image, image1.depth(), kernel);  <span class="comment">//卷积</span></span><br><span class="line"></span><br><span class="line">imshow(<span class="string">&quot;image1&quot;</span>, image1);</span><br><span class="line">imshow(<span class="string">&quot;output_image&quot;</span>, output_image);</span><br><span class="line"></span><br><span class="line">waitKey(<span class="number">0</span>);  <span class="comment">//暂停，保持图像显示，等待按键结束</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在filter2D函数中，image1.depth()是用来获取图像image1的深度（depth）信息的函数调用。</p><p>图像的深度表示图像中每个像素值的数据类型。在OpenCV中，常见的图像深度包括：</p><ul><li>CV_8U：8位无符号整数（即Unsigned char），对应于灰度图像的深度</li><li>CV_16U：16位无符号整数</li><li>CV_16S：16位有符号整数</li><li>CV_32S：32位有符号整数</li><li>CV_32F：32位浮点数</li><li>CV_64F：64位浮点数</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;前面一部分笔记都是学习一个大佬的教程做的，但是大佬用的python，我在笔记里都转换成了c++&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;基础配置&quot;&gt;&lt;a href=&quot;#基础配置&quot; class=&quot;headerlink&quot; title=&quot;基础</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    <category term="图像处理" scheme="http://tumytime.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    <category term="OpenCV" scheme="http://tumytime.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>c语言计算机二级笔记</title>
    <link href="http://tumytime.github.io/2024/03/23/c%E8%AF%AD%E8%A8%80%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BA%8C%E7%BA%A7%E7%AC%94%E8%AE%B0/"/>
    <id>http://tumytime.github.io/2024/03/23/c%E8%AF%AD%E8%A8%80%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BA%8C%E7%BA%A7%E7%AC%94%E8%AE%B0/</id>
    <published>2024-03-23T08:39:11.000Z</published>
    <updated>2024-03-25T03:50:05.109Z</updated>
    
    <content type="html"><![CDATA[<h2 id="计算机系统"><a href="#计算机系统" class="headerlink" title="计算机系统"></a>计算机系统</h2><h3 id="E-R实体联系"><a href="#E-R实体联系" class="headerlink" title="E-R实体联系"></a>E-R实体联系</h3><ol><li><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2krogi3z4f.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2krogi3z4f.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div> 矩形表示实体，菱形表示实体之间的联系</li><li>在关系数据库中，用于表示实体间联系的是<strong>二维表</strong></li><li>将E-R图转换为关系模式时，实体和联系都可以表示为<strong>关系</strong>(关系就是二维表)</li><li><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.969i7jl0dn.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.969i7jl0dn.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li><li></li></ol><p>已经考完了。。。。。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;计算机系统&quot;&gt;&lt;a href=&quot;#计算机系统&quot; class=&quot;headerlink&quot; title=&quot;计算机系统&quot;&gt;&lt;/a&gt;计算机系统&lt;/h2&gt;&lt;h3 id=&quot;E-R实体联系&quot;&gt;&lt;a href=&quot;#E-R实体联系&quot; class=&quot;headerlink&quot; title=</summary>
      
    
    
    
    <category term="c语言" scheme="http://tumytime.github.io/categories/c%E8%AF%AD%E8%A8%80/"/>
    
    
    <category term="c语言" scheme="http://tumytime.github.io/tags/c%E8%AF%AD%E8%A8%80/"/>
    
    <category term="计算机二级" scheme="http://tumytime.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BA%8C%E7%BA%A7/"/>
    
  </entry>
  
  <entry>
    <title>收藏夹</title>
    <link href="http://tumytime.github.io/2024/03/22/%E6%94%B6%E8%97%8F%E5%A4%B9/"/>
    <id>http://tumytime.github.io/2024/03/22/%E6%94%B6%E8%97%8F%E5%A4%B9/</id>
    <published>2024-03-22T11:54:52.000Z</published>
    <updated>2024-03-25T05:21:58.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h2><div class="tagLink"><a class="link-card" title="从头开始实现一个神经网络" href="https://mp.weixin.qq.com/s/lk12kP2fbuSBSV5lSFKTlA"><span class="link-card-backdrop" style="background-image: url(https://picx.zhimg.com/80/v2-0b63b54fc59d235ad97530a98bc0e014_1440w.webp?source=2c26e567)"></span><div class="left"><img src="https://picx.zhimg.com/80/v2-0b63b54fc59d235ad97530a98bc0e014_1440w.webp?source=2c26e567" class="lazyload placeholder" data-srcset="https://picx.zhimg.com/80/v2-0b63b54fc59d235ad97530a98bc0e014_1440w.webp?source=2c26e567" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">从头开始实现一个神经网络</p><p class="url">https://mp.weixin.qq.com/s/lk12kP2fbuSBSV5lSFKTlA</p></div></a></div><div class="tagLink"><a class="link-card" title="数据处理之归一化、标准化、正则化" href="https://job.yanxishe.com/blogDetail/27604"><span class="link-card-backdrop" style="background-image: url(https://static.leiphone.com/uploads/new/sns/blogSpe/article/202110/616c488c9c69f.png)"></span><div class="left"><img src="https://static.leiphone.com/uploads/new/sns/blogSpe/article/202110/616c488c9c69f.png" class="lazyload placeholder" data-srcset="https://static.leiphone.com/uploads/new/sns/blogSpe/article/202110/616c488c9c69f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">数据处理之归一化、标准化、正则化</p><p class="url">https://job.yanxishe.com/blogDetail/27604</p></div></a></div><iframe src="//player.bilibili.com/player.html?aid=770444004&bvid=BV18r4y1M71J&cid=760424160&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><iframe src="//player.bilibili.com/player.html?aid=541842600&bvid=BV1yi4y1g7ro&cid=227677652&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h2 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h2><details ><summary pointer> 存一下包版本 </summary>              <div class='content'>              <p>(Paddle_Py3.12) C:\Users\lxcqm&gt;pip list<br>Package                 Version</p><hr><p>absl-py                 2.1.0<br>anyio                   4.3.0<br>archspec                0.2.3<br>astor                   0.8.1<br>astunparse              1.6.3<br>boltons                 23.1.1<br>Brotli                  1.0.9<br>certifi                 2024.2.2<br>cffi                    1.16.0<br>charset-normalizer      3.3.2<br>cloudpickle             3.0.0<br>cmake                   3.28.3<br>colorama                0.4.6<br>conda                   24.1.2<br>conda-libmamba-solver   24.1.0<br>conda-package-handling  2.2.0<br>conda_package_streaming 0.9.0<br>contourpy               1.2.0<br>cycler                  0.11.0<br>Cython                  3.0.9<br>decorator               5.1.1<br>distro                  1.9.0<br>filelock                3.13.1<br>flatbuffers             24.3.7<br>fonttools               4.25.0<br>gast                    0.5.4<br>google-pasta            0.2.0<br>grpcio                  1.62.1<br>gym                     0.26.2<br>gym-notices             0.0.8<br>h11                     0.14.0<br>h5py                    3.10.0<br>httpcore                1.0.4<br>httpx                   0.27.0<br>idna                    3.6<br>Jinja2                  3.1.3<br>joblib                  1.3.2<br>jsonpatch               1.33<br>jsonpointer             2.4<br>keras                   3.1.1<br>kiwisolver              1.4.4<br>libclang                18.1.1<br>libmambapy              1.5.7<br>mamba                   1.5.7<br>Markdown                3.6<br>markdown-it-py          3.0.0<br>MarkupSafe              2.1.5<br>matplotlib              3.8.0<br>mdurl                   0.1.2<br>menuinst                2.0.2<br>meson                   1.3.2<br>mkl-fft                 1.3.8<br>mkl-random              1.2.4<br>mkl-service             2.4.0<br>ml-dtypes               0.3.2<br>mpmath                  1.3.0<br>munkres                 1.1.4<br>namex                   0.0.7<br>nes_py                  8.2.1<br>networkx                3.2.1<br>numpy                   1.26.4<br>opencv-python           4.9.0.80<br>opt-einsum              3.3.0<br>optree                  0.10.0<br>packaging               23.1<br>paddlepaddle-gpu        2.6.0.post120<br>pandas                  2.2.1<br>pillow                  10.2.0<br>pip                     24.0<br>platformdirs            4.2.0<br>pluggy                  1.4.0<br>ply                     3.11<br>protobuf                4.25.2<br>pycocotools             2.0<br>pycosat                 0.6.6<br>pycparser               2.21<br>pyglet                  1.5.21<br>Pygments                2.17.2<br>pyparsing               3.0.9<br>PyQt5                   5.15.10<br>PyQt5-sip               12.13.0<br>PySocks                 1.7.1<br>python-dateutil         2.8.2<br>pytz                    2024.1<br>PyYAML                  6.0.1<br>requests                2.31.0<br>rich                    13.7.1<br>ruamel.yaml             0.18.6<br>ruamel.yaml.clib        0.2.8<br>scipy                   1.12.0<br>setuptools              69.1.1<br>sip                     6.7.12<br>six                     1.16.0<br>sniffio                 1.3.1<br>sympy                   1.12<br>tensorboard             2.16.2<br>tensorboard-data-server 0.7.2<br>tensorflow              2.16.1<br>tensorflow-intel        2.16.1<br>termcolor               2.4.0<br>threadpoolctl           3.3.0<br>torch                   2.2.1<br>torchaudio              2.2.1<br>torchvision             0.17.1<br>tornado                 6.3.3<br>tqdm                    4.66.2<br>truststore              0.8.0<br>typing_extensions       4.10.0<br>tzdata                  2024.1<br>urllib3                 2.2.1<br>Werkzeug                3.0.1<br>wheel                   0.43.0<br>win-inet-pton           1.1.0<br>wrapt                   1.16.0<br>zstandard               0.22.0</p>              </div>            </details>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;AI&quot;&gt;&lt;a href=&quot;#AI&quot; class=&quot;headerlink&quot; title=&quot;AI&quot;&gt;&lt;/a&gt;AI&lt;/h2&gt;&lt;div class=&quot;tagLink&quot;&gt;&lt;a class=&quot;link-card&quot; title=&quot;从头开始实现一个神经网络&quot; href=&quot;http</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    <category term="YoloV3" scheme="http://tumytime.github.io/tags/YoloV3/"/>
    
  </entry>
  
  <entry>
    <title>YoloV3模型构建</title>
    <link href="http://tumytime.github.io/2024/03/21/YoloV3%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/"/>
    <id>http://tumytime.github.io/2024/03/21/YoloV3%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/</id>
    <published>2024-03-21T13:28:10.000Z</published>
    <updated>2024-03-21T15:34:27.534Z</updated>
    
    <content type="html"><![CDATA[<div class="tagLink"><a class="link-card" title="【yolov3详解】一文让你读懂yolov3目标检测原理" href="https://blog.csdn.net/weixin_39615182/article/details/109752498"><span class="link-card-backdrop" style="background-image: url(https://tumytime.github.io/picx-images-hosting/image.7i057r983s.webp)"></span><div class="left"><img src="https://tumytime.github.io/picx-images-hosting/image.7i057r983s.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7i057r983s.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">【yolov3详解】一文让你读懂yolov3目标检测原理</p><p class="url">https://blog.csdn.net/weixin_39615182/article/details/109752498</p></div></a></div><p><strong>yolov3检测分两步：</strong><br>1、确定检测对象位置<br>2、对检测对象分类（是什么东西）<br>即在识别图片是什么的基础上，还需定位识别对象的位置，并框出。</p><p>我们首先上一幅图宏观理解下</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7i057r983s.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7i057r983s.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>图中的红框是通过在yolov3检测最后得出的<strong>边界框</strong>（bounding box），又如下图的黄色框也是边界框</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7smz0wp6zw.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7smz0wp6zw.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>yolov3处理图片过程如下</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.pf3lakvam.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.pf3lakvam.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>首先一张图片传进yolo，yolo会将其转化为416×416大小的网格，增加灰度条用于防止失真，之后图片会分成三个网格图片（13×13，26×26，52×52）<br>由于图像在多次卷积压缩后，小物体的特征容易丢失，所以用52x52的网格检测小物体，由于猫属于大物体，所以用13x13的网格检测</p><h2 id="详细过程"><a href="#详细过程" class="headerlink" title="详细过程"></a>详细过程</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8ad0phujlt.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8ad0phujlt.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>先上流程图，该图是基于<strong>voc数据集</strong>讲解的，voc数据集有20个类别，最下面红框中(13，13，75)表示预测结果的shape，实际上是13,13,3×25,表示有13*13的网格，每个网格有3个先验框（又称锚框，anchors，先验框下面有解释），每个先验框有25个参数(20个类别+5个参数)，这5个参数分别是<strong>x_offset</strong>、<strong>y_offset</strong>、<strong>height</strong>、<strong>width</strong>与<strong>置信度confidence</strong>，用这3个框去试探，试探是否框中有物体，如果有，就会把这个物体给框起来。如果是基于coco的数据集就会有80种类别，最后的维度应该为3x(80+5)&#x3D;255，最上面两个预测结果shape同理</p><p>yolov3主干网络为Darknet53，重要的是使用了<strong>残差网络Residual</strong>，darknet53的每一个卷积部分使用了特有的<strong>DarknetConv2D结构</strong>，每一次卷积的时候进行<strong>l2正则化</strong>，完成卷积后进行<strong>BatchNormalization标准化</strong>与<strong>LeakyReLU激活函数</strong></p><p>对应代码如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--------------------------------------------------#</span></span><br><span class="line"><span class="comment">#   单次卷积</span></span><br><span class="line"><span class="comment">#--------------------------------------------------#</span></span><br><span class="line"><span class="meta">@wraps(<span class="params">Conv2D</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DarknetConv2D</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">    darknet_conv_kwargs = &#123;<span class="string">&#x27;kernel_regularizer&#x27;</span>: l2(<span class="number">5e-4</span>)&#125;</span><br><span class="line">    darknet_conv_kwargs[<span class="string">&#x27;padding&#x27;</span>] = <span class="string">&#x27;valid&#x27;</span> <span class="keyword">if</span> kwargs.get(<span class="string">&#x27;strides&#x27;</span>)==(<span class="number">2</span>,<span class="number">2</span>) <span class="keyword">else</span> <span class="string">&#x27;same&#x27;</span></span><br><span class="line">    darknet_conv_kwargs.update(kwargs)</span><br><span class="line">    <span class="keyword">return</span> Conv2D(*args, **darknet_conv_kwargs)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------------------------#</span></span><br><span class="line"><span class="comment">#   卷积块</span></span><br><span class="line"><span class="comment">#   DarknetConv2D + BatchNormalization + LeakyReLU</span></span><br><span class="line"><span class="comment">#---------------------------------------------------#</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DarknetConv2D_BN_Leaky</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">    no_bias_kwargs = &#123;<span class="string">&#x27;use_bias&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">    no_bias_kwargs.update(kwargs)</span><br><span class="line">    <span class="keyword">return</span> compose( </span><br><span class="line">        DarknetConv2D(*args, **no_bias_kwargs),<span class="comment">#调用单次卷积函数进行正则化</span></span><br><span class="line">        BatchNormalization(),<span class="comment"># 标准化</span></span><br><span class="line">        LeakyReLU(alpha=<span class="number">0.1</span>))<span class="comment"># 激活函数</span></span><br></pre></td></tr></table></figure><details open><summary pointer> python装饰器 </summary>              <div class='content'>              <p><strong>将函数作为参数传给另一个函数</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hi</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;hi yasoob!&quot;</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">doSomethingBeforeHi</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;I am doing some boring work before executing hi()&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(func())</span><br><span class="line"> </span><br><span class="line">doSomethingBeforeHi(hi)</span><br><span class="line"><span class="comment">#outputs:I am doing some boring work before executing hi()</span></span><br><span class="line"><span class="comment">#        hi yasoob!</span></span><br></pre></td></tr></table></figure><p>现在你已经具备所有必需知识，来进一步学习装饰器真正是什么了。装饰器让你在一个函数的前后去执行代码。</p><p><strong>你的第一个装饰器</strong></p><p>在上一个例子里，其实我们已经创建了一个装饰器！现在我们修改下上一个装饰器，并编写一个稍微更有用点的程序：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">a_new_decorator</span>(<span class="params">a_func</span>):</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapTheFunction</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I am doing some boring work before executing a_func()&quot;</span>)</span><br><span class="line"> </span><br><span class="line">        a_func()</span><br><span class="line"> </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I am doing some boring work after executing a_func()&quot;</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> wrapTheFunction</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">a_function_requiring_decoration</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;I am the function which needs some decoration to remove my foul smell&quot;</span>)</span><br><span class="line"> </span><br><span class="line">a_function_requiring_decoration()</span><br><span class="line"><span class="comment">#outputs: &quot;I am the function which needs some decoration to remove my foul smell&quot;</span></span><br><span class="line"> </span><br><span class="line">a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)</span><br><span class="line"><span class="comment">#now a_function_requiring_decoration is wrapped by wrapTheFunction()</span></span><br><span class="line"> </span><br><span class="line">a_function_requiring_decoration()</span><br><span class="line"><span class="comment">#outputs:I am doing some boring work before executing a_func()</span></span><br><span class="line"><span class="comment">#        I am the function which needs some decoration to remove my foul smell</span></span><br><span class="line"><span class="comment">#        I am doing some boring work after executing a_func()</span></span><br></pre></td></tr></table></figure><p>你看明白了吗？我们刚刚应用了之前学习到的原理。这正是python中装饰器做的事情！它们封装一个函数，并且用这样或者那样的方式来修改它的行为。现在你也许疑惑，我们在代码里并没有使用<code>@</code>符号？那只是一个简短的方式来生成一个被装饰的函数。这里是我们如何使用<code>@</code>来运行之前的代码：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@a_new_decorator</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">a_function_requiring_decoration</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Hey you! Decorate me!&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;I am the function which needs some decoration to &quot;</span></span><br><span class="line">          <span class="string">&quot;remove my foul smell&quot;</span>)</span><br><span class="line"> </span><br><span class="line">a_function_requiring_decoration()</span><br><span class="line"><span class="comment">#outputs: I am doing some boring work before executing a_func()</span></span><br><span class="line"><span class="comment">#         I am the function which needs some decoration to remove my foul smell</span></span><br><span class="line"><span class="comment">#         I am doing some boring work after executing a_func()</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#the @a_new_decorator is just a short way of saying:</span></span><br><span class="line">a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration)</span><br></pre></td></tr></table></figure>              </div>            </details><p>讲解流程之前的<strong>基本概念</strong>了解一下，后面不记得回来再看看</p><p><strong>x_offset</strong>：表示网格左上角相对x轴的距离（偏移量）<br><strong>y_offset</strong>：表示网格左上角相对y轴的距离（偏移量）</p><p><strong>上采样</strong>：缩小图像（或称为下采样（subsampled），如池化）的主要目的有两个：1、使得图像符合显示区域的大小；2、生成对应图像的缩略图。放大图像（或称为上采样（upSampling）或图像插值（interpolating））的主要目的是放大原图像,从而可以显示在更高分辨率的显示设备上。</p><p><strong>先验框</strong>（anchor box）：就是帮助我们定好了常见目标的宽和高，在进行预测的时候，我们可以利用这个已经定好的宽和高来进行处理，可以帮助我们进行预测，作用就是辅助处理x_offset、y_offset、h和w。如下图所示，用的是coco数据集，输出是(13,13,(80+5)*3)，乘3表示，有3个先验框，每个先验框都有85个参数，下图就有3个蓝色框，也即先验框，可以理解成给你的建议框，识别的对象可能在这些建议框中，目的是带你得到更高的IOU，即更高置信度、更可能有对象得部分，黄色框为真实最后显示的边界框，红色框表示中心位置。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2kroe0h5ah.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2kroe0h5ah.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p><strong>置信度</strong>（confidence）：就是预测的先验框和真实框ground truth box（真实对象的框）的IOU值，即先验框是否有对象的概率Pr(Object)，如进行人脸识别，一张图中有房子，树，车，人等，识别时背景和人的身体都没有脸这个需要识别的对象，那么这些地方的置信度就是0，框中的人脸越多，置信度（有对象概率）就越大，置信度是检测中非常重要的参数</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.5tqsao8853.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.5tqsao8853.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>IOU表示交并比</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.3razmma7pz.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.3razmma7pz.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p><strong>为什么要使用残差（Residual）神经网络？</strong><br>答：网络越深，梯度消失的现象就越来越明显，网络的训练效果也不会很好。残差神经网络就是为了在加深网络的情况下又解决梯度消失的问题。残差结构可以不通过卷积，直接从前面一个特征层映射到后面的特征层（跳跃连接），有助于训练，也有助于特征的提取，容易优化。</p><h2 id="yolov3检测流程原理"><a href="#yolov3检测流程原理" class="headerlink" title="yolov3检测流程原理"></a>yolov3检测流程原理</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.26l8n5exyl.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.26l8n5exyl.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="第一步：从特征获取预测结果"><a href="#第一步：从特征获取预测结果" class="headerlink" title="第一步：从特征获取预测结果"></a>第一步：从特征获取预测结果</h3><ol><li><p>yolov3提取多特征层进行目标检测，一共提取三个特征层，三个特征层位于主干特征提取网络darknet53的不同位置，分别位于中间层，中下层，底层，三个特征层的shape分别为(52,52,256)、(26,26,512)、(13,13,1024)，这三个特征层后面用于与上采样后的其他特征层堆叠拼接（Concat）</p></li><li><p>第三个特征层(13,13,1024)进行5次卷积处理（为了特征提取），处理完后一部分用于卷积+上采样UpSampling，另一部分用于输出对应的预测结果（13,13,75），Conv2D 3×3和Conv2D1×1两个卷积起通道调整的作用，调整成输出需要的大小。</p></li><li><p>卷积+上采样后得到(26,26,256)的特征层，然后与Darknet53网络中的特征层(26,26,512)进行拼接，得到的shape为(26,26,768)，再进行5次卷积，处理完后一部分用于卷积上采样，另一部分用于输出对应的预测结果(26,26,75)，Conv2D 3×3和Conv2D1×1同上为通道调整</p></li><li><p>之后再将3中卷积+上采样的特征层与shape为(52,52,256)的特征层拼接（Concat）,再进行卷积得到shape为(52,52,128)的特征层，最后再Conv2D 3×3和Conv2D1×1两个卷积，得到(52,52,75)特征层</p></li></ol><p>最后图中有三个红框原因就是有些物体相对在图中较大，就用13×13检测，物体在图中比较小，就会归为52×52来检测</p><h3 id="第二步：预测结果的解码"><a href="#第二步：预测结果的解码" class="headerlink" title="第二步：预测结果的解码"></a>第二步：预测结果的解码</h3><p>预测结果解码原因：预测结果(红框)并不对应着最终的预测框在图片上的位置，还需要解码）</p><p>yolov3的预测原理是分别将整幅图分为13x13、26x26、52x52的网格，每个网络点负责一个区域的检测。解码过程就是计算得出最后显示的边界框的坐标bx,by，以及宽高bw,bh，这样就得出了边界框的位置，计算过程如图（b–为bounding box 缩写）</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.1e8d5fao6l.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.1e8d5fao6l.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>(cx,cy)：该点所在网格的左上角距离最左上角相差的格子数。<br>(pw,ph)：先验框的边长<br>(tx,ty)：目标中心点相对于该点所在网格左上角的偏移量<br>(tw,th)：预测边框的宽和高<br>σ：激活函数，论文作者用的是sigmoid函数，[0,1]之间概率，之所以用sigmoid取代之前版本的softmax，原因是softmax会扩大最大类别概率值而抑制其他类别概率值 ，图解如下</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.9rj5rcytb7.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.9rj5rcytb7.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>注：最终得到的边框坐标值是bx,by,bw,bh.而网络学习目标是tx，ty，tw，th。<br>另外cy向下此处为正向</p><h3 id="第三步：对预测出的边界框得分排序与非极大抑制筛选"><a href="#第三步：对预测出的边界框得分排序与非极大抑制筛选" class="headerlink" title="第三步：对预测出的边界框得分排序与非极大抑制筛选"></a>第三步：对预测出的边界框得分排序与非极大抑制筛选</h3><p>这步就是将最大概率的框筛选出来<br>1、取出每一类得分大于一定阈值的框和得分进行排序。<br>2、利用框的位置和得分进行非极大抑制。最后可以得出概率最大的边界框，也就是最后显示出的框<br>如下几幅图，一步步筛选得到最终边界框</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tagLink&quot;&gt;&lt;a class=&quot;link-card&quot; title=&quot;【yolov3详解】一文让你读懂yolov3目标检测原理&quot; href=&quot;https://blog.csdn.net/weixin_39615182/article/details/1</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    <category term="YoloV3" scheme="http://tumytime.github.io/tags/YoloV3/"/>
    
  </entry>
  
  <entry>
    <title>1x1卷积核</title>
    <link href="http://tumytime.github.io/2024/03/21/1x1%E5%8D%B7%E7%A7%AF%E6%A0%B8/"/>
    <id>http://tumytime.github.io/2024/03/21/1x1%E5%8D%B7%E7%A7%AF%E6%A0%B8/</id>
    <published>2024-03-21T09:40:05.000Z</published>
    <updated>2024-03-21T12:15:18.385Z</updated>
    
    <content type="html"><![CDATA[<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7awxc3fekp.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7awxc3fekp.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><blockquote><p>在卷积神经网络的卷积层中，不同的通道使用的卷积核参数是不一样的。每个通道都有自己对应的卷积核参数，这些参数用于在该通道上对输入数据进行滤波操作，提取特定的特征。<br>通道之间的卷积核参数是不共享的，即每个通道都有自己独特的卷积核参数。这种设计可以让神经网络更加灵活地学习不同通道之间的特征表示，从而提高网络的表征能力。</p></blockquote><h2 id="1×1-卷积核作用"><a href="#1×1-卷积核作用" class="headerlink" title="$1×1$卷积核作用"></a>$1×1$卷积核作用</h2><p><strong>卷积层中的卷积核数量决定了输出的通道数，而每个卷积核的通道数取决于输入数据的通道数</strong></p><ol><li><p><strong>卷积核数决定了输出通道数：</strong> 在卷积神经网络中，每个卷积层包含多个卷积核。每个卷积核在输入数据上进行卷积操作，生成一个对应的输出特征图（通道）。因此，卷积核的数量决定了输出特征图的通道数。如果一个卷积层有n个卷积核，那么输出将包含n个通道。</p></li><li><p><strong>每个卷积核的通道数取决于输入的通道数：</strong> 当卷积核在输入数据上进行卷积操作时，每个卷积核会同时处理输入数据的所有通道。例如，如果输入数据是RGB图像，有3个通道（红色、绿色、蓝色），那么每个卷积核将同时在这3个通道上进行卷积操作。这样，每个卷积核的通道数就等于输入数据的通道数。因此，卷积核的通道数取决于输入数据的通道数。</p></li></ol><h3 id="增加网络深度-增加非线性映射次数"><a href="#增加网络深度-增加非线性映射次数" class="headerlink" title="增加网络深度(增加非线性映射次数)"></a>增加网络深度(增加非线性映射次数)</h3><iframe src="//player.bilibili.com/player.html?aid=696259725&bvid=BV11m4y1r7jK&cid=1062261407&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><p>首先直接从网络深度来理解，1x1 的卷积核虽小，但也是卷积核，加 1 层卷积，网络深度自然会增加。<br>1x1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很深。并且1x1卷积核的卷积过程相当于全连接的计算过程，通过<strong>加入非线性激活函数</strong>，可以<strong>增加网络的非线性</strong>，使得网络可以表达更复杂的特征。</p><h4 id="feature-map的含义"><a href="#feature-map的含义" class="headerlink" title="feature map的含义"></a>feature map的含义</h4><p>在每个卷积层，数据都是以三维形式存在的。你可以把它看成许多个二维图片叠在一起，其中每一个称为一个feature map。在输入层，如果是灰度图片，那就只有一个feature map；如果是彩色图片，一般就是3个feature map（红绿蓝）。层与层之间会有若干个卷积核（kernel），上一层和每个feature map跟每个卷积核做卷积，都会产生下一层的一个feature map。</p><p>feature map（下图红线标出） 即：该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map，也就是下图中 <code>豆腐皮儿</code>的层数、同时也是下图<code>豆腐块</code>的深度（宽度）！！这个宽度可以手动指定，一般网络越深的地方这个值越大，因为随着网络的加深，feature map的长宽尺寸缩小，本卷积层的每个map提取的特征越具有代表性（精华部分），所以后一层卷积层需要增加feature map的数量，才能更充分的提取出前一层的特征，一般是成倍增加（不过具体论文会根据实验情况具体设置）！</p><p>在卷积神经网络中，每个卷积层都包含多个卷积核（也称为滤波器），每个卷积核生成一个特征图。当前一层输出的特征图与后一层卷积核进行卷积操作时，可以看作是在进行矩阵相乘操作。增加后一层的特征图数量实际上意味着增加了后一层卷积核的数量，这可以使网络在进行特征提取时拥有更多的“过滤器”，从而更全面地捕获输入数据中的不同特征和模式。</p><p>卷积特征的可视化，有助于我们更好地理解深度网络。卷积网络在学习过程中保持了图像的空间结构，也就是说最后一层的激活值（feature map）总和原始图像具有空间上的对应关系，具体对应的位置以及大小，可以用感受野来度量。利用这点性质可以做很多事情：</p><ol><li>前向计算。我们直接可视化网络每层的 feature map，然后观察feature map 的数值变化. 一个训练成功的CNN 网络，其feature map 的值伴随网络深度的增加，会越来越稀疏。这可以理解网络取精去燥。 <details open><summary pointer> WHY越来越稀疏 </summary>              <div class='content'>              <p>在一个训练成功的CNN（Convolutional Neural Network）网络中，随着网络深度的增加，feature map 的值会越来越稀疏的现象可以通过以下方面进行详细解释：</p><ol><li><p><strong>特征稀疏性在深层网络中的原因</strong>：</p><ul><li><strong>激活函数的非线性作用</strong>：在卷积神经网络中，通常在每个卷积层之后都会使用非线性激活函数（如ReLU）。这种非线性激活会导致大部分神经元的输出接近于0，只有部分神经元会激活并输出非零值，从而导致 feature map 的稀疏性。</li><li><strong>权重更新和特征选择</strong>：随着网络的训练，CNN 会根据损失函数进行权重更新，通过学习提取对分类任务有用的特征。在网络深度增加的过程中，网络会更加注重对关键特征的提取，而相对不重要的特征很可能被抑制，这也会导致 feature map 的稀疏性。</li></ul></li><li><p><strong>稀疏特征对网络性能的影响</strong>：</p><ul><li><strong>泛化能力提升</strong>：存储较少的激活值可以增加网络的泛化能力，减少过拟合的风险，因为网络更多地关注于对区分性重要的特征进行学习。</li><li><strong>计算效率提高</strong>：稀疏的特征图在后续的层次中减少了计算量，因为对于很多值较小或接近于零的神经元，不必执行额外的乘法运算，从而提高了网络的计算效率。</li></ul></li><li><p><strong>深度增加导致特征复杂性</strong>：</p><ul><li>随着网络深度的增加，特征图表示的特征也会变得越来越复杂和抽象，需要更少的激活来描述一个高级别的特征，这也间接导致 feature map 的稀疏性。</li></ul></li></ol><p>综上所述，随着网络深度的增加，一个训练成功的CNN 网络中的 feature map 的值会变得越来越稀疏，这主要是由于非线性激活函数的作用、权重更新和特征选择机制，以及深层网络中复杂特征的表示所导致的结果。这种稀疏性有助于提升网络的泛化能力、计算效率，并反映了网络对关键特征的学习和抽象能力。</p><details open><summary pointer> 激活一个神经元的过程 </summary>          <div class='content'>          <p>激活一个神经元的过程可以简单描述为以下几个步骤：</p><ol><li><p><strong>加权求和（Weighted Summation）</strong>：神经元接收来自上一层或输入数据的输入信号，每个输入信号都会乘以对应的连接权重（weights），然后将所有加权输入信号求和，得到一个加权和。这个加权和可以表示为：$[ z &#x3D; \sum_{i&#x3D;1}^{n} (w_i \cdot x_i) + b ]$，其中 $(w_i)$ 是第 $(i)$ 个输入信号的权重，$(x_i)$ 是对应的输入值，$(b)$ 是神经元的偏置项（bias）。</p></li><li><p><strong>激活函数（Activation Function）</strong>：将上一步计算得到的加权和$(z)$输入到激活函数中，激活函数会对加权和进行非线性变换，从而输出神经元的激活值（activation value）。常见的激活函数包括ReLU、Sigmoid、Tanh等。激活函数将决定神经元是否被激活，以及激活级别如何。</p></li><li><p><strong>输出值（Output）</strong>：激活函数的输出值即为神经元的最终输出，也可以表示为神经元的激活值。这个输出值将会被传递到下一层神经元或作为最终输出。</p></li></ol><p>总结起来，激活一个神经元的详细过程就是通过加权求和得到输入信号的加权和，然后经过激活函数进行非线性变换得到最终的输出值。这个过程在神经网络的每一层都会被重复执行，用于处理来自前一层神经元的信号并生成新的表示。</p>          </div>        </details>               </div>            </details></li><li>反向计算。根据网络最后一层最强的激活值，利用感受野求出原始输入图像的区域。可以观察输入图像的那些区域激活了网络，利用这个思路可以做一些物体定位。</li></ol><h4 id="1x1卷积核增加网络深度的原因"><a href="#1x1卷积核增加网络深度的原因" class="headerlink" title="1x1卷积核增加网络深度的原因"></a>1x1卷积核增加网络深度的原因</h4><p>在卷积神经网络中，1x1卷积核通过在通道维度上进行卷积操作，可以起到增加网络深度的作用。这是因为1x1卷积核可以在不改变空间尺寸的情况下，增加通道数量，从而增加网络的深度，提供更多的非线性变换和表达能力。以下是1x1卷积核如何增加网络深度的原理：</p><ol><li><p><strong>通道维度的变换：</strong> 1x1卷积核的作用是在每个空间位置对输入数据的通道进行线性变换。通过对输入数据的每个通道分别进行加权求和，可以生成新的特征表示。这样，在1x1卷积层之后，输出将具有更多的通道数，因此网络的深度也会增加。</p></li><li><p><strong>引入非线性变换：</strong> 尽管1x1卷积核是在通道维度上进行卷积操作，但其引入的非线性激活函数（如ReLU）会使输出具有更丰富的特征表示能力。这种非线性变换有助于增加网络的深度，使网络能够学习到更复杂的特征。</p></li><li><p><strong>增加网络的表达能力：</strong> 通过1x1卷积核增加网络的深度，网络可以更好地捕获不同抽象级别的特征。每个1x1卷积层都可以看作是一个含有非线性激活函数的全连接层，因此可以提高网络的表达能力和学习能力。</p></li></ol><h4 id="WHY使用1x1卷积核"><a href="#WHY使用1x1卷积核" class="headerlink" title="WHY使用1x1卷积核"></a>WHY使用1x1卷积核</h4><p><strong>增加网络深度有什么好处？为什么非要用 1x1 来增加深度呢？其它的不可以吗？</strong></p><p>其实，这涉及到<code>感受野</code>(感受野（Receptive Field）的定义是卷积神经网络每一层输出的特征图（feature map）上的像素点在输入图片上映射的区域大小)的问题，我们知道<strong>卷积核越大，它生成的 featuremap 上单个节点的感受野就越大</strong>，随着网络深度的增加，<strong>越靠后的 featuremap 上的节点感受野也越大。因此特征也越来越抽象</strong>。</p><p>但有的时候，我们想在不增加感受野的情况下，让网络加深，为的就是引入更多的非线性。</p><p>而 1x1 卷积核，恰巧可以办到。</p><p>我们知道，卷积后生成图片的尺寸受卷积核的大小和跨度影响，但如果卷积核是 1x1 ，跨度也是 1，那么生成后的图像大小就并没有变化。</p><p>但通常一个卷积过程包括一个激活函数，比如 Sigmoid 和 Relu。</p><p>所以，<strong>在输入不发生尺寸的变化下，却引入了更多的非线性</strong>，这将增强神经网络的表达能力</p><h3 id="升维-降维"><a href="#升维-降维" class="headerlink" title="升维&#x2F;降维"></a>升维&#x2F;降维</h3><p>其实这里的升维、降维具体指的是通道数的变化，当我们确定了卷积核尺寸后，我们的height、width都不变，那么这里的维度具体指的就是channels。我们通过改变卷积核的数量来改变卷积后特征图的通道channels来实现升维、降维的效果。这样可以将原本的数据量进行增加或者减少<br>下面分别举两个例子就能明显看到效果</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4ckn8pum0v.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4ckn8pum0v.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="升维"><a href="#升维" class="headerlink" title="升维"></a>升维</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.3nrdop8yvr.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.3nrdop8yvr.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2ruw98zwjt.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2ruw98zwjt.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.1e8d57p5wp.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.1e8d57p5wp.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>其实很明显的能看出来，无论是升维还是降维，我们都是通过改变卷积核的数量实现的，卷积后的特征图的通道数channels同卷积核的数量保持一致，这里其实不仅仅是1x1卷积核能实现这个功能，其他尺寸的卷积核也可以，那么我们为什么要选用1x1卷积核呢</p><h4 id="使用1x1卷积核升维-降维的原因"><a href="#使用1x1卷积核升维-降维的原因" class="headerlink" title="使用1x1卷积核升维&#x2F;降维的原因"></a>使用1x1卷积核升维&#x2F;降维的原因</h4><p>当我们仅仅只是想要改变通道数的情况下，1x1卷积核是最小的选择，因为大于1x1的卷积核无疑会增加计算的参数量，内存也会随之增大，所以只想单纯的去提升或者降低特征图的通道，选用1x1卷积核最为合适， 1x1卷积核会使用更少的权重参数数量。</p><h3 id="跨通道的信息交互"><a href="#跨通道的信息交互" class="headerlink" title="跨通道的信息交互"></a>跨通道的信息交互</h3><p>1x1卷积核只有一个参数，当它作用在多通道的feature map上时，相当于不同通道上的一个线性组合，实际上就是乘以一个系数再加起来，但是这样输出的feature map就是多个通道的整合信息了，能够使网络提取的特征更加丰富。</p><p>使用1x1卷积核，实现降维和升维的操作其实就是 channel 间信息的线性组合变化。</p><p>比如：在尺寸 3x3，64通道个数的卷积核后面添加一个尺寸1x1，28通道个数的卷积核，就变成了尺寸3x3，28尺寸的卷积核。 原来的64个通道就可以理解为跨通道线性组合变成了28通道，这就是通道间的信息交互。</p><p>注意：只是在通道维度上做线性组合，W和H上是共享权值的滑动窗口。</p><h3 id="减少卷积核参数（简化模型）"><a href="#减少卷积核参数（简化模型）" class="headerlink" title="减少卷积核参数（简化模型）"></a>减少卷积核参数（简化模型）</h3><p>下面仅以计算权重数为例子进行计算（不添加偏差bias）</p><h4 id="一层卷积添加1x1卷积核，分别计算权重数"><a href="#一层卷积添加1x1卷积核，分别计算权重数" class="headerlink" title="一层卷积添加1x1卷积核，分别计算权重数"></a>一层卷积添加1x1卷积核，分别计算权重数</h4><ul><li><p>不使用1x1卷积核</p>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.839stz0ial.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.839stz0ial.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li><li><p>使用1x1卷积核</p>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.73tpgsyher.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.73tpgsyher.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li></ul><p>可以看到不使用1x1的卷积核是使用卷积核的10倍左右</p><h4 id="GoogLeNet的3a模块"><a href="#GoogLeNet的3a模块" class="headerlink" title="GoogLeNet的3a模块"></a>GoogLeNet的3a模块</h4><ul><li>不使用1x1卷积核  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.58h4o6olfv.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.58h4o6olfv.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.13ljc2ryvv.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.13ljc2ryvv.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>权重数：192 × (1×1×64) +192 × (3×3×128) + 192 × (5×5×32) &#x3D; 387072<br>这个网络的说明如下</li></ul><ol><li>采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合；</li><li>之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride&#x3D;1之后，只要分别设定pad&#x3D;0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；</li><li>文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。</li><li>网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</li></ol><ul><li>使用1x1卷积核  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2a4ukoith5.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2a4ukoith5.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7zq6w9eiya.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7zq6w9eiya.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li></ul><p>权重数：192 × (1×1×64) +（192×1×1×96+ 96 × 3×3×128）+（192×1×1×16+16×5×5×32）&#x3D; 157184</p><p>不使用1x1的卷积核是使用1x1卷积核的权重数2倍</p><h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p>ResNet同样也利用了1×1卷积，并且是在3×3卷积层的前后都使用了，不仅进行了降维，还进行了升维，参数数量进一步减少</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8ojgga406k.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8ojgga406k.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>其中右图又称为<code>bottleneck design</code>，目的一目了然，就是为了降低参数的数目，第一个1x1的卷积把256维channel降到64维，然后在最后通过1x1卷积恢复，<br>当我们的特征图通道数为256时，变得很大，出现的问题是计算复杂度会很高，这里做法是通过1×1卷积投影映射回64维，再做一个3×3通道数不变的卷积，然后再通过1×1卷积投影回去256维，因为输入是256维，输出要匹配上，这样设计之后复杂度就跟左图差不多了。<br>左图参数量：64 x ( 3 x 3 x 64)+64 x ( 3 x 3 x 64 ) &#x3D; 73728<br>当通道数增加到 256时：256 x ( 3 x 3 x 256 ) + 256 x ( 3 x 3 x 256 ) &#x3D; 1179648<br>右图参数量：256 x ( 1 x 1 x 64) + 64 x ( 3 x 3 x 64 ) + 256 x ( 1 x 1 x 64) &#x3D; 69632</p><p>当通道数增加为256时，可以发现添加两层1x1的卷积的参数量和64为原有残差块参数量差不多。</p><p>对于常规ResNet，可以用于34层或者更少的网络中，对于Bottleneck Design的ResNet通常用于更深的网络中，目的是减少计算和参数量（实用目的）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img lazyload placeholder&quot; src=&quot;https://tumytime.github.io/picx-images-hosting/image.7a</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>残差网络</title>
    <link href="http://tumytime.github.io/2024/03/21/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/"/>
    <id>http://tumytime.github.io/2024/03/21/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/</id>
    <published>2024-03-21T08:49:21.000Z</published>
    <updated>2024-03-22T11:59:17.558Z</updated>
    
    <content type="html"><![CDATA[<div class="tagLink"><a class="link-card" title="详解残差网络" href="https://zhuanlan.zhihu.com/p/42706477"><span class="link-card-backdrop" style="background-image: url(https://pic2.zhimg.com/80/v2-bd76d0f10f84d74f90505eababd3d4a1_1440w.webp)"></span><div class="left"><img src="https://pic2.zhimg.com/80/v2-bd76d0f10f84d74f90505eababd3d4a1_1440w.webp" class="lazyload placeholder" data-srcset="https://pic2.zhimg.com/80/v2-bd76d0f10f84d74f90505eababd3d4a1_1440w.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">详解残差网络</p><p class="url">https://zhuanlan.zhihu.com/p/42706477</p></div></a></div><h2 id="WHY要有残差网络"><a href="#WHY要有残差网络" class="headerlink" title="WHY要有残差网络"></a><strong>WHY要有残差网络</strong></h2><blockquote><ul><li><p>首先，当网络发生退化时，意味着随着网络层数的增加，模型的性能并没有相应地提高，甚至可能变得更差。这通常是由于梯度消失、梯度爆炸或者模型优化难度增加导致的。在这种情况下，浅层的网络由于模型复杂度较低，可能更容易优化，因此能够达到更好的训练效果。</p></li><li><p>接下来，如果我们能够<strong>将低层的特征有效地传递到高层</strong>，那么高层网络就有可能利用这些有用的特征来提高性能。这是因为在深度学习中，<strong>低层网络</strong>通常学习一些<strong>基本的、通用的特征</strong>（如边缘、纹理等），而高层网络则在此基础上学习更复杂的特征。如果<strong>高层网络能够重用这些低层的特征，那么它就有可能达到甚至超过浅层网络的性能</strong>。</p></li><li><p>以VGG-100和VGG-16为例，假设我们在VGG-100的第98层和第14层之间<strong>添加一条直接映射</strong>（Identity Mapping）。这意味着第98层的输出将包含第14层的输出作为其一部分。<strong>如果这条直接映射能够有效地传递有用的特征，并且高层网络能够有效地利用这些特征，那么VGG-100的性能理论上应该至少与VGG-16相当，甚至可能更好。</strong></p></li><li><p>然而，需要注意的是，直接映射并不意味着简单地复制和粘贴特征。它需要以一种有效的方式将低层特征整合到高层网络中，以确保高层网络能够充分利用这些特征。此外，还需要考虑如何平衡新旧特征之间的关系，以及如何处理特征维度不匹配等问题。</p></li><li><p>在实际应用中，直接映射的策略已经在一些深度学习架构中得到了应用，如<strong>残差网络（ResNet）和密集连接网络（DenseNet）</strong>。这些网络通过引入残差块或密集连接来实现直接映射，从而有效地缓解了网络退化的问题，并提高了模型的性能。</p></li></ul></blockquote><details open><summary pointer> 高层网络 </summary>              <div class='content'>              <blockquote><p>在一个神经网络中，离输入层更远的网络层通常被称为“深层网络”或“高层网络”，因为它们在网络中的位置更深或更靠近网络的中间部分，而不是直接与输出层相连。这些深层网络通常包括多个隐藏层，并且在网络的层次结构中扮演重要的角色，用于提取更加抽象和高级的特征信息。<br>一个神经网络的层次结构通常包括输入层、多个隐藏层（包括深层网络）和输出层。深层网络在隐藏层中间位置，远离输入层但不是靠近输出层，因为深层网络通常在多层神经网络的结构中处于中间位置。<br>因此，深层网络位于输入层和输出层之间，通过多个隐藏层处理输入数据，逐步提取和学习特征，最终为输出层提供经过多次非线性变换后的表示以完成具体任务。深度学习模型的深度通常指的是隐藏层的层数，而深层网络则是指包含多个隐藏层的部分。</p></blockquote><blockquote><p>高层网络（即深层网络）在深度学习中具有以下特点：</p><ol><li><p><strong>多层结构</strong>：高层网络由多个隐藏层组成，每一层都包含大量的神经元。通过多层结构，网络可以学习和表示更加复杂和抽象的特征。</p></li><li><p><strong>层间连接</strong>：不同层之间的神经元相互连接，信息逐层传递。每一层的输出作为下一层的输入，通过层间连接实现特征的组合和抽象。</p></li><li><p><strong>特征提取</strong>：高层网络可以通过多个隐藏层逐步提取数据中的特征信息，从低级特征到高级特征的逐渐抽象过程有助于网络学习更深层次的表示。</p></li><li><p><strong>表征学习</strong>：通过深度学习，高层网络可以自动学习表示数据的特征，而无需手工设计特征提取器。这种表征学习的方式能够更好地适应不同类型的数据和任务。</p></li><li><p><strong>非线性变换</strong>：高层网络通过激活函数引入非线性变换，使网络能够学习和表示更加复杂的函数关系。非线性激活函数如ReLU、Sigmoid等有助于网络学习非线性模式。</p></li><li><p><strong>端对端学习</strong>：高层网络支持端对端学习，即从原始输入数据端到最终输出结果端的全过程训练。这种端对端学习能够更好地优化整个模型，提高模型的泛化能力和性能。</p></li></ol><p>总的来说，高层网络的特点包括多层结构、特征提取、表征学习、非线性变换等，使得深度学习模型能够更好地适应和解决复杂的机器学习任务。</p></blockquote><blockquote><p>在深度神经网络中，一旦到达最深层级，通常会对网络进行一些操作，以降低网络的深度或减少参数数量，使接下来的层级逐渐变浅。这些操作包括：</p><ol><li><p><strong>降采样（Downsampling）</strong>：通过池化操作（如最大池化或平均池化）或步长较大的卷积操作来减少特征图的宽度和高度，从而减少下一层的神经元数量。</p></li><li><p><strong>特征合并（Feature Concatenation）</strong>：将前几层提取的高级特征与浅层特征进行连接或拼接，使得网络在接下来层级中不需要再学习这些高级特征，从而减少网络的深度。</p></li><li><p><strong>特征选择（Feature Selection）</strong>：对于某些特征进行筛选或降维，只保留最重要的特征，可以通过降维技术（如主成分分析）来实现。</p></li><li><p><strong>残差连接（Residual Connections）</strong>：在残差网络（ResNet）中使用残差连接，使得深层网络可以通过跳过连接获得浅层网络的信息，从而减少深层网络的堆叠层数。</p></li><li><p><strong>特征映射（Feature Mapping）</strong>：通过对特征图进行逐层映射或抽取表示，可以将原始的深层特征映射到浅层网络中，减少网络的深度。</p></li></ol><p>这些操作旨在提高网络的效率和泛化能力，避免深度过深导致的梯度消失、计算量增加和过拟合等问题。通过适当的操作，可以使深度神经网络在保持良好性能的同时，减少深度或层级，提高网络的训练效率和性能。</p></blockquote>              </div>            </details><details open><summary pointer> CNN中的底层、高层特征、上下文信息、多尺度 </summary>              <div class='content'>              <ol><li><p><strong>CNN中的底层、高层特征:</strong></p><p> 简短总结： 分类要求特征有较多的高级信息，回归（定位）要求特征包含更多的细节信息</p><ul><li><p><strong>图像的低层特征</strong>（对定位任务帮助大，我们可以想想比如轮廓信息都不准那怎么去良好定位）:</p><p>  图像底层特征指的是：轮廓、边缘、颜色、纹理、棱角和形状特征。</p><p>  边缘和轮廓能反映图像内容；如果能对边缘和关键点进行可靠提取的话，很多视觉问题就基本上得到了解决。图像的低层的特征语义信息比较少，但越浅的层特征越细节（低级）且特征图分辨率大，所以位置信息很充足，目标位置准确。再从另一个方面讲，越浅层的特征感受野越小（每个像素点映射回原图的覆盖面积小），故用浅层特征图检测大目标时就有点像瞎子摸象的感觉效果并不好，因为光能看到象腿也不知道这是啥东西。当然对于小目标检测来说如果能利用足够的上下文信息也是有好处的！例如，通过只看图中的一个小目标所在的那个位置，人类甚至很难识别这些物体。然而，通过考虑到它位于天空中的背景，这个物体可以被识别为鸟类。因此，我们认为，解决这个问题的关键取决于我们如何将上下文作为额外信息来帮助检测小目标。</p></li><li><p><strong>图像的高层特征</strong>也叫语义特征（高层特征即CNN中网络越深的层得到的特征，高层的特征包含很丰富的组合信息，象征着人对它的分辨能力，越高层越好分辨出是啥东西，如表征着类别啥的，对识别任务帮助大）:</p></li></ul><p> 图像的高层语义特征值得是我们所能看的东西，比如对一张人脸提取低层特征我们可以提取到连的轮廓、鼻子、眼睛之类的，那么高层的特征就显示为一张人脸。高层的特征语义信息比较丰富，但是目标位置比较粗略。</p><p> 愈深层特征包含的高层语义性愈强、分辨能力也愈强。我们把图像的视觉特征称为视觉空间 (visual space)，把种类的语义信息称为语义空间 (semantic space)</p></li><li><p><strong>上下文信息</strong></p><p> 做图像的，上下文特征是很常见的，其实上下文大概去理解就是图像中的每一个像素点不可能是孤立的，一个像素一定和周围像素是有一定的关系的，大量像素的互相联系才产生了图像中的各种物体，所以上下文特征就指像素以及周边像素的某种联系。</p><p> 具体到图像语义分割，一般论文会说我们的XXX算法充分结合了上下文信息，意思也就是在判断某一个位置上的像素属于哪种类别的时候，不仅考察到该像素的灰度值，还充分考虑和它临近的像素。</p><p> 然后上下文信息还分全局和局部，意思就是考虑全图不同范围内的像素和只考虑邻近的一些像素。</p><p> 全局上下文信息 也可以理解为能够捕捉来自更多的不同尺度的上下文信息，不同尺度就是指不同感受野。</p></li><li><p><strong>多尺度</strong></p><p> 个人感觉，多尺度 就是 你能看到的范围（看到尺度就理解为CNN的感受野就完事了！！！）。</p><p> 图像中一个东西的尺度越大，就指距离越近相当于被放大了，那么给人感觉就越模糊。例如：</p><ul><li><p>训练的时候，把图片缩放到不同大小输入给同一个网络，网络就能看到不一样大小范围的内容，缩放得分辨率越高就指尺度越大，因为对图中的某一个物体来讲就是被放大的感觉。然后就是因为缩放后，比如中间特征图上的某个像素点都只能看到原图3乘3的区域，可随着输入的图片尺度不一样，同样是看到的3乘3区域，但相对于整张图的范围也自然就不一样了，然后就叫做多尺度训练；好处是可以适应不同尺度的输入，泛化性好。</p></li><li><p>把一个特征层用由不同感受野的卷积核组成的网络层（例如SPP）处理，这层网络的同一个像素位置就能看到不同范围的上层特征，就叫做多尺度特征融合；好处是能考虑到不同范围的空间特征上下文（例如头发下面一般会有一张脸）。</p></li><li><p>把一个网络中不同深度的层做融合：浅层感受野小，分辨率大，能够处理并保存小尺度的几何特征；高层感受野大，分辨率小，能够处理并保存大尺度的语义特征。这也叫做多尺度特征融合；好处是能够将语义特征和几何特征进行融合（例如这块区域是头发，低分辨率图上的分界线一般是线状特征和非线状特征的边界）。</p></li></ul></li></ol>              </div>            </details><blockquote><p>从信息论的角度讲，由于DPI(数据处理不等式)的存在，在前向传输的过程中，随着层数的加深，Feature Map包含的图像信息会逐层减少，而ResNet的直接映射的加入，保证了$l+1$层的网络一定比$l$层包含更多的图像信息。</p><details open><summary pointer> 解释 </summary>              <div class='content'>              <p>保证了$l+1$层的网络一定比l层包含更多的图像信息，这是因为直接映射（恒等映射）将前一层的信息无损地传递到了后一层，确保了信息的完整性。同时，由于残差部分的存在，网络可以学习输入和输出之间的差值，即残差。这个残差部分可能会引入一些新的、有用的特征或模式，这些特征或模式在之前的层中可能并不存在。这些新增的特征或模式会与直接映射的信息相结合，导致$l+1$层的信息量实际上比$l$层更多。<br>换句话说，直接映射保证了信息量的下限（即至少与前一层相同），而残差部分则有可能增加额外的信息量。因此，综合这两部分，$l+1$层的网络包含的信息量一定会比$l$层更多。这也是ResNet能够在增加网络深度的同时保持甚至提高性能的关键原因之一。<br>需要注意的是，这里的“更多”并不意味着绝对的信息量一定更大，而是指相对于前一层，后一层有可能包含更多的有用特征或模式。在实际应用中，还需要考虑其他因素，如网络的训练方式、数据集的质量等，来综合评估网络性能。</p>              </div>            </details><p>基于这种使用直接映射来连接网络不同层直接的思想，残差网络应运而生。</p></blockquote><h2 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h2><h3 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h3><p>残差网络是由一系列残差块组成的（图1）。一个残差块可以用表示为：</p><p class='p center'>$x_{l+1}=x_l+F(x_l，W_l)$</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.969i4oz9f9.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.969i4oz9f9.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="图1:残差块"/></div><span class="image-caption">图1:残差块</span></div><blockquote><p>图1中的Weight在卷积网络中是指卷积操作，addition指的是单位加操作，即在卷积计算中的相加步骤。<br>卷积计算的4个步骤为反折、平移、相乘、相加。将两组数进行卷积后，变成第三组数，其中相加就是addition。</p></blockquote><p><strong>残差块分成两部分-直接映射部分和残差部分。</strong></p><ul><li>$h(x_l)$是直接映射，反应在图1中是左边的曲线</li><li>$F(x_l，W_l)$是残差部分，一般由两个或者三个卷积操作构成，即图1中右侧包含卷积的部分。</li></ul><p>在卷积网络中,$x_l$可能和$x_{l+1}$的Feature Map的数量不一样，这时候就需要使用$1×1$卷积进行升维或者降维（图2）。</p><div class="tagLink"><a class="link-card" title="$1×1$卷积核" href="https://tumytime.space/2024/03/21/1x1%E5%8D%B7%E7%A7%AF%E6%A0%B8/"><span class="link-card-backdrop" style="background-image: url(https://tumytime.github.io/picx-images-hosting/image.7awxc3fekp.webp)"></span><div class="left"><img src="https://tumytime.github.io/picx-images-hosting/image.7awxc3fekp.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7awxc3fekp.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">$1×1$卷积核</p><p class="url">https://tumytime.space/2024/03/21/1x1%E5%8D%B7%E7%A7%AF%E6%A0%B8/</p></div></a></div><p>这时，残差块表示为：</p><p class='p center'>$x_{l+1}=h(x_l)+F(x_l，W_l)$</p><p>其中$h(x_l)&#x3D;W_l^{‘}x$。其中$W_l^{‘}$是$1×1$卷积操作，但是实验结果$1×1$卷积对模型性能提升有限，所以一般是在升维或者降维时才会使用。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.54xiqiz1jd.webp ,alt=$1×1$残差块" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.54xiqiz1jd.webp ,alt=$1×1$残差块" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>一般，这种版本的残差块叫做resnet_v1，keras代码实现如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">res_block_v1</span>(<span class="params">x, input_filter, output_filter</span>):</span><br><span class="line">    res_x = Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>), filters=output_filter, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    res_x = BatchNormalization()(res_x)</span><br><span class="line">    res_x = Activation(<span class="string">&#x27;relu&#x27;</span>)(res_x)</span><br><span class="line">    res_x = Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>), filters=output_filter, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)(res_x)</span><br><span class="line">    res_x = BatchNormalization()(res_x)</span><br><span class="line">    <span class="keyword">if</span> input_filter == output_filter:</span><br><span class="line">        identity = x</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment">#需要升维或者降维</span></span><br><span class="line">        identity = Conv2D(kernel_size=(<span class="number">1</span>,<span class="number">1</span>), filters=output_filter, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    x = keras.layers.add([identity, res_x])</span><br><span class="line">    output = Activation(<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>这段代码定义了一个简单的残差块（residual block），用于构建残差神经网络（ResNet）中的一个基本单元。在这段代码中，<code>res_block_v1</code>函数接受输入特征<code>x</code>，输入的卷积核数量<code>input_filter</code>和输出的卷积核数量<code>output_filter</code>作为参数，然后构建一个残差块，并返回处理后的输出特征。</p><p>具体实现过程如下：</p><ol><li>使用一个3x3大小的卷积核，输出通道数为<code>output_filter</code>，步长为1，填充方式为’same’进行卷积操作，并接上BatchNormalization层和ReLU激活函数。</li><li>再次使用一个3x3大小的卷积核，输出通道数为<code>output_filter</code>，步长为1，填充方式为’same’进行卷积操作，并接上BatchNormalization层。</li><li>根据输入卷积核数量和输出卷积核数量是否相等，判断是否需要进行维度加减变换，如果相等则直接将输入特征作为恒等映射（identity），否则使用1x1的卷积核进行维度变换。</li><li>将恒等映射和经过两次卷积操作的特征相加，得到残差连接。</li><li>对残差连接的结果进行ReLU激活函数操作，最终输出处理后的特征。</li></ol><p>这段代码展示了如何实现一个简单的残差块，用于搭建深度残差神经网络，通过残差连接来解决深度神经网络训练中的梯度消失和梯度爆炸问题，帮助网络更好地训练和优化。</p><h3 id="残差网络的搭建"><a href="#残差网络的搭建" class="headerlink" title="残差网络的搭建"></a>残差网络的搭建</h3><p>残差网络的搭建分为两步：</p><ol><li>使用VGG公式搭建Plain VGG网络</li><li>在Plain VGG的卷积网络之间插入Identity Mapping，注意需要升维或者降维的时候加入$1×1$卷积。<br>在实现过程中，一般是直接stack残差块的方式。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">resnet_v1</span>(<span class="params">x</span>):</span><br><span class="line">    x = Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>), filters=<span class="number">16</span>, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">    x = res_block_v1(x, <span class="number">16</span>, <span class="number">16</span>)</span><br><span class="line">    x = res_block_v1(x, <span class="number">16</span>, <span class="number">32</span>)</span><br><span class="line">    x = Flatten()(x)</span><br><span class="line">    outputs = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>)(x)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure></li></ol><h3 id="为什么叫残差网络"><a href="#为什么叫残差网络" class="headerlink" title="为什么叫残差网络"></a>为什么叫残差网络</h3><p>在统计学中，残差和误差是非常容易混淆的两个概念。误差是衡量观测值和真实值之间的差距，残差是指预测值和观测值之间的差距。对于残差网络的命名原因，作者给出的解释是，网络的一层通常可以看做$y&#x3D;H(x)$, 而残差网络的一个残差块可以表示为$H(x)&#x3D;F(x)+x$，也就是$F(x)&#x3D;H(x)-x$，在单位映射中，$y&#x3D;x$便是观测值，而$H(x)$是预测值，所以$F(x)$便对应着残差，因此叫做残差网络。</p><h3 id="略"><a href="#略" class="headerlink" title="略"></a>略</h3><h3 id="将激活函数移动到残差部分可以提高模型的精度"><a href="#将激活函数移动到残差部分可以提高模型的精度" class="headerlink" title="将激活函数移动到残差部分可以提高模型的精度"></a>将激活函数移动到残差部分可以提高模型的精度</h3><p>该网络一般就在resnet_v2，keras实现如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">res_block_v2</span>(<span class="params">x, input_filter, output_filter</span>):</span><br><span class="line">    res_x = BatchNormalization()(x)</span><br><span class="line">    res_x = Activation(<span class="string">&#x27;relu&#x27;</span>)(res_x)</span><br><span class="line">    res_x = Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>), filters=output_filter, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)(res_x)</span><br><span class="line">    res_x = BatchNormalization()(res_x)</span><br><span class="line">    res_x = Activation(<span class="string">&#x27;relu&#x27;</span>)(res_x)</span><br><span class="line">    res_x = Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>), filters=output_filter, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)(res_x)</span><br><span class="line">    <span class="keyword">if</span> input_filter == output_filter:</span><br><span class="line">        identity = x</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment">#需要升维或者降维</span></span><br><span class="line">        identity = Conv2D(kernel_size=(<span class="number">1</span>,<span class="number">1</span>), filters=output_filter, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">    output= keras.layers.add([identity, res_x])</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet_v2</span>(<span class="params">x</span>):</span><br><span class="line">    x = Conv2D(kernel_size=(<span class="number">3</span>,<span class="number">3</span>), filters=<span class="number">16</span> , strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">    x = res_block_v2(x, <span class="number">16</span>, <span class="number">16</span>)</span><br><span class="line">    x = res_block_v2(x, <span class="number">16</span>, <span class="number">32</span>)</span><br><span class="line">    x = BatchNormalization()(x)</span><br><span class="line">    y = Flatten()(x)</span><br><span class="line">    outputs = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>)(y)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure><h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线*******************"></a>分割线*******************</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tagLink&quot;&gt;&lt;a class=&quot;link-card&quot; title=&quot;详解残差网络&quot; href=&quot;https://zhuanlan.zhihu.com/p/42706477&quot;&gt;&lt;span class=&quot;link-card-backdrop&quot; style</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>蓝桥杯stm32学习笔记（八）：模数转换ADC</title>
    <link href="http://tumytime.github.io/2024/03/18/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E6%A8%A1%E6%95%B0%E8%BD%AC%E6%8D%A2ADC/"/>
    <id>http://tumytime.github.io/2024/03/18/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E6%A8%A1%E6%95%B0%E8%BD%AC%E6%8D%A2ADC/</id>
    <published>2024-03-18T12:27:33.000Z</published>
    <updated>2024-03-19T09:16:54.795Z</updated>
    
    <content type="html"><![CDATA[<h3 id="CubeMX配置"><a href="#CubeMX配置" class="headerlink" title="CubeMX配置"></a>CubeMX配置</h3><h4 id="配置引脚"><a href="#配置引脚" class="headerlink" title="配置引脚"></a>配置引脚</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2h82d2oxha.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2h82d2oxha.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>我们这里先只用R37</p><p>配置<code>PB15</code>为<code>ADC2_IN15</code></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.6t6vkmcqb6.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.6t6vkmcqb6.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>选择<code>Single_ended</code></p><h4 id="生成工程"><a href="#生成工程" class="headerlink" title="生成工程"></a>生成工程</h4><p><strong>点击右上角”GENERATE CODE”,生成工程</strong></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="aadc-c"><a href="#aadc-c" class="headerlink" title="aadc.c"></a>aadc.c</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;aadc.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">double</span> <span class="title function_">getADC</span><span class="params">(ADC_HandleTypeDef *pin)</span></span><br><span class="line">&#123;</span><br><span class="line">uint adc;</span><br><span class="line">HAL_ADC_Start (pin);</span><br><span class="line">adc = HAL_ADC_GetValue(pin);</span><br><span class="line"><span class="keyword">return</span> adc*<span class="number">3.3</span>/<span class="number">4096</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="aadc-h"><a href="#aadc-h" class="headerlink" title="aadc.h"></a>aadc.h</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;main.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">double</span> <span class="title function_">getADC</span><span class="params">(ADC_HandleTypeDef *pin)</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个函数 <code>getADC</code> 是一个用于从ADC（模拟到数字转换器）读取模拟信号并将其转换为电压值的函数。让我们一步步地分析这个函数：</p><ol><li><strong>函数签名</strong>:</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> <span class="title function_">getADC</span><span class="params">(ADC_HandleTypeDef *pin)</span></span><br></pre></td></tr></table></figure><ul><li><code>double</code>: 函数的返回类型是<code>double</code>，这意味着它将返回一个浮点数。</li><li><code>ADC_HandleTypeDef *pin</code>: 函数接受一个指向<code>ADC_HandleTypeDef</code>类型的指针，这个指针指向一个ADC句柄，它包含了ADC的配置信息和状态信息。</li></ul><ol start="2"><li><strong>函数体</strong>:</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> uint adc;</span><br><span class="line"> HAL_ADC_Start (pin);</span><br><span class="line"> adc = HAL_ADC_GetValue(pin);</span><br><span class="line"> <span class="keyword">return</span> adc*<span class="number">3.3</span>/<span class="number">4096</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>uint adc;</code>: 定义了一个无符号整数变量<code>adc</code>，用于存储从ADC读取的原始值。</li><li><code>HAL_ADC_Start (pin);</code>: 调用HAL库（硬件抽象层库）中的<code>HAL_ADC_Start</code>函数来启动指定的ADC。这个函数接受一个ADC句柄（即<code>pin</code>）作为参数。</li><li><code>adc = HAL_ADC_GetValue(pin);</code>: 在ADC转换完成后，调用<code>HAL_ADC_GetValue</code>函数来获取转换后的ADC值，并将其存储在<code>adc</code>变量中。</li><li><code>return adc*3.3/4096;</code>: 返回转换后的电压值。这里假设ADC是一个12位的ADC（因此最大值是4095或4096，取决于具体的实现和计数方式），其参考电压是3.3V。因此，<code>adc*3.3/4096</code>这个公式将ADC的原始读数转换成了相应的电压值。</li></ul><p>总之，这个函数的主要目的是从指定的ADC读取模拟信号，并将其转换为一个表示电压的浮点数。这个电压值是基于ADC的参考电压（在这个例子中是3.3V）和ADC的位数（在这个例子中是12位）来计算的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;CubeMX配置&quot;&gt;&lt;a href=&quot;#CubeMX配置&quot; class=&quot;headerlink&quot; title=&quot;CubeMX配置&quot;&gt;&lt;/a&gt;CubeMX配置&lt;/h3&gt;&lt;h4 id=&quot;配置引脚&quot;&gt;&lt;a href=&quot;#配置引脚&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
  </entry>
  
  <entry>
    <title>蓝桥杯stm32学习笔记（七）：输入捕获（频率，占空比测量）</title>
    <link href="http://tumytime.github.io/2024/03/18/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E8%BE%93%E5%85%A5%E6%8D%95%E8%8E%B7%EF%BC%88%E9%A2%91%E7%8E%87%EF%BC%8C%E5%8D%A0%E7%A9%BA%E6%AF%94%E6%B5%8B%E9%87%8F%EF%BC%89/"/>
    <id>http://tumytime.github.io/2024/03/18/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E8%BE%93%E5%85%A5%E6%8D%95%E8%8E%B7%EF%BC%88%E9%A2%91%E7%8E%87%EF%BC%8C%E5%8D%A0%E7%A9%BA%E6%AF%94%E6%B5%8B%E9%87%8F%EF%BC%89/</id>
    <published>2024-03-18T09:03:06.000Z</published>
    <updated>2024-03-19T08:58:06.330Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>跳线帽拔了不能烧工程。。。。(好像可以。。。那天不知道怎么了板子抽风)</p></blockquote><h3 id="CubeMX配置"><a href="#CubeMX配置" class="headerlink" title="CubeMX配置"></a>CubeMX配置</h3><h4 id="配置引脚"><a href="#配置引脚" class="headerlink" title="配置引脚"></a>配置引脚</h4><p><strong>我们这里使用<code>PA7</code>进行捕获</strong></p><p><strong>配置<code>PA7</code>为<code>TIM17_CH1</code></strong><br>(只有一个通道没关系，我的题目里不用测占空比，但是我后面会写加上测占空比的引脚和程序的)</p><ul><li>配置一下引脚  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.5j3yd4e8d4.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.5j3yd4e8d4.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li><li>使能定时器中断  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7awx810hqy.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7awx810hqy.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li></ul><h4 id="生成工程"><a href="#生成工程" class="headerlink" title="生成工程"></a>生成工程</h4><p><strong>点击右上角”GENERATE CODE”,生成工程</strong></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="中断函数"><a href="#中断函数" class="headerlink" title="中断函数"></a>中断函数</h4><p><strong>interrupt.c中：</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">uint ccrl_val=<span class="number">0</span>;</span><br><span class="line">uint frq=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">HAL_TIM_IC_CaptureCallback</span><span class="params">(TIM_HandleTypeDef *htim)</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>中断回调函数名记不住的话和按键那一章一样，在tim.h文件里找</p><details open><summary pointer> 中断回调函数 </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">HAL_TIM_IC_CaptureCallback</span><span class="params">(TIM_HandleTypeDef *htim)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(htim-&gt;Instance==TIM17)</span><br><span class="line">&#123;</span><br><span class="line">ccrl_val = HAL_TIM_ReadCapturedValue(htim,TIM_CHANNEL_1);</span><br><span class="line">frq=(<span class="number">80000000</span>/<span class="number">80</span>)/ccrl_val;</span><br><span class="line">__HAL_TIM_SetCounter(htim,<span class="number">0</span>);</span><br><span class="line">HAL_TIM_IC_Start(htim,TIM_CHANNEL_1);<span class="comment">//IC:Input Capture</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>              </div>            </details><blockquote><p>注意自己写的中断回调函数有什么用，如果不写自己的回调函数，已设置的中断照样正常运行，自己的函数是用来特殊化一些中断流程的，没有特殊化的仍旧按照默认正常运行</p></blockquote><blockquote><p><strong>原理解释:</strong><br>当TIM17的中断触发(因为配置了上升沿触发，即当检测到上升沿时)<br>进入中断回调函数<br>因为最后一行才启动定时器的输入捕获通道1<br>所以第一次触发后，计数器归0(__HAL_TIM_SetCounter(htim,0);)<br>启动定时器的输入捕获通道1,开始计数<br>第二次触发中断(即第二次上升沿)<br>ccrl_val读取到两个上升沿间隔(因为第一个上升沿才开始计数)<br>所以频率等于时钟主频除以分频系数除以周期计数<br>重新启动定时器的输入捕获通道1</p></blockquote><h4 id="main-c中配置"><a href="#main-c中配置" class="headerlink" title="main.c中配置"></a>main.c中配置</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> uint frq;</span><br><span class="line">uchar pa1_duty=<span class="number">10</span>;<span class="comment">//初始化占空比</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>main函数里的初始化:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HAL_TIM_Base_Start_IT(&amp;htim4 );<span class="comment">//按键的定时器</span></span><br><span class="line">HAL_TIM_PWM_Start(&amp;htim2,TIM_CHANNEL_2);<span class="comment">//PA1的PWM输出开启</span></span><br><span class="line"></span><br><span class="line">HAL_TIM_IC_Start_IT(&amp;htim17,TIM_CHANNEL_1);<span class="comment">//频率测量捕获定时器开启</span></span><br><span class="line"></span><br><span class="line">__HAL_TIM_SetCompare(&amp;htim2,TIM_CHANNEL_2,pa1_duty);<span class="comment">//设置初始pwm频率</span></span><br></pre></td></tr></table></figure><h3 id="同时测频率和占空比："><a href="#同时测频率和占空比：" class="headerlink" title="同时测频率和占空比："></a>同时测频率和占空比：</h3><h4 id="引脚配置"><a href="#引脚配置" class="headerlink" title="引脚配置"></a>引脚配置</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.41xtci74hr.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.41xtci74hr.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/////////////////////////////测量频率+占空比///////////////////</span></span><br><span class="line"><span class="type">double</span> ccr1_val1a=<span class="number">0</span>,ccr1_val2a=<span class="number">0</span>;</span><br><span class="line">uint ccr1_val1b=<span class="number">0</span>,ccr1_val2b=<span class="number">0</span>;</span><br><span class="line">uint frq1=<span class="number">0</span>,frq2=<span class="number">0</span>;<span class="comment">//频率</span></span><br><span class="line"><span class="type">float</span> duty1=<span class="number">0</span>,duty2=<span class="number">0</span>;<span class="comment">//占空比</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">HAL_TIM_IC_CaptureCallback</span><span class="params">(TIM_HandleTypeDef *htim)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(htim-&gt;Instance==TIM17)<span class="comment">//PA7</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">//if(htim-&gt;Channel==HAL_TIM_ACTIVE_CHANNEL_1)//中断消息来源 选择直接输入的通道</span></span><br><span class="line"><span class="comment">//&#123;</span></span><br><span class="line">ccr1_val1a=HAL_TIM_ReadCapturedValue(htim,TIM_CHANNEL_1);<span class="comment">//直接</span></span><br><span class="line"><span class="comment">//ccr1_val1b=HAL_TIM_ReadCapturedValue(htim,TIM_CHANNEL_2);//间接</span></span><br><span class="line">__HAL_TIM_SetCounter(htim,<span class="number">0</span>);</span><br><span class="line">frq1=(<span class="number">80000000</span>/<span class="number">80</span>)/ccr1_val1a;</span><br><span class="line"><span class="comment">//duty1=(ccr1_val1b/ccr1_val1a)*100;</span></span><br><span class="line">HAL_TIM_IC_Start(htim,TIM_CHANNEL_1);</span><br><span class="line"><span class="comment">//HAL_TIM_IC_Start(htim,TIM_CHANNEL_2);</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(htim-&gt;Instance==TIM3)<span class="comment">//PB4</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(htim-&gt;Channel==HAL_TIM_ACTIVE_CHANNEL_1)<span class="comment">//中断消息来源 选择直接输入的通道</span></span><br><span class="line">&#123;</span><br><span class="line">ccr1_val2a=HAL_TIM_ReadCapturedValue(htim,TIM_CHANNEL_1);</span><br><span class="line">ccr1_val2b=HAL_TIM_ReadCapturedValue(htim,TIM_CHANNEL_2);</span><br><span class="line">__HAL_TIM_SetCounter(htim,<span class="number">0</span>);</span><br><span class="line">frq2=(<span class="number">80000000</span>/<span class="number">80</span>)/ccr1_val2a;</span><br><span class="line">duty2=(ccr1_val2b/ccr1_val2a)*<span class="number">100</span>;</span><br><span class="line">HAL_TIM_IC_Start(htim,TIM_CHANNEL_1);</span><br><span class="line">HAL_TIM_IC_Start(htim,TIM_CHANNEL_2);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;跳线帽拔了不能烧工程。。。。(好像可以。。。那天不知道怎么了板子抽风)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;CubeMX配置&quot;&gt;&lt;a href=&quot;#CubeMX配置&quot; class=&quot;headerlink&quot; title=&quot;CubeMX</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    <category term="stm32" scheme="http://tumytime.github.io/tags/stm32/"/>
    
    <category term="蓝桥杯" scheme="http://tumytime.github.io/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"/>
    
  </entry>
  
  <entry>
    <title>蓝桥杯stm32学习笔记（六）：PWM输出</title>
    <link href="http://tumytime.github.io/2024/03/17/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9APWM%E8%BE%93%E5%87%BA/"/>
    <id>http://tumytime.github.io/2024/03/17/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9APWM%E8%BE%93%E5%87%BA/</id>
    <published>2024-03-17T11:01:43.000Z</published>
    <updated>2024-03-19T08:39:12.112Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>PWM的占空比改变的是CCR寄存器的值（不同通道对应不同的CCR），频率的改变对应的是ARR寄存器的值</p></blockquote><h3 id="CubeMX配置"><a href="#CubeMX配置" class="headerlink" title="CubeMX配置"></a>CubeMX配置</h3><h4 id="配置引脚"><a href="#配置引脚" class="headerlink" title="配置引脚"></a>配置引脚</h4><blockquote><p>频率是指PWM信号的周期性重复频率，即PWM信号在一段时间内完整周期重复的次数。频率与占空比和自动重载值之间存在以下关系：</p><ol><li>PWM信号的频率 &#x3D; 1 &#x2F; PWM信号的周期</li><li>PWM信号的周期 &#x3D; 自动重载值 + 1</li><li>PWM信号的占空比 &#x3D; 高电平时间 &#x2F; PWM信号的周期</li></ol></blockquote><p><strong>我们这里配置PC9输出PWM波</strong><br>配置<code>PC9</code>引脚为<code>TIM3_CH4</code>,选择定时器<code>TIM3</code>的通道4(有哪个用哪个)<br>(后面带<code>N</code>的是互补PWM波)</p><blockquote><p>PWM频率 &#x3D; 1 &#x2F; (周期时间)<br>单个脉冲宽度 &#x3D; (占空比) * (周期时间)</p></blockquote><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.ibvk6580f.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.ibvk6580f.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="生成工程"><a href="#生成工程" class="headerlink" title="生成工程"></a>生成工程</h4><p><strong>点击右上角”GENERATE CODE”,生成工程</strong></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="打开定时器"><a href="#打开定时器" class="headerlink" title="打开定时器"></a>打开定时器</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HAL_TIM_PWM_Start(&amp;htim3,TIM_CHANNEL_4);</span><br></pre></td></tr></table></figure><h4 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h4><details open><summary pointer> while(1) </summary>              <div class='content'>              <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">  &#123;</span><br><span class="line">LED_Disp(<span class="number">0x00</span>);<span class="comment">//LED的初始化</span></span><br><span class="line"><span class="keyword">if</span>(key[<span class="number">2</span>].single_flag==<span class="number">1</span>) &#123;</span><br><span class="line"></span><br><span class="line">w+=<span class="number">1000</span>;</span><br><span class="line"><span class="keyword">if</span>(w&gt;<span class="number">10000</span>)</span><br><span class="line">&#123;</span><br><span class="line">w=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">TIM3-&gt;CCR4 = w;</span><br><span class="line">key[<span class="number">2</span>].single_flag=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* USER CODE END WHILE */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* USER CODE BEGIN 3 */</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>              </div>            </details>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;PWM的占空比改变的是CCR寄存器的值（不同通道对应不同的CCR），频率的改变对应的是ARR寄存器的值&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;CubeMX配置&quot;&gt;&lt;a href=&quot;#CubeMX配置&quot; class=&quot;headerlin</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    <category term="stm32" scheme="http://tumytime.github.io/tags/stm32/"/>
    
    <category term="蓝桥杯" scheme="http://tumytime.github.io/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"/>
    
  </entry>
  
  <entry>
    <title>蓝桥杯stm32学习笔记（五）：按键</title>
    <link href="http://tumytime.github.io/2024/03/16/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E6%8C%89%E9%94%AE/"/>
    <id>http://tumytime.github.io/2024/03/16/%E8%93%9D%E6%A1%A5%E6%9D%AFstm32%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E6%8C%89%E9%94%AE/</id>
    <published>2024-03-16T10:24:00.000Z</published>
    <updated>2024-03-17T11:01:12.237Z</updated>
    
    <content type="html"><![CDATA[<h2 id="短按键"><a href="#短按键" class="headerlink" title="短按键"></a>短按键</h2><h3 id="电路图"><a href="#电路图" class="headerlink" title="电路图"></a>电路图</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.1lbkuno8bo.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.1lbkuno8bo.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>按键按下后接地变为低电平，未按下为高电平；</p><h4 id="不用定时器的简单按键："><a href="#不用定时器的简单按键：" class="headerlink" title="不用定时器的简单按键："></a>不用定时器的简单按键：</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_0)==GPIO_PIN_RESET ) &#123;</span><br><span class="line">HAL_GPIO_WritePin(GPIOC,GPIO_PIN_8,GPIO_PIN_RESET );</span><br><span class="line">HAL_GPIO_WritePin(GPIOD,GPIO_PIN_2,GPIO_PIN_SET);</span><br><span class="line">HAL_GPIO_WritePin(GPIOD,GPIO_PIN_2,GPIO_PIN_RESET);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">HAL_GPIO_WritePin(GPIOC,GPIO_PIN_8,GPIO_PIN_SET );</span><br><span class="line">HAL_GPIO_WritePin(GPIOD,GPIO_PIN_2,GPIO_PIN_SET);</span><br><span class="line">HAL_GPIO_WritePin(GPIOD,GPIO_PIN_2,GPIO_PIN_RESET);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CubeMX配置"><a href="#CubeMX配置" class="headerlink" title="CubeMX配置"></a>CubeMX配置</h3><h4 id="引脚配置"><a href="#引脚配置" class="headerlink" title="引脚配置"></a>引脚配置</h4><p>配置<code>PB0-2</code>和<code>PA0</code>为<code>GPIO_Input</code><br>并将<code>GPIO Pull-up/Pull-down</code>配置为<code>Pull-up</code></p><h4 id="定时器配置"><a href="#定时器配置" class="headerlink" title="定时器配置"></a>定时器配置</h4><p>选一个定时器（这里选择TIM4）</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7smyutv65f.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7smyutv65f.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>配置时钟源为内部时钟</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.wibapqvqk.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.wibapqvqk.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><details open><summary pointer> 选项解释 </summary>              <div class='content'>              <ol><li><p><strong>Prescaler (PSC-16 bits value)</strong>:</p><ul><li>Prescaler是用于将输入时钟频率进行分频的参数，以降低计数器的工作频率。16位值表示了分频比，用于控制计数器每次计数之前如何分频输入时钟。较大的分频比会使计数器工作在较低的频率下。例如，如果一个系统的输入时钟频率为10 MHz，而计数器需要以1 kHz的频率进行计数，那么可以通过设置适当的预分频器值来实现这一要求。假设我们设置预分频器的16位值为10000，在这种情况下，输入时钟在进入计数器之前会先进行10,000倍的分频。这样，每10,000个输入时钟周期，计数器才会计数一次，从而使得计数器的工作频率为1 kHz。不同的应用场景会有不同的计数需求。例如，某些应用可能需要高速计数，一种计数器的频率可能需要达到几十MHz甚至更高的频率。在这种情况下，计数器需要以更高的速率进行计数，以满足对计数精度和速度的要求。另一方面，一些应用可能只需要低速计数，比如在一些传感器监测系统中，计数器可以以较低的频率进行计数，以实时监测并记录事件发生的次数。</li></ul></li><li><p><strong>Counter Mode</strong>:</p><ul><li>此处设置计数器的工作模式为”Up”，即计数器会从0开始递增计数，计数到最大值后重新从0开始。</li></ul></li><li><p><strong>Dithering</strong>:</p><ul><li>在这里设置了禁用抖动（Dithering），抖动是指通过微小的随机变化来减小量化误差的一种技术。在这种情况下，抖动被禁用，即不会在计数器中引入这种微小的变化。</li></ul></li><li><p><strong>Counter Period (AutoReload Register)</strong>:</p><ul><li>设置计数器的计数周期，通常通过AutoReload Register（自动重装载寄存器）来实现。在这里设置了计数器的周期为0到65535之间的值，当计数器达到最大值时会重新加载初始值。</li></ul></li><li><p><strong>Internal Clock Division (CKD)</strong>:</p><ul><li>设置内部时钟分频（CKD），在这里选择了”No Division”，表示计数器的时钟不会被分频，以确保计数器运行在输入时钟的最高频率下。</li></ul></li><li><p><strong>Auto-reload preload</strong>:</p><ul><li>在这里禁用了自动加载预设值功能，即不会在计数器自动重新加载时预先装载新的值。</li></ul></li></ol><p>这些设置有助于调整计时器&#x2F;计数器的行为和性能，例如调整计数模式、周期以及时钟分频等，以满足特定的应用需求。通过合理设置这些参数，可以有效地控制计时器&#x2F;计数器的功能，确保其在系统中正确、稳定地运行。</p>              </div>            </details><ol><li><p><strong>Prescaler</strong>:分频系数，决定定时器的工作频率<br> 定时器工作频率&#x3D;外部总线频率(80MHz)&#x2F;(PSC+1)<br> 这里设置为80-1,即定时器工作频率&#x3D;80，000，000&#x2F;80&#x3D;1，000，000</p></li><li><p><strong>Counter Period</strong>:<br> 定时频率&#x3D;定时器工作频率&#x2F;counter<br> 这里设置为10000-1,即定时频率&#x3D;1，000，000&#x2F;10，000&#x3D;100Hz，即定时周期10ms;<br> 10ms中断一次；</p></li></ol><p><strong>使能中断</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4n7gvyvfe6.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4n7gvyvfe6.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="生成工程"><a href="#生成工程" class="headerlink" title="生成工程"></a>生成工程</h4><p><strong>点击右上角”GENERATE CODE”,生成工程</strong></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><h4 id="新建两个文件"><a href="#新建两个文件" class="headerlink" title="新建两个文件"></a>新建两个文件</h4><p>保存<code>interrupt.c</code>和<code>interrupt.h</code>到<code>bsp</code>文件夹<br>然后添加<code>interrupt.c</code>到项目<code>bsp</code>文件夹里</p><h4 id="写中断回调函数"><a href="#写中断回调函数" class="headerlink" title="写中断回调函数"></a>写中断回调函数</h4><p>记不住函数名复制这个:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.wibaqozwy.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.wibaqozwy.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="interrupt-h"><a href="#interrupt-h" class="headerlink" title="interrupt.h"></a>interrupt.h</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _INTERRUPT_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _INTERRUPT_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;main.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;stdbool.h&quot;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">keys</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">uchar judge;</span><br><span class="line"><span class="type">bool</span> status;</span><br><span class="line"><span class="type">bool</span> single_flag;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><h4 id="interrupt-c"><a href="#interrupt-c" class="headerlink" title="interrupt.c"></a>interrupt.c</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;interrupt.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">keys</span> <span class="title">key</span>[4]=</span> &#123;&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>&#125;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">HAL_TIM_PeriodElapsedCallback</span><span class="params">(TIM_HandleTypeDef *htim)</span> &#123;</span><br><span class="line"></span><br><span class="line">key[<span class="number">0</span>].status=HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_0);</span><br><span class="line">key[<span class="number">1</span>].status=HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_1);</span><br><span class="line">key[<span class="number">2</span>].status=HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_2);</span><br><span class="line">key[<span class="number">3</span>].status=HAL_GPIO_ReadPin (GPIOA,GPIO_PIN_0);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(htim-&gt;Instance==TIM4) &#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">4</span>; i++) </span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">switch</span>(key[i].judge)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(key[i].status==<span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">key[i].judge=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(key[i].status==<span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">key[i].judge=<span class="number">2</span>;</span><br><span class="line">key[i].single_flag=<span class="number">1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;key[i].judge=<span class="number">0</span>;&#125;</span><br><span class="line"></span><br><span class="line">&#125;<span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(key[i].status==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">key[i].judge=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;<span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="main-c中extern结构体-打开中断"><a href="#main-c中extern结构体-打开中断" class="headerlink" title="main.c中extern结构体&#x2F;打开中断"></a>main.c中extern结构体&#x2F;打开中断</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">keys</span> <span class="title">key</span>[];</span></span><br></pre></td></tr></table></figure><p><strong>main函数里：</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HAL_TIM_Base_Start_IT(&amp;htim4 );</span><br></pre></td></tr></table></figure><blockquote><p>一定要放在<code>MX_TIM4_Init();</code>后面！！！！！！！！！！！</p></blockquote><blockquote><p>启动定时器 TIM4 的基本定时器模式并使能定时器中断.</p></blockquote><h2 id="长按键"><a href="#长按键" class="headerlink" title="长按键"></a>长按键</h2><h3 id="interrupt-h-1"><a href="#interrupt-h-1" class="headerlink" title="interrupt.h"></a>interrupt.h</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _INTERRUPT_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _INTERRUPT_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;main.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;stdbool.h&quot;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">keys</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">uchar judge;</span><br><span class="line"><span class="type">bool</span> status;</span><br><span class="line"><span class="type">bool</span> single_flag;</span><br><span class="line"><span class="type">bool</span> long_flag;</span><br><span class="line">uint time;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><h3 id="interrupt-c-1"><a href="#interrupt-c-1" class="headerlink" title="interrupt.c"></a>interrupt.c</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;interrupt.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">keys</span> <span class="title">key</span>[4]=</span> &#123;&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="literal">false</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">HAL_TIM_PeriodElapsedCallback</span><span class="params">(TIM_HandleTypeDef *htim)</span> &#123;</span><br><span class="line"></span><br><span class="line">key[<span class="number">0</span>].status=HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_0);</span><br><span class="line">key[<span class="number">1</span>].status=HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_1);</span><br><span class="line">key[<span class="number">2</span>].status=HAL_GPIO_ReadPin (GPIOB,GPIO_PIN_2);</span><br><span class="line">key[<span class="number">3</span>].status=HAL_GPIO_ReadPin (GPIOA,GPIO_PIN_0);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(htim-&gt;Instance==TIM4) &#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">4</span>; i++) &#123;</span><br><span class="line"><span class="keyword">switch</span>(key[i].judge) &#123;</span><br><span class="line"><span class="keyword">case</span> <span class="number">0</span>: &#123;</span><br><span class="line"><span class="keyword">if</span>(key[i].status==<span class="number">0</span>) &#123;</span><br><span class="line">key[i].judge=<span class="number">1</span>;</span><br><span class="line">key[i].time =<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">1</span>: &#123;</span><br><span class="line"><span class="keyword">if</span>(key[i].status==<span class="number">0</span>) &#123;</span><br><span class="line">key[i].judge=<span class="number">2</span>;</span><br><span class="line"><span class="comment">//key[i].single_flag=1;</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">key[i].judge=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="number">2</span>: &#123;</span><br><span class="line"><span class="keyword">if</span>(key[i].status==<span class="number">1</span>) &#123;</span><br><span class="line">key[i].judge=<span class="number">0</span>;</span><br><span class="line">key[i].single_flag=<span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span>(key[i].time&lt;<span class="number">200</span>)</span><br><span class="line">&#123;</span><br><span class="line">key[i].long_flag=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">key[i].time++;</span><br><span class="line"><span class="keyword">if</span>(key[i].time&gt;<span class="number">200</span>)</span><br><span class="line">&#123;</span><br><span class="line">key[i].long_flag=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>key[i].time&gt;200:</strong><br>之前配置的定时器一个周期10ms,<strong>200也就是2s</strong></p><h2 id="函数封装"><a href="#函数封装" class="headerlink" title="函数封装"></a>函数封装</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">char</span>  view=<span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">key_proc</span><span class="params">()</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">disp_proc</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">key_proc</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(key[<span class="number">0</span>].single_flag==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">key[<span class="number">0</span>].single_flag =<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(key[<span class="number">1</span>].single_flag==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">view++;</span><br><span class="line"><span class="keyword">if</span>(view&gt;<span class="number">2</span>)</span><br><span class="line">&#123;</span><br><span class="line">view=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">key[<span class="number">1</span>].single_flag =<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(key[<span class="number">2</span>].single_flag==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">key[<span class="number">2</span>].single_flag =<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(key[<span class="number">3</span>].single_flag==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">key[<span class="number">3</span>].single_flag =<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">disp_proc</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(view==<span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> text[<span class="number">30</span>];</span><br><span class="line"><span class="built_in">sprintf</span>(text,<span class="string">&quot;  view=0      &quot;</span>);</span><br><span class="line">LCD_DisplayStringLine(Line9, (<span class="type">uint8_t</span> *)text);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(view==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> text[<span class="number">30</span>];</span><br><span class="line"><span class="built_in">sprintf</span>(text,<span class="string">&quot;  view=1      &quot;</span>);</span><br><span class="line">LCD_DisplayStringLine(Line9, (<span class="type">uint8_t</span> *)text);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(view==<span class="number">2</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">char</span> text[<span class="number">30</span>];</span><br><span class="line"><span class="built_in">sprintf</span>(text,<span class="string">&quot;  view=2      &quot;</span>);</span><br><span class="line">LCD_DisplayStringLine(Line9, (<span class="type">uint8_t</span> *)text);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;短按键&quot;&gt;&lt;a href=&quot;#短按键&quot; class=&quot;headerlink&quot; title=&quot;短按键&quot;&gt;&lt;/a&gt;短按键&lt;/h2&gt;&lt;h3 id=&quot;电路图&quot;&gt;&lt;a href=&quot;#电路图&quot; class=&quot;headerlink&quot; title=&quot;电路图&quot;&gt;&lt;/a&gt;电路图&lt;/h</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    <category term="stm32" scheme="http://tumytime.github.io/tags/stm32/"/>
    
    <category term="蓝桥杯" scheme="http://tumytime.github.io/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"/>
    
  </entry>
  
  <entry>
    <title>STM32第二次考核</title>
    <link href="http://tumytime.github.io/2024/03/14/STM32%E7%AC%AC%E4%BA%8C%E6%AC%A1%E8%80%83%E6%A0%B8/"/>
    <id>http://tumytime.github.io/2024/03/14/STM32%E7%AC%AC%E4%BA%8C%E6%AC%A1%E8%80%83%E6%A0%B8/</id>
    <published>2024-03-14T12:41:37.000Z</published>
    <updated>2024-03-15T07:25:42.956Z</updated>
    
    <content type="html"><![CDATA[<p>要求：</p><h2 id="功能引脚概述"><a href="#功能引脚概述" class="headerlink" title="功能引脚概述"></a>功能引脚概述</h2><h3 id="PA1"><a href="#PA1" class="headerlink" title="PA1"></a>PA1</h3><p>PA1:PWM（频率、占空比可调节）</p><ol><li>低频模式: 输出信号频率为4KHz。</li><li>高频模式: 输出信号频率为8KHz。<br>PA1输出信号占空比可以通过电位器R37进行调节，关系如图2所示。<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/img/图片1.jpg" class="lazyload placeholder" data-srcset="/img/图片1.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li></ol><p>当模式切换时，在保证占空比不变的前提下，频率在5秒内均匀的升高或降低到目标频率，要求频率步进值小于200Hz</p><h3 id="PA7-频率测量"><a href="#PA7-频率测量" class="headerlink" title="PA7(频率测量)"></a>PA7(频率测量)</h3><p>PA7:脉冲捕获<br>测量输入到PA7 引脚的信号频率，并将其转换为速度值，速度值(v) 与频率值(f)的对应关系:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/img/图片2.jpg" class="lazyload placeholder" data-srcset="/img/图片2.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>其中f单位为Hz，R和K作为参数，可以通过按键进行调整，π取小数点后2位有效数字。</p><h3 id="ADC"><a href="#ADC" class="headerlink" title="ADC"></a>ADC</h3><p>ADC:检测电位器R37上输出的模拟电压信号</p><h2 id="显示"><a href="#显示" class="headerlink" title="显示"></a>显示</h2><blockquote><p>显示背景色 (BackColor):黑色<br>显示前景色(TextColor):白色.<br>数据项与对应的数据之间使用“&#x3D;”间隔开。</p></blockquote><h3 id="数据界面"><a href="#数据界面" class="headerlink" title="数据界面"></a>数据界面</h3><ol><li>LD1:处于数据界面，指示灯LD1点亮，否则熄灭。</li><li>LD2: 低频模式、高频模式切换期间，指示灯LD2以0.1秒为间隔切换亮、灭状态，模式切换完成后熄灭。</li><li>LD3:占空比调整处于 “锁定”状态时，指示灯LD3点亮，否则熄灭。</li></ol><blockquote><p>显示要素包括界面名称(DATA)、PWM 输出模式(M)、 实时占空比(P)、 实时速度(V)。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/img/图片3.jpg" class="lazyload placeholder" data-srcset="/img/图片3.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>实时速度取小数点后1位有效数字。<br>输出模式以“H”表示高频模式、“L”表示低频模式，模式切换未完成前，屏幕显示的输出模式保持不变。</p></blockquote><h3 id="参数界面"><a href="#参数界面" class="headerlink" title="参数界面"></a>参数界面</h3><p>显示要素包括界面名称(PARA)、参数R和K的当前值，R值和K值有效范围1-10,整数。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/img/图片4.jpg" class="lazyload placeholder" data-srcset="/img/图片4.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="统计界面"><a href="#统计界面" class="headerlink" title="统计界面"></a>统计界面</h3><p>显示要素包括:界面名称( RECD)、PWM输出模式切换次数(N)、高频和低频模式下的速度最大值。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/img/图片5.jpg" class="lazyload placeholder" data-srcset="/img/图片5.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>MH:高频模式最大速度，ML: 低频模式最大速度，显示保留小数点后1位有效数字。</p><h2 id="按键功能"><a href="#按键功能" class="headerlink" title="按键功能"></a>按键功能</h2><h3 id="B1"><a href="#B1" class="headerlink" title="B1"></a>B1</h3><p>定义为“界面”按键，按下B1按键可以往复切换数据、参数和记录三个界面，切换模式如图6所示。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="/img/图片6.png" class="lazyload placeholder" data-srcset="/img/图片6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="B2"><a href="#B2" class="headerlink" title="B2"></a>B2</h3><p>定义为 “选择”按键。</p><ol><li>在数据界面下，用于切换选择低频或高频模式。按键按下后，5秒内不可再次触发切换功能。</li><li>在参数界面下，按下B2按键，切换选择R或K参数。每次从数据界面进入参数界面，默认当前可调整的参数为R参数;从参数界面退出时，新的R参数和K参数生效。</li></ol><h3 id="B3"><a href="#B3" class="headerlink" title="B3"></a>B3</h3><p>定义为 “加”按键。<br>在参数界面下，按下B3按键，当前可调整的参数加1，参数调整模式:<br>… 1 2 3 4 … 10 1 2 3 …</p><h3 id="B4"><a href="#B4" class="headerlink" title="B4"></a>B4</h3><ol><li>在参数界面下，按下B4按键，当前可调整的参数减1,参数调整模式· · ·1  10  9 · · · 2  1  10  9  ··· · ·</li><li>在数据界面下，长按B4按键超过2秒后松开(长按键)，可以“锁定“占空比调整功能，此时输出信号占空比保持不变，不受R37电位器输出电压控制;处于“锁定”状态后，再次按下B4按键(短按键),实现“解锁”功能，恢复R37电位器对输出信号占空比的控制。.</li></ol><p><strong>要求:</strong></p><ul><li>按键应进行有效的防抖处理，避免出现一次按键动作 触发多次功能等情形。</li><li>按键动作不应影响数据采集过程和屏幕显示效果。</li><li>有效区分长、短按键功能，互不影响。</li><li>参数调整应考虑边界值，不出现无效参数。</li><li>当前界面下无功能的按键按下，不触发其它界面的功能。</li></ul><h2 id="统计功能"><a href="#统计功能" class="headerlink" title="统计功能"></a>统计功能</h2><ol><li>低频模式、高频模式切换次数(N)。</li><li>高频、低频输出模式下的最大速度分开统计,保持时间不足2秒的速度值不纳入统计。</li></ol><h2 id="LED"><a href="#LED" class="headerlink" title="LED"></a>LED</h2><p>LD4-LD8 指示灯始终处于熄灭状态。</p><h2 id="初始状态说明"><a href="#初始状态说明" class="headerlink" title="初始状态说明"></a>初始状态说明</h2><ol><li>参数R为1。</li><li>参数K为1。</li><li>切换次数N 为0。</li><li>PWM输出模式为低频模式。</li><li>处于“解锁”状态，R37电位器可以控制信号占空比。</li><li>处于数据显示界面。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;要求：&lt;/p&gt;
&lt;h2 id=&quot;功能引脚概述&quot;&gt;&lt;a href=&quot;#功能引脚概述&quot; class=&quot;headerlink&quot; title=&quot;功能引脚概述&quot;&gt;&lt;/a&gt;功能引脚概述&lt;/h2&gt;&lt;h3 id=&quot;PA1&quot;&gt;&lt;a href=&quot;#PA1&quot; class=&quot;headerlink&quot;</summary>
      
    
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/categories/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    
    <category term="嵌入式" scheme="http://tumytime.github.io/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    <category term="stm32" scheme="http://tumytime.github.io/tags/stm32/"/>
    
    <category term="蓝桥杯" scheme="http://tumytime.github.io/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/"/>
    
  </entry>
  
  <entry>
    <title>一.《动手学深度学习》Paddle版笔记-使用Tensor来处理数据</title>
    <link href="http://tumytime.github.io/2024/03/14/%E4%B8%80.%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8BPaddle%E7%89%88%E7%AC%94%E8%AE%B0-%E4%BD%BF%E7%94%A8Tensor%E6%9D%A5%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/"/>
    <id>http://tumytime.github.io/2024/03/14/%E4%B8%80.%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8BPaddle%E7%89%88%E7%AC%94%E8%AE%B0-%E4%BD%BF%E7%94%A8Tensor%E6%9D%A5%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/</id>
    <published>2024-03-14T07:13:52.000Z</published>
    <updated>2024-03-22T16:40:57.606Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>记录一下，如果文章在文件夹里改名字了，要再打开一次，要不然vscode里改的bug不影响这个文件。。。</p></blockquote><h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><h2 id="使用Tensor来处理数据"><a href="#使用Tensor来处理数据" class="headerlink" title="使用Tensor来处理数据"></a>使用Tensor来处理数据</h2><blockquote><p>“tensor”这个单词一般可译作“张量”，张量可以看作是一个多维数组。标量可以看作是0维张量，向量可以看作1维张量，矩阵可以看作是二维张量。</p></blockquote><h3 id="Tensor概念解释"><a href="#Tensor概念解释" class="headerlink" title="Tensor概念解释"></a>Tensor概念解释</h3><ul><li>飞桨使用张量（Tensor） 来表示神经网络中传递的数据</li><li>Tensor 可以理解为多维数组，类似于 Numpy 数组（ndarray） 的概念</li><li>与 Numpy 数组相比，Tensor 除了支持运行在 CPU 上，还支持运行在 GPU 及各种 AI 芯片上，以实现计算加速</li><li>飞桨基于 Tensor，实现了深度学习所必须的反向传播功能和多种多样的组网算子，从而可更快捷地实现深度学习组网与训练等功能</li></ul><h3 id="Tensor的创建"><a href="#Tensor的创建" class="headerlink" title="Tensor的创建"></a>Tensor的创建</h3><h4 id="指定数据创建"><a href="#指定数据创建" class="headerlink" title="指定数据创建"></a>指定数据创建</h4><p>与 Numpy 创建数组方式类似，通过给定 Python 序列（如列表 list、元组 tuple），可使用 paddle.to_tensor 创建任意维度的 Tensor</p><ol><li><p><strong>创建类似向量的1维Tensor</strong></p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> paddle</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ndim_1_Tensor = paddle.to_tensor([<span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ndim_1_Tensor)</span><br><span class="line">Tensor(shape=[<span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br></pre></td></tr></table></figure><p> ndim:维度<br> <strong>如果仅输入单个标量（scalar）数据（例如 float&#x2F;int&#x2F;bool 类型的单个元素），则会创建形状为 [1] 的 Tensor，即 0 维 Tensor：</strong></p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.to_tensor(<span class="number">2</span>)</span><br><span class="line">Tensor(shape=[], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.to_tensor([<span class="number">2</span>])</span><br><span class="line">Tensor(shape=[<span class="number">1</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [<span class="number">2</span>])</span><br></pre></td></tr></table></figure><blockquote><p>这两个有区别，维度不同，一个0维，一个1维</p></blockquote></li><li><p><strong>创建类似矩阵的2维Tensor</strong></p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ndim_2_Tensor = paddle.to_tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ndim_2_Tensor)</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">3</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ndim_2_Tensor = paddle.to_tensor([[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ndim_2_Tensor)</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ndim_2_Tensor = paddle.to_tensor([[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>],[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ndim_2_Tensor)</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>]])</span><br></pre></td></tr></table></figure></li><li><p><strong>创建3维Tensor</strong></p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ndim_3_Tensor = paddle.to_tensor([[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]],[[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(ndim_3_Tensor)</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]])</span><br></pre></td></tr></table></figure><p> 上述不同维度的 Tensor 可视化的表示如下图所示(数据可能不同，看个图示就行)：</p> <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.9rj5gz3k7w.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.9rj5gz3k7w.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><blockquote><p>需要注意的是，Tensor 必须形如矩形，即在任何一个维度上，元素的数量必须相等，否则会抛出异常，示例如下：<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = paddle.to_tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>]])</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">File <span class="string">&quot;C:\Users\lxcqm\anaconda3\envs\Paddle_Py3.12\Lib\site-packages\paddle\tensor\creation.py&quot;</span>, line <span class="number">794</span>, <span class="keyword">in</span> to_tensor</span><br><span class="line">    <span class="keyword">return</span> _to_tensor_non_static(data, dtype, place, stop_gradient)</span><br><span class="line">        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span><br><span class="line">File <span class="string">&quot;C:\Users\lxcqm\anaconda3\envs\Paddle_Py3.12\Lib\site-packages\paddle\tensor\creation.py&quot;</span>, line <span class="number">577</span>, <span class="keyword">in</span> _to_tensor_non_static</span><br><span class="line">    data = np.array(data)</span><br><span class="line">        ^^^^^^^^^^^^^^</span><br><span class="line">ValueError: setting an array element <span class="keyword">with</span> a sequence. The requested array has an inhomogeneous shape after <span class="number">1</span> dimensions. The detected shape was (<span class="number">2</span>,) + inhomogeneous part.</span><br></pre></td></tr></table></figure><br><strong>说明：</strong></p><ul><li>飞桨也支持将 Tensor 转换为 Python 序列数据，可通过 paddle.tolist 实现，飞桨实际的转换处理过程是 Python 序列 &lt;-&gt; Numpy 数组 &lt;-&gt; Tensor。</li><li>基于给定数据创建 Tensor 时，飞桨是通过拷贝方式创建，与原始数据不共享内存。</li></ul></blockquote></li></ol><h4 id="指定形状创建"><a href="#指定形状创建" class="headerlink" title="指定形状创建"></a>指定形状创建</h4><p>如果要创建一个指定形状的 Tensor，可以使用 paddle.zeros、paddle.ones、paddle.full 实现：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.zeros([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">W0314 <span class="number">17</span>:<span class="number">10</span>:<span class="number">06.231387</span>  <span class="number">9012</span> gpu_resources.cc:<span class="number">119</span>] Please NOTE: device: <span class="number">0</span>, GPU Compute Capability: <span class="number">8.9</span>, Driver API Version: <span class="number">12.4</span>, Runtime API Version: <span class="number">12.0</span></span><br><span class="line">W0314 <span class="number">17</span>:<span class="number">10</span>:<span class="number">08.771996</span>  <span class="number">9012</span> gpu_resources.cc:<span class="number">164</span>] device: <span class="number">0</span>, cuDNN Version: <span class="number">8.9</span>.</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.twos([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">AttributeError: module <span class="string">&#x27;paddle&#x27;</span> has no attribute <span class="string">&#x27;twos&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.full([<span class="number">2</span>,<span class="number">4</span>],<span class="number">4</span>)</span><br><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br></pre></td></tr></table></figure><h4 id="指定区间创建"><a href="#指定区间创建" class="headerlink" title="指定区间创建"></a>指定区间创建</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">paddle.arange(start, end, step)  <span class="comment"># 创建以步长 step 均匀分隔区间[start, end)的 Tensor</span></span><br><span class="line">paddle.linspace(start, stop, num) <span class="comment"># 创建以元素个数 num 均匀分隔区间[start, stop)的 Tensor</span></span><br></pre></td></tr></table></figure><p>实例:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.arange(start=<span class="number">1</span>, end=<span class="number">10</span>, step = <span class="number">2</span>)</span><br><span class="line">Tensor(shape=[<span class="number">5</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.linspace(start=<span class="number">1</span>,stop=<span class="number">10</span>,num=<span class="number">3</span>)</span><br><span class="line">Tensor(shape=[<span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">1.</span>        , <span class="number">5.50000000</span>, <span class="number">10.</span>       ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>paddle.linspace(start=<span class="number">0</span>,stop=<span class="number">10</span>,num=<span class="number">3</span>)</span><br><span class="line">Tensor(shape=[<span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">0.</span> , <span class="number">5.</span> , <span class="number">10.</span>])</span><br></pre></td></tr></table></figure><blockquote><p><strong>说明：</strong><br>除了以上指定数据、形状、区间创建 Tensor 的方法，飞桨还支持如下类似的创建方式，如：</p><ul><li>创建一个空 Tensor，即根据 shape 和 dtype 创建尚未初始化元素值的 Tensor，可通过 paddle.empty 实现。</li><li>创建一个与其他 Tensor 具有相同 <strong>shape</strong> 与 <strong>dtype</strong> 的 Tensor，可通过 paddle.ones_like 、 paddle.zeros_like 、 paddle.full_like 、paddle.empty_like 实现。</li><li>拷贝并创建一个与其他 Tensor 完全相同的 Tensor，可通过 paddle.<strong>clone</strong> 实现。</li><li>创建一个满足特定分布的 Tensor，如 paddle.rand, paddle.randn , paddle.randint 等。</li><li>通过设置随机种子创建 Tensor，可每次生成相同元素值的随机数 Tensor，可通过 paddle.seed 和 paddle.rand 组合实现。</li></ul></blockquote><h4 id="指定图像-文本数据创建"><a href="#指定图像-文本数据创建" class="headerlink" title="指定图像&#x2F;文本数据创建"></a>指定图像&#x2F;文本数据创建</h4><p>在常见深度学习任务中，数据样本可能是图片（image）、文本（text）、语音（audio）等多种类型，在送入神经网络训练或推理前，这些数据和对应的标签均需要创建为 Tensor。以下是图像场景和 NLP(自然语言处理) 场景中手动转换 Tensor 方法的介绍。</p><ul><li><p>对于图像场景，可使用 paddle.vision.transforms.ToTensor 直接将 PIL.Image 格式的数据转为 Tensor，使用 paddle.to_tensor 将图像的标签（Label，通常是 Python 或 Numpy 格式的数据）转为 Tensor。</p></li><li><p>对于文本场景，需将文本数据解码为数字后，再通过 paddle.to_tensor 转为 Tensor。不同文本任务标签形式不一样，有的任务标签也是文本，有的则是数字，均需最终通过 paddle.to_tensor 转为 Tensor。</p></li></ul><p>下面以图像场景为例介绍，以下示例代码中将随机生成的图片转换为 Tensor:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> paddle.vision.transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">import</span> paddle.vision.transforms.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">fake_img = Image.fromarray((np.random.rand(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>) * <span class="number">255.</span>).astype(np.uint8)) <span class="comment"># 创建随机图片</span></span><br><span class="line">fake_img.show()</span><br><span class="line">transform = T.ToTensor()</span><br><span class="line">tensor = transform(fake_img) <span class="comment"># 使用 ToTensor()将图片转换为 Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure><p>输出:</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4g48waay9i.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4g48waay9i.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">(Paddle_Py3<span class="number">.12</span>) C:\Users\lxcqm&gt;python D:\PyTorch\Pytorch1\main.py</span><br><span class="line">W0314 <span class="number">17</span>:<span class="number">25</span>:<span class="number">22.979338</span> <span class="number">34280</span> gpu_resources.cc:<span class="number">119</span>] Please NOTE: device: <span class="number">0</span>, GPU Compute Capability: <span class="number">8.9</span>, Driver API Version: <span class="number">12.4</span>, Runtime API Version: <span class="number">12.0</span></span><br><span class="line">W0314 <span class="number">17</span>:<span class="number">25</span>:<span class="number">22.984452</span> <span class="number">34280</span> gpu_resources.cc:<span class="number">164</span>] device: <span class="number">0</span>, cuDNN Version: <span class="number">8.9</span>.</span><br><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[[<span class="number">0.05098040</span>, <span class="number">0.00392157</span>, <span class="number">0.09019608</span>, ..., <span class="number">0.48627454</span>,</span><br><span class="line">          <span class="number">0.25882354</span>, <span class="number">0.21960786</span>],</span><br><span class="line">         [<span class="number">0.77254909</span>, <span class="number">0.82352948</span>, <span class="number">0.12549020</span>, ..., <span class="number">0.29411766</span>,</span><br><span class="line">          <span class="number">0.47450984</span>, <span class="number">0.99215692</span>],</span><br><span class="line">         [<span class="number">0.50980395</span>, <span class="number">0.90588242</span>, <span class="number">0.86666673</span>, ..., <span class="number">0.94509810</span>,</span><br><span class="line">          <span class="number">0.73725492</span>, <span class="number">0.40784317</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">0.59215689</span>, <span class="number">0.96470594</span>, <span class="number">0.12549020</span>, ..., <span class="number">0.43529415</span>,</span><br><span class="line">          <span class="number">0.34117648</span>, <span class="number">0.25490198</span>],</span><br><span class="line">         [<span class="number">0.27843139</span>, <span class="number">0.50196081</span>, <span class="number">0.22745100</span>, ..., <span class="number">0.70588237</span>,</span><br><span class="line">          <span class="number">0.95294124</span>, <span class="number">0.57647061</span>],</span><br><span class="line">         [<span class="number">0.20784315</span>, <span class="number">0.70588237</span>, <span class="number">0.88235301</span>, ..., <span class="number">0.55294120</span>,</span><br><span class="line">          <span class="number">0.77254909</span>, <span class="number">0.16078432</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">0.28235295</span>, <span class="number">0.54117650</span>, <span class="number">0.21960786</span>, ..., <span class="number">0.47450984</span>,</span><br><span class="line">          <span class="number">0.32941177</span>, <span class="number">0.95294124</span>],</span><br><span class="line">         [<span class="number">0.22352943</span>, <span class="number">0.68627453</span>, <span class="number">0.76470596</span>, ..., <span class="number">0.51764709</span>,</span><br><span class="line">          <span class="number">0.55294120</span>, <span class="number">0.96470594</span>],</span><br><span class="line">         [<span class="number">0.23921570</span>, <span class="number">0.79607850</span>, <span class="number">0.48627454</span>, ..., <span class="number">0.51764709</span>,</span><br><span class="line">          <span class="number">0.20000002</span>, <span class="number">0.80392164</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">0.09411766</span>, <span class="number">0.49019611</span>, <span class="number">0.83529419</span>, ..., <span class="number">0.43137258</span>,</span><br><span class="line">          <span class="number">0.76862752</span>, <span class="number">0.26666668</span>],</span><br><span class="line">         [<span class="number">0.99607849</span>, <span class="number">0.09411766</span>, <span class="number">0.81960791</span>, ..., <span class="number">0.54117650</span>,</span><br><span class="line">          <span class="number">0.27843139</span>, <span class="number">0.92549026</span>],</span><br><span class="line">         [<span class="number">0.20000002</span>, <span class="number">0.47058827</span>, <span class="number">0.05882353</span>, ..., <span class="number">0.41176474</span>,</span><br><span class="line">          <span class="number">0.41960788</span>, <span class="number">0.30196080</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">0.86666673</span>, <span class="number">0.46274513</span>, <span class="number">0.13333334</span>, ..., <span class="number">0.80000007</span>,</span><br><span class="line">          <span class="number">0.34509805</span>, <span class="number">0.13333334</span>],</span><br><span class="line">         [<span class="number">0.47843140</span>, <span class="number">0.14509805</span>, <span class="number">0.41960788</span>, ..., <span class="number">0.73725492</span>,</span><br><span class="line">          <span class="number">0.18823531</span>, <span class="number">0.42745101</span>],</span><br><span class="line">         [<span class="number">0.11372550</span>, <span class="number">0.73725492</span>, <span class="number">0.65490198</span>, ..., <span class="number">0.86666673</span>,</span><br><span class="line">          <span class="number">0.25490198</span>, <span class="number">0.83137262</span>],</span><br><span class="line">         ...,</span><br><span class="line">         [<span class="number">0.94901967</span>, <span class="number">0.45490199</span>, <span class="number">0.08235294</span>, ..., <span class="number">0.85882360</span>,</span><br><span class="line">          <span class="number">0.14901961</span>, <span class="number">0.14117648</span>],</span><br><span class="line">         [<span class="number">0.03137255</span>, <span class="number">0.72549021</span>, <span class="number">0.51372552</span>, ..., <span class="number">0.35686275</span>,</span><br><span class="line">          <span class="number">0.24313727</span>, <span class="number">0.01176471</span>],</span><br><span class="line">         [<span class="number">0.12941177</span>, <span class="number">0.24705884</span>, <span class="number">0.97254908</span>, ..., <span class="number">0.65098041</span>,</span><br><span class="line">          <span class="number">0.00784314</span>, <span class="number">0.96470594</span>]]])</span><br></pre></td></tr></table></figure><blockquote><p>说明：<br>实际编码时，由于飞桨数据加载的 paddle.io.DataLoader API 能够将原始 paddle.io.Dataset 定义的数据自动转换为 Tensor，所以可以不做手动转换。具体如下节介绍。</p></blockquote><h4 id="自动创建Tensor的功能介绍"><a href="#自动创建Tensor的功能介绍" class="headerlink" title="自动创建Tensor的功能介绍"></a>自动创建Tensor的功能介绍</h4><p>除了手动创建 Tensor 外，实际在飞桨框架中有一些 API 封装了 Tensor 创建的操作，从而无需用户手动创建 Tensor。例如 paddle.io.DataLoader 能够基于原始 Dataset，返回读取 Dataset 数据的迭代器，迭代器返回的数据中的每个元素都是一个 Tensor。另外在一些高层 API，如 paddle.Model.fit 、paddle.Model.predict ，如果传入的数据不是 Tensor，会自动转为 Tensor 再进行模型训练或推理。</p><blockquote><p><strong>说明：</strong><br>paddle.Model.fit、paddle.Model.predict 等高层 API 支持传入 Dataset 或 DataLoader，如果传入的是 Dataset，那么会用 DataLoader 封装转为 Tensor 数据；如果传入的是 DataLoader，则直接从 DataLoader 迭代读取 Tensor 数据送入模型训练或推理。因此即使没有写将数据转为 Tensor 的代码，也能正常执行，提升了编程效率和容错性。</p></blockquote><p>以下示例代码中，分别打印了原始数据集的数据，和送入 DataLoader 后返回的数据，可以看到数据结构由 Python list 转为了 Tensor:</p><details open><summary pointer> Compose&Normalize </summary>              <div class='content'>              <ol><li><p><strong>Compose</strong>:</p><ul><li><code>Compose</code> 是一个组合多个图像变换的工具。你可以将多个变换（transforms）放入一个列表中，然后传递给 <code>Compose</code>。当你应用这个组合变换到一个图像上时，这些变换会按照列表中的顺序一个接一个地应用到图像上。</li><li>例如，如果你想先对图像进行归一化，然后再将其转换为 Tensor，你可以这样做： <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transforms = Compose([</span><br><span class="line">    Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]),</span><br><span class="line">    ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>Normalize</strong>:</p><ul><li><code>Normalize</code> 用于对图像进行标准化。在深度学习中，我们经常对输入数据进行标准化，使其具有零均值和单位方差，这有助于模型的训练。</li><li><code>Normalize</code> 需要两个参数：<code>mean</code> 和 <code>std</code>，分别代表每个通道的均值和标准差。对于 RGB 图像，这三个通道分别是红色、绿色和蓝色。</li><li>在上面的例子中，我们使用了 <code>[0.5, 0.5, 0.5]</code> 作为均值和 <code>[0.5, 0.5, 0.5]</code> 作为标准差，这实际上是将图像的像素值从 [0, 1] 范围转换到 [-1, 1] 范围。</li></ul></li></ol><p>总之，<code>Compose</code> 和 <code>Normalize</code> 是 PaddlePaddle 中非常有用的工具，用于图像预处理和增强。</p>              </div>            </details><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> Compose,Normalize</span><br><span class="line"></span><br><span class="line">transform = Compose([Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>], data_format=<span class="string">&#x27;CHW&#x27;</span>)])</span><br><span class="line">test_dataset = paddle.vision.datasets.MNIST(mode=<span class="string">&#x27;test&#x27;</span>, transform=transform)</span><br><span class="line"><span class="built_in">print</span>(test_dataset[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line">loader = paddle.io.DataLoader(test_dataset)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">    x, label = data[<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(label)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p><strong>输出:</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(Paddle_Py3<span class="number">.12</span>) C:\Users\lxcqm&gt;python D:\PyTorch\Pytorch1\main.py</span><br><span class="line">[<span class="number">7</span>]  <span class="comment"># 原始数据中 label 为 Python list</span></span><br><span class="line">Tensor(shape=[<span class="number">1</span>, <span class="number">1</span>], dtype=int64, place=Place(gpu_pinned), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">7</span>]])   <span class="comment"># 由 DataLoader 转换后，label 为 Tensor</span></span><br></pre></td></tr></table></figure><h3 id="Tensor的属性"><a href="#Tensor的属性" class="headerlink" title="Tensor的属性"></a>Tensor的属性</h3><p>在前文中，可以看到打印 Tensor 时有 shape、dtype、place 等信息，这些都是 Tensor 的重要属性，想要了解如何操作 Tensor 需要对其属性有一定了解，接下来分别展开介绍 Tensor 的属性相关概念:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br></pre></td></tr></table></figure><h4 id="Tensor的形状"><a href="#Tensor的形状" class="headerlink" title="Tensor的形状"></a>Tensor的形状</h4><ol><li><p>形状的介绍<br> 形状是 Tensor 的一个重要的基础属性，可以通过 Tensor.shape 查看一个 Tensor 的形状，以下为相关概念：</p><ul><li><p>shape：描述了 Tensor 每个维度上元素的数量。</p></li><li><p>ndim： Tensor 的维度数量，例如<strong>向量的维度为 1，矩阵的维度为 2</strong>，Tensor 可以有任意数量的维度。</p></li><li><p>axis 或者 dimension：Tensor 的轴，<strong>即某个特定的维度</strong>。</p></li><li><p>size：Tensor 中全部元素的个数。</p></li></ul><p> 创建 1 个四维 Tensor ，并通过图形来直观表达以上几个概念之间的关系：</p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ndim_4_Tensor = paddle.ones([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure> <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7p1mhwgcx.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7p1mhwgcx.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p> axis0:2的意思是0轴，数值为2<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">ndim_4_Tensor = paddle.ones([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Data Type of every element:&quot;</span>, ndim_4_Tensor.dtype)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of dimensions:&quot;</span>, ndim_4_Tensor.ndim)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of Tensor:&quot;</span>, ndim_4_Tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Elements number along axis 0 of Tensor:&quot;</span>, ndim_4_Tensor.shape[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Elements number along the last axis of Tensor:&quot;</span>, ndim_4_Tensor.shape[-<span class="number">1</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><br> 输出:<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(Paddle_Py3<span class="number">.12</span>) C:\Users\lxcqm&gt;python D:\PyTorch\Pytorch1\main.py</span><br><span class="line">W0314 <span class="number">18</span>:05:<span class="number">09.299489</span>  <span class="number">8612</span> gpu_resources.cc:<span class="number">119</span>] Please NOTE: device: <span class="number">0</span>, GPU Compute Capability: <span class="number">8.9</span>, Driver API Version: <span class="number">12.4</span>, Runtime API Version: <span class="number">12.0</span></span><br><span class="line">W0314 <span class="number">18</span>:05:<span class="number">09.303498</span>  <span class="number">8612</span> gpu_resources.cc:<span class="number">164</span>] device: <span class="number">0</span>, cuDNN Version: <span class="number">8.9</span>.</span><br><span class="line">Data <span class="type">Type</span> of every element: paddle.float32</span><br><span class="line">Number of dimensions: <span class="number">4</span></span><br><span class="line">Shape of Tensor: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">Elements number along axis <span class="number">0</span> of Tensor: <span class="number">2</span></span><br><span class="line">Elements number along the last axis of Tensor: <span class="number">5</span></span><br></pre></td></tr></table></figure></p></li><li><p>重置 Tensor 形状（Reshape） 的方法</p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">ndim_1_Tensor = paddle.to_tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;origina:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ndim_1_Tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the shape of ndim_1_Tensor:&quot;</span>, ndim_1_Tensor.shape)</span><br><span class="line"></span><br><span class="line">reshape_Tensor = paddle.reshape(ndim_1_Tensor, [<span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[3, 1]:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(reshape_Tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;After reshape:&quot;</span>, reshape_Tensor.shape)</span><br><span class="line"></span><br><span class="line">reshape_Tensor = paddle.reshape(ndim_1_Tensor, [<span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[1, 3]:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(reshape_Tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;After reshape:&quot;</span>, reshape_Tensor.shape)</span><br></pre></td></tr></table></figure><p> 输出:</p> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">original:</span><br><span class="line">Tensor(shape=[<span class="number">3</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">the shape of ndim_1_Tensor: [<span class="number">3</span>]</span><br><span class="line">[<span class="number">3</span>, <span class="number">1</span>]:</span><br><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">1</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [[<span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>]])</span><br><span class="line">After reshape: [<span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">3</span>]:</span><br><span class="line">Tensor(shape=[<span class="number">1</span>, <span class="number">3</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">After reshape: [<span class="number">1</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><blockquote><p>在指定新的 <code>shape</code> 时存在一些技巧：<br><code>-1</code>表示这个维度的值是从 <code>Tensor</code> 的元素总数和剩余维度自动推断出来的。因此，有且只有一个维度可以被设置为 <code>-1</code>。<br><code>0</code> 表示该维度的元素数量与原值相同，因此 <code>shape</code> 中 <code>0</code> 的索引值必须小于 <code>Tensor</code> 的维度（索引值从 <code>0</code> 开始计，如第 <code>1</code> 维的索引值是 <code>0</code>，第二维的索引值是 <code>1</code>）。<br>通过几个例子来详细了解：<br> origin代表原始形状<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">origin:[<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>] reshape:[<span class="number">3</span>, <span class="number">10</span>]      actual: [<span class="number">3</span>, <span class="number">10</span>] <span class="comment"># 直接指定目标 shape</span></span><br><span class="line"></span><br><span class="line">origin:[<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>] reshape:[-<span class="number">1</span>]         actual: [<span class="number">30</span>] <span class="comment"># 转换为 1 维，维度根据元素总数推断出来是 3*2*5=30</span></span><br><span class="line"></span><br><span class="line">origin:[<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>] reshape:[-<span class="number">1</span>, <span class="number">5</span>]      actual: [<span class="number">6</span>, <span class="number">5</span>] <span class="comment"># 转换为 2 维，固定一个维度 5，另一个维度根据元素总数推断出来是 30÷5=6</span></span><br><span class="line"></span><br><span class="line">origin:[<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>] reshape:[<span class="number">0</span>, -<span class="number">1</span>]      actual: [<span class="number">3</span>, <span class="number">10</span>] <span class="comment"># reshape:[0, -1]中 0 的索引值为 0，按照规则，转换后第 0 维的元素数量与原始 Tensor 第 0 维的元素数量相同，为 3；第 1 维的元素数量根据元素总值计算得出为 30÷3=10。</span></span><br><span class="line"></span><br><span class="line">origin:[<span class="number">3</span>, <span class="number">2</span>]    reshape:[<span class="number">3</span>, <span class="number">1</span>, <span class="number">0</span>]    error： <span class="comment"># reshape:[3, 1, 0]中 0 的索引值为 2，但原 Tensor 只有 2 维，无法找到与第 3 维对应的元素数量，因此出错。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><br> 从上面的例子可以看到，通过 reshape:[-1] ，可以很方便地将 Tensor 按其在计算机上的内存分布展平为一维。<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">ndim_3_Tensor = paddle.to_tensor([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">                                [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]],</span><br><span class="line">                                [[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">                                [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>]]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Tensor flattened to Vector:&quot;</span>, paddle.reshape(ndim_3_Tensor, [-<span class="number">1</span>]).numpy())</span><br></pre></td></tr></table></figure><br> 输出:<br> <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor flattened to Vector: [ <span class="number">1</span>  <span class="number">2</span>  <span class="number">3</span>  <span class="number">4</span>  <span class="number">5</span>  <span class="number">6</span>  <span class="number">7</span>  <span class="number">8</span>  <span class="number">9</span> <span class="number">10</span> <span class="number">11</span> <span class="number">12</span> <span class="number">13</span> <span class="number">14</span> <span class="number">15</span> <span class="number">16</span> <span class="number">17</span> <span class="number">18</span> <span class="number">19</span> <span class="number">20</span>]</span><br></pre></td></tr></table></figure><br><strong>说明：</strong><br>除了 paddle.reshape 可重置 Tensor 的形状，还可通过如下方法改变 shape：</p><ul><li>paddle.squeeze，可实现 Tensor 的降维操作，即把 Tensor 中尺寸为 1 的维度删除。</li><li>paddle.unsqueeze，可实现 Tensor 的升维操作，即向 Tensor 中某个位置插入尺寸为 1 的维度。</li><li>paddle.flatten，将 Tensor 的数据在指定的连续维度上展平。</li><li>paddle.transpose，对 Tensor 的数据进行重排。</li></ul></blockquote></li><li><p>原位（Inplace）操作和非原位操作的区别</p></li></ol><h2 id="课程笔记"><a href="#课程笔记" class="headerlink" title="课程笔记"></a>课程笔记</h2><h3 id="创建一个tensor"><a href="#创建一个tensor" class="headerlink" title="创建一个tensor"></a>创建一个tensor</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(x.shape)  <span class="comment">#the shape of the tensor</span></span><br><span class="line"><span class="built_in">print</span>(x.numel())    <span class="comment">#the num element of the tensor</span></span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">12</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">0</span> , <span class="number">1</span> , <span class="number">2</span> , <span class="number">3</span> , <span class="number">4</span> , <span class="number">5</span> , <span class="number">6</span> , <span class="number">7</span> , <span class="number">8</span> , <span class="number">9</span> , <span class="number">10</span>, <span class="number">11</span>])</span><br><span class="line">[<span class="number">12</span>]</span><br><span class="line">Tensor(shape=[], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       <span class="number">12</span>)</span><br></pre></td></tr></table></figure><h3 id="改变张量形状"><a href="#改变张量形状" class="headerlink" title="改变张量形状"></a>改变张量形状</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">y = paddle.reshape(x, [<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">4</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span> , <span class="number">1</span> , <span class="number">2</span> , <span class="number">3</span> ],</span><br><span class="line">        [<span class="number">4</span> , <span class="number">5</span> , <span class="number">6</span> , <span class="number">7</span> ],</span><br><span class="line">        [<span class="number">8</span> , <span class="number">9</span> , <span class="number">10</span>, <span class="number">11</span>]])</span><br></pre></td></tr></table></figure><h3 id="tensor的计算"><a href="#tensor的计算" class="headerlink" title="tensor的计算"></a>tensor的计算</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.to_tensor([<span class="number">1.0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>])</span><br><span class="line">y = paddle.to_tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"><span class="built_in">print</span>(x - y)</span><br><span class="line"><span class="built_in">print</span>(x * y)</span><br><span class="line"><span class="built_in">print</span>(x / y)</span><br><span class="line"><span class="built_in">print</span>(x ** y)  <span class="comment"># 求幂</span></span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">3.</span> , <span class="number">4.</span> , <span class="number">6.</span> , <span class="number">10.</span>])</span><br><span class="line">Tensor(shape=[<span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [-<span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">2.</span>,  <span class="number">6.</span>])</span><br><span class="line">Tensor(shape=[<span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">2.</span> , <span class="number">4.</span> , <span class="number">8.</span> , <span class="number">16.</span>])</span><br><span class="line">Tensor(shape=[<span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">0.50000000</span>, <span class="number">1.</span>        , <span class="number">2.</span>        , <span class="number">4.</span>        ])</span><br><span class="line">Tensor(shape=[<span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">1.</span> , <span class="number">4.</span> , <span class="number">16.</span>, <span class="number">64.</span>])</span><br></pre></td></tr></table></figure><h3 id="tensor的连结"><a href="#tensor的连结" class="headerlink" title="tensor的连结"></a>tensor的连结</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>, dtype=paddle.float32).reshape([<span class="number">3</span>, <span class="number">4</span>])<span class="comment">#[]也可以写成()</span></span><br><span class="line">y = paddle.to_tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(paddle.concat((x, y), axis=<span class="number">0</span>))<span class="comment">#第一个维度</span></span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">6</span>, <span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0.</span> , <span class="number">1.</span> , <span class="number">2.</span> , <span class="number">3.</span> ],</span><br><span class="line">        [<span class="number">4.</span> , <span class="number">5.</span> , <span class="number">6.</span> , <span class="number">7.</span> ],</span><br><span class="line">        [<span class="number">8.</span> , <span class="number">9.</span> , <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">        [<span class="number">2.</span> , <span class="number">1.</span> , <span class="number">4.</span> , <span class="number">3.</span> ],</span><br><span class="line">        [<span class="number">1.</span> , <span class="number">2.</span> , <span class="number">3.</span> , <span class="number">4.</span> ],</span><br><span class="line">        [<span class="number">4.</span> , <span class="number">3.</span> , <span class="number">2.</span> , <span class="number">1.</span> ]])</span><br></pre></td></tr></table></figure><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>, dtype=paddle.float32).reshape([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = paddle.to_tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(paddle.concat((x, y), axis=-<span class="number">1</span>))<span class="comment">#最后一个维度</span></span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">8</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0.</span> , <span class="number">1.</span> , <span class="number">2.</span> , <span class="number">3.</span> , <span class="number">2.</span> , <span class="number">1.</span> , <span class="number">4.</span> , <span class="number">3.</span> ],</span><br><span class="line">        [<span class="number">4.</span> , <span class="number">5.</span> , <span class="number">6.</span> , <span class="number">7.</span> , <span class="number">1.</span> , <span class="number">2.</span> , <span class="number">3.</span> , <span class="number">4.</span> ],</span><br><span class="line">        [<span class="number">8.</span> , <span class="number">9.</span> , <span class="number">10.</span>, <span class="number">11.</span>, <span class="number">4.</span> , <span class="number">3.</span> , <span class="number">2.</span> , <span class="number">1.</span> ]])</span><br></pre></td></tr></table></figure><h3 id="通过逻辑运算符构建二维tensor"><a href="#通过逻辑运算符构建二维tensor" class="headerlink" title="通过逻辑运算符构建二维tensor"></a>通过逻辑运算符构建二维tensor</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>, dtype=paddle.float32).reshape([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = paddle.to_tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">z = x == y</span><br><span class="line"><span class="built_in">print</span>(z)</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">4</span>], dtype=<span class="built_in">bool</span>, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="literal">False</span>, <span class="literal">True</span> , <span class="literal">False</span>, <span class="literal">True</span> ],</span><br><span class="line">        [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">        [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]])</span><br></pre></td></tr></table></figure><h3 id="求和产生一个元素的张量"><a href="#求和产生一个元素的张量" class="headerlink" title="求和产生一个元素的张量"></a>求和产生一个元素的张量</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>, dtype=paddle.float32).reshape([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       <span class="number">66.</span>)</span><br></pre></td></tr></table></figure><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = paddle.to_tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>(y))</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">4</span>], dtype=float32, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [<span class="number">7.</span>, <span class="number">6.</span>, <span class="number">9.</span>, <span class="number">8.</span>])</span><br></pre></td></tr></table></figure><h3 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">3</span>).reshape([<span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line">y = paddle.arange(<span class="number">2</span>).reshape([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x+y)</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">1</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>]])</span><br><span class="line">Tensor(shape=[<span class="number">1</span>, <span class="number">2</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">2</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><h3 id="访问元素"><a href="#访问元素" class="headerlink" title="访问元素"></a>访问元素</h3><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">3</span>).reshape([<span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">2</span>, <span class="number">1</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>]])</span><br></pre></td></tr></table></figure><h3 id="赋值矩阵中的元素"><a href="#赋值矩阵中的元素" class="headerlink" title="赋值矩阵中的元素"></a>赋值矩阵中的元素</h3><h4 id="赋值单个元素"><a href="#赋值单个元素" class="headerlink" title="赋值单个元素"></a>赋值单个元素</h4><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">3</span>).reshape([<span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">x[<span class="number">1</span>, <span class="number">0</span>] = <span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">1</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>]])</span><br><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">1</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span>],</span><br><span class="line">        [<span class="number">5</span>],</span><br><span class="line">        [<span class="number">2</span>]])</span><br></pre></td></tr></table></figure><h4 id="赋值多个元素"><a href="#赋值多个元素" class="headerlink" title="赋值多个元素"></a>赋值多个元素</h4><p><strong>IN</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"></span><br><span class="line">x = paddle.arange(<span class="number">12</span>).reshape([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">x[<span class="number">0</span>:<span class="number">2</span>, :] = <span class="number">99</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><p><strong>OUT</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">4</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">0</span> , <span class="number">1</span> , <span class="number">2</span> , <span class="number">3</span> ],</span><br><span class="line">        [<span class="number">4</span> , <span class="number">5</span> , <span class="number">6</span> , <span class="number">7</span> ],</span><br><span class="line">        [<span class="number">8</span> , <span class="number">9</span> , <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line">Tensor(shape=[<span class="number">3</span>, <span class="number">4</span>], dtype=int64, place=Place(gpu:<span class="number">0</span>), stop_gradient=<span class="literal">True</span>,</span><br><span class="line">       [[<span class="number">99</span>, <span class="number">99</span>, <span class="number">99</span>, <span class="number">99</span>],</span><br><span class="line">        [<span class="number">99</span>, <span class="number">99</span>, <span class="number">99</span>, <span class="number">99</span>],</span><br><span class="line">        [<span class="number">8</span> , <span class="number">9</span> , <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="为新结果分配内存"><a href="#为新结果分配内存" class="headerlink" title="为新结果分配内存"></a>为新结果分配内存</h4>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;记录一下，如果文章在文件夹里改名字了，要再打开一次，要不然vscode里改的bug不影响这个文件。。。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;前置知识&quot;&gt;&lt;a href=&quot;#前置知识&quot; class=&quot;headerlink&quot; title</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>人工智能考核</title>
    <link href="http://tumytime.github.io/2024/03/11/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%80%83%E6%A0%B8/"/>
    <id>http://tumytime.github.io/2024/03/11/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%80%83%E6%A0%B8/</id>
    <published>2024-03-11T10:20:44.000Z</published>
    <updated>2024-03-22T12:28:30.528Z</updated>
    
    <content type="html"><![CDATA[<h1 id="task1-1"><a href="#task1-1" class="headerlink" title="task1.1"></a>task1.1</h1><blockquote><p>对于你给出的解释，请给出相应的PaddlePaddle对应的函数，并尽可能的解释函数参数的意义</p><ol><li>解释神经网络中<strong>卷积层</strong>的作用。<blockquote><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.39kxm747di.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.39kxm747di.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7zq6klz9it.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7zq6klz9it.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><ul><li>把卷积核中心点周围的像素按比例附加到(对其产生影响)卷积核中心对应的像素;</li><li>卷积核代表一个特征，用来提取输入数据的特定特征<br><strong>paddle.nn.Conv2D()</strong></li><li><code>in_channels</code>：输入特征图的通道数。</li><li><code>out_channels</code>：输出特征图的通道数。</li><li><code>kernel_size</code>：卷积核大小。</li><li><code>stride</code>：卷积步长。</li><li><code>padding</code>：填充大小。</li></ul></blockquote></li><li>解释神经网络中<strong>池化层</strong>的作用。<blockquote><p>过滤特征(减小特征图的维度)<br><strong>paddle.nn.MaxPool2D(最大池化)   paddle.nn.AvgPool2D(平均池化)</strong></p><ul><li><code>kernel_size</code>：池化核大小。</li><li><code>stride</code>：池化步长。</li><li><code>padding</code>：填充大小。</li></ul></blockquote></li><li>解释神经网络中<strong>连接层</strong>的作用。<blockquote><p>将输入的多维向量数据展平为一维向量，然后线性处理，与权重矩阵相乘，再加上偏置项，通过激活函数输出结构，可以进行分类&#x2F;预测<br><strong>paddle.nn.Linear()</strong></p><ul><li><code>in_features</code>：输入特征的大小。</li><li><code>out_features</code>：输出特征的大小。</li></ul></blockquote></li><li>解释神经网络中<strong>激活函数层</strong>的作用。<blockquote><p>把连接层得到的线性结构转化为非线性结果，从而更好地拟合数据并提高模型的性能<br><strong>paddle.nn.ReLU  paddle.nn.Sigmoid   paddle.tanh</strong></p><ul><li>没有参数</li></ul></blockquote></li><li>解释神经网络中<strong>Dropout层</strong>的作用。<blockquote><p>正则化，随机丢弃神经元，减少参数，降低模型复杂度，减少过拟合情况<br><strong>paddle.nn.Dropout</strong></p><ul><li><code>dropout_prob</code>：丢弃概率，即要丢弃的神经元的比例。</li></ul></blockquote></li></ol></blockquote><h1 id="task2-1"><a href="#task2-1" class="headerlink" title="task2.1"></a>task2.1</h1><p>在一个单层感知器中，假设有两个输入特征和一个输出。</p><p>权重分别是w1 &#x3D; 0.5，w2 &#x3D; -0.3，偏差为b &#x3D; 0.1。</p><p>输入特征为x1 &#x3D; 2，x2 &#x3D; -1。</p><p>计算输出（假设激活函数是阶跃函数）。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义权重/偏差/输入特征</span></span><br><span class="line">w1 = <span class="number">0.5</span></span><br><span class="line">w2 = -<span class="number">0.3</span></span><br><span class="line">b = <span class="number">0.1</span></span><br><span class="line">x1 = <span class="number">2</span></span><br><span class="line">x2 = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义激活函数(阶跃函数)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">if</span> x &gt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">perceptron_output</span>(<span class="params">w1, w2, b, x1, x2</span>):</span><br><span class="line">    result = w1 * x1 + w2 * x2 + b</span><br><span class="line">    <span class="keyword">return</span> step_function(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">output = perceptron_output(w1, w2, b, x1, x2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output:&quot;</span>, output)</span><br></pre></td></tr></table></figure><h1 id="task2-2（代码实现）"><a href="#task2-2（代码实现）" class="headerlink" title="task2.2（代码实现）"></a>task2.2（代码实现）</h1><p>假设你有一个包含两个隐藏层的前馈神经网络，每个隐藏层分别有3个神经元。</p><p>输入层有4个特征，输出层有2个神经元。</p><p>所有的激活函数都是ReLU。</p><p>编写一个函数来计算整个网络的输出，给定输入和网络参数。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">IP = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">W1 = [[<span class="number">0.32361505</span>, -<span class="number">1.08053636</span>, <span class="number">1.94312927</span>],</span><br><span class="line">      [<span class="number">1.87599918</span>, <span class="number">0.09333858</span>, -<span class="number">0.54394708</span>],</span><br><span class="line">      [<span class="number">0.31721595</span>, <span class="number">0.15919131</span>, <span class="number">0.75238423</span>],</span><br><span class="line">      [<span class="number">0.52593422</span>, <span class="number">0.39281801</span>, <span class="number">0.47263081</span>]]</span><br><span class="line">B1 = [[-<span class="number">0.95059911</span>, -<span class="number">0.78673449</span>, -<span class="number">0.27075615</span>]]</span><br><span class="line">W2 = [[-<span class="number">1.11562289</span>, -<span class="number">1.05667625</span>, <span class="number">1.17330918</span>],</span><br><span class="line">      [<span class="number">1.15682221</span>, <span class="number">0.30359694</span>, -<span class="number">0.32633211</span>],</span><br><span class="line">      [<span class="number">0.44536135</span>, <span class="number">0.31302144</span>, -<span class="number">1.16012537</span>]]</span><br><span class="line">B2 = [[<span class="number">1.48936813</span>, -<span class="number">0.50073038</span>, -<span class="number">0.16725209</span>]]</span><br><span class="line">W3 = [[-<span class="number">0.06277751</span>, -<span class="number">0.52103597</span>],</span><br><span class="line">      [-<span class="number">0.29022904</span>, <span class="number">1.55451498</span>],</span><br><span class="line">      [-<span class="number">0.80766273</span>, -<span class="number">0.24495497</span>]]</span><br><span class="line">B3 = [[<span class="number">0.97822396</span>, <span class="number">1.32775756</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义relu函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">relu</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Feedforward_neural_network</span>(<span class="params">IP, W1, B1, W2, B2, W3, B3</span>):</span><br><span class="line">    IP = np.array(IP)</span><br><span class="line">    W1 = np.array(W1)</span><br><span class="line">    B1 = np.array(B1)</span><br><span class="line">    W2 = np.array(W2)</span><br><span class="line">    B2 = np.array(B2)</span><br><span class="line">    W3 = np.array(W3)</span><br><span class="line">    B3 = np.array(B3)</span><br><span class="line"></span><br><span class="line">    out1 = np.dot(IP, W1) + B1</span><br><span class="line">    in2 = relu(out1)</span><br><span class="line">    out2 = np.dot(in2, W2) + B2</span><br><span class="line">    in3 = relu(out2)</span><br><span class="line">    out3 = np.dot(in3, W3) + B3</span><br><span class="line">    output = out3</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">result = Feedforward_neural_network(IP, W1, B1, W2, B2, W3, B3)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><h1 id="task3-1（代码实现）"><a href="#task3-1（代码实现）" class="headerlink" title="task3.1（代码实现）"></a>task3.1（代码实现）</h1><h3 id="题目：线性回归模型"><a href="#题目：线性回归模型" class="headerlink" title="题目：线性回归模型"></a>题目：线性回归模型</h3><p>使用PaddlePaddle框架（Paddle Pytorch Tensorflow，或者自己手写线性回归网络都可）搭建一个简单的线性回归模型，对data.csv数据集中的数据进行训练，并预测新数据点的值。</p><h4 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h4><p>使用paddle.nn.Linear创建一个具有单个输入和单个输出的线性层。<br>定义损失函数和优化器。<br>训练模型以拟合数据。<br>对新数据进行预测。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> Linear</span><br><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="comment"># 从文件导入数据</span></span><br><span class="line">    datafile = pd.read_csv(<span class="string">&quot;C:/Users/lxcqm/Desktop/人工智能考核/训练数据/data.csv&quot;</span>)</span><br><span class="line">    X = datafile[<span class="string">&quot;X&quot;</span>].values.astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    Y = datafile[<span class="string">&quot;y&quot;</span>].values.astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    data_matrix = np.column_stack((X, Y))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 确保数据的总元素数量为 100000</span></span><br><span class="line">    num_rows = <span class="number">50000</span></span><br><span class="line">    num_cols = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    data_matrix = data_matrix.reshape((num_rows, num_cols))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原数据集拆分成训练集和测试集</span></span><br><span class="line">    <span class="comment"># 这里使用80%的数据做训练，20%的数据做测试</span></span><br><span class="line">    <span class="comment"># 测试集和训练集必须是没有交集的</span></span><br><span class="line">    ratio = <span class="number">0.8</span></span><br><span class="line">    offset = <span class="built_in">int</span>(data_matrix.shape[<span class="number">0</span>] * ratio)</span><br><span class="line">    training_data = data_matrix[:offset]</span><br><span class="line">    test_data = data_matrix[offset:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算train数据集的最大值，最小值</span></span><br><span class="line">    maximums, minimums = training_data.<span class="built_in">max</span>(axis=<span class="number">0</span>), training_data.<span class="built_in">min</span>(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 记录数据的归一化参数，在预测时对数据做归一化</span></span><br><span class="line">    <span class="keyword">global</span> max_values</span><br><span class="line">    <span class="keyword">global</span> min_values</span><br><span class="line"></span><br><span class="line">    max_values = maximums</span><br><span class="line">    min_values = minimums</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对数据进行归一化处理</span></span><br><span class="line">    training_data = (training_data - min_values) / (maximums - minimums)</span><br><span class="line">    test_data = (test_data - min_values) / (maximums - minimums)</span><br><span class="line">    <span class="keyword">return</span> training_data, test_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 验证数据集读取程序的正确性</span></span><br><span class="line"><span class="comment"># training_data, test_data = load_data()</span></span><br><span class="line"><span class="comment"># print(training_data.shape)</span></span><br><span class="line"><span class="comment"># print(training_data)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Regressor</span>(paddle.nn.Layer):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># self代表类的实例自身</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化父类中的一些参数</span></span><br><span class="line">        <span class="built_in">super</span>(Regressor, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义一层全连接层，输入维度是1，输出维度是1</span></span><br><span class="line">        self.fc = Linear(in_features=<span class="number">1</span>, out_features=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 网络的前向计算</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        x = self.fc(inputs)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明定义好的线性回归模型</span></span><br><span class="line">model = Regressor()</span><br><span class="line"><span class="comment"># 开启模型训练模式</span></span><br><span class="line">model.train()</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">training_data, test_data = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化算法，使用随机梯度下降SGD</span></span><br><span class="line"><span class="comment"># 学习率设置为0.01</span></span><br><span class="line">opt = paddle.optimizer.SGD(learning_rate=<span class="number">0.01</span>, parameters=model.parameters())</span><br><span class="line"></span><br><span class="line">EPOCH_NUM = <span class="number">10</span>  <span class="comment"># 设置外层循环次数</span></span><br><span class="line">BATCH_SIZE = <span class="number">100</span>  <span class="comment"># 设置batch大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义外层循环</span></span><br><span class="line"><span class="keyword">for</span> epoch_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">    <span class="comment"># 在每轮迭代开始之前，将训练数据的顺序随机的打乱</span></span><br><span class="line">    np.random.shuffle(training_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将训练数据进行拆分，每个batch包含10条数据</span></span><br><span class="line">    mini_batches = [training_data[k:k + BATCH_SIZE] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(training_data), BATCH_SIZE)]</span><br><span class="line"><span class="comment"># print(mini_batches)</span></span><br><span class="line">    <span class="comment"># 定义内层循环</span></span><br><span class="line">    <span class="keyword">for</span> iter_id, mini_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(mini_batches):</span><br><span class="line">        x = np.array(mini_batch[:, :-<span class="number">1</span>])  <span class="comment"># 获得当前批次训练X</span></span><br><span class="line">        y = np.array(mini_batch[:, -<span class="number">1</span>:])  <span class="comment"># 获得当前批次训练Y</span></span><br><span class="line"><span class="comment"># print(mini_batch, x, y)</span></span><br><span class="line">        <span class="comment"># 将numpy数据转为飞桨动态图tensor的格式</span></span><br><span class="line">        X = paddle.to_tensor(x)</span><br><span class="line">        Y = paddle.to_tensor(y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向计算</span></span><br><span class="line">        predicts = model(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = F.square_error_cost(predicts, label=Y)</span><br><span class="line">        avg_loss = paddle.mean(loss)</span><br><span class="line">        <span class="keyword">if</span> iter_id % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;epoch: &#123;&#125;, iter: &#123;&#125;, loss is: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch_id, iter_id, avg_loss.numpy()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播，计算每层参数的梯度值</span></span><br><span class="line">        avg_loss.backward()</span><br><span class="line">        <span class="comment"># 更新参数，根据设置好的学习率迭代一步</span></span><br><span class="line">        opt.step()</span><br><span class="line">        <span class="comment"># 清空梯度变量，以备下一轮计算</span></span><br><span class="line">        opt.clear_grad()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_one_example</span>():</span><br><span class="line">    <span class="comment"># 从上边已加载的测试集中，随机选择一条作为测试数据</span></span><br><span class="line">    idx = np.random.randint(<span class="number">0</span>, test_data.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># idx = -10</span></span><br><span class="line">    x0, y0 = test_data[idx, <span class="number">0</span>], test_data[idx, -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    x0 = x0.reshape([<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x0, y0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型参数，文件名为LR_model.pdparams</span></span><br><span class="line">paddle.save(model.state_dict(), <span class="string">&#x27;C:/Users/lxcqm/Desktop/model/model1.pdmodel&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型保存成功，模型参数保存在C:/Users/lxcqm/Desktop/model/model1.pdmodel&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数为保存模型参数的文件地址</span></span><br><span class="line">model_dict = paddle.load(<span class="string">&#x27;C:/Users/lxcqm/Desktop/model/model1.pdmodel&#x27;</span>)</span><br><span class="line">model.load_dict(model_dict)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数为数据集的文件地址</span></span><br><span class="line">xn, yn = load_one_example()</span><br><span class="line"><span class="comment"># 将数据转为动态图的variable格式</span></span><br><span class="line">xn = paddle.to_tensor(xn)</span><br><span class="line">predict = model(xn)</span><br><span class="line"><span class="comment"># print(&quot;xn&quot;, xn,&quot;predict&quot;,predict, &quot;yn&quot;, yn)</span></span><br><span class="line"><span class="comment"># 对结果做反归一化处理</span></span><br><span class="line">predict = predict * (max_values[-<span class="number">1</span>] - min_values[-<span class="number">1</span>]) + min_values[-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 对Y数据做反归一化处理</span></span><br><span class="line">yn = yn * (max_values[-<span class="number">1</span>] - min_values[-<span class="number">1</span>]) + min_values[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Inference result is &#123;&#125;, the corresponding Y is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(predict.numpy(), yn))</span><br></pre></td></tr></table></figure><h1 id="task3-2（代码实现）"><a href="#task3-2（代码实现）" class="headerlink" title="task3.2（代码实现）"></a>task3.2（代码实现）</h1><h3 id="题目：卷积神经网络（CNN）分类"><a href="#题目：卷积神经网络（CNN）分类" class="headerlink" title="题目：卷积神经网络（CNN）分类"></a>题目：卷积神经网络（CNN）分类</h3><p>使用PaddlePaddle框架构建一个简单的卷积神经网络（CNN），用于对MNIST手写数字数据集进行分类。</p><p>(Paddle Pytorch Tensorflow等框架都可)</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> Normalize</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义图像归一化处理方法,这里的CHW指图像格式需为 [C通道数,H图像高度,W图像宽度]</span></span><br><span class="line"><span class="comment"># 减均值,除以标准差</span></span><br><span class="line"><span class="comment"># 假设像素值范围是 [0, 255]</span></span><br><span class="line"><span class="comment"># 当每个像素值减去 127.5 后</span></span><br><span class="line"><span class="comment"># 范围变为 [-127.5, 127.5]</span></span><br><span class="line"><span class="comment"># 再除以 127.5（或者是原始数据范围的一半）</span></span><br><span class="line"><span class="comment"># 就得到了 [-1, 1] 的范围</span></span><br><span class="line">transform = Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>], data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNISTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, datafile, mode=<span class="string">&#x27;train&#x27;</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.mode = mode</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;loading mnist dataset from &#123;&#125; ......&#x27;</span>.<span class="built_in">format</span>(datafile))</span><br><span class="line"></span><br><span class="line">        data = json.load(gzip.<span class="built_in">open</span>(datafile))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;mnist dataset load done&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取到的数据区分训练集,验证集,测试集</span></span><br><span class="line">        train_set, val_set, eval_set = data</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            <span class="comment"># 获得训练数据集</span></span><br><span class="line">            self.imgs, self.labels = train_set[<span class="number">0</span>], train_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;valid&#x27;</span>:</span><br><span class="line">            <span class="comment"># 获得验证数据集</span></span><br><span class="line">            self.imgs, self.labels = val_set[<span class="number">0</span>], val_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            <span class="comment"># 获得测试数据集</span></span><br><span class="line">            self.imgs, self.labels = eval_set[<span class="number">0</span>], eval_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;mode can only be one of [&#x27;train&#x27;, &#x27;valid&#x27;, &#x27;test&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        实现__getitem__方法，定义指定index时如何获取数据</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        data = self.imgs[index]</span><br><span class="line">        label = self.labels[index]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.transform(data), label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        实现__len__方法，返回数据集总数目</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.imgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datafile = <span class="string">&#x27;D:/paddlepaddle/paddlepaddle手写数字/mnist.json.gz&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载数据集并初始化 DataSet</span></span><br><span class="line">train_dataset = MNISTDataset(datafile, mode=<span class="string">&#x27;train&#x27;</span>, transform=transform)</span><br><span class="line">test_dataset = MNISTDataset(datafile, mode=<span class="string">&#x27;test&#x27;</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&#x27;train images: &#x27;, train_dataset.__len__(), &#x27;, test images: &#x27;, test_dataset.__len__())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># for data in train_dataset:</span></span><br><span class="line"><span class="comment">#     image, label = data</span></span><br><span class="line"><span class="comment">#     print(&#x27;shape of image: &#x27;, image.shape)</span></span><br><span class="line"><span class="comment">#     plt.title(str(label))</span></span><br><span class="line"><span class="comment">#     plt.imshow(image[0])</span></span><br><span class="line"><span class="comment">#     break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义并初始化数据读取器</span></span><br><span class="line">train_loader = paddle.io.DataLoader(train_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">test_loader = paddle.io.DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># print(&#x27;step num:&#x27;, len(train_loader))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># class MNIST_CNN(paddle.nn.Layer):</span></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         super(MNIST_CNN, self).__init__()</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         # 定义一层全连接层，输出维度为一</span></span><br><span class="line"><span class="comment">#         self.fc = paddle.nn.Linear(in_features=784, out_features=1)</span></span><br><span class="line"><span class="comment">#         # 图片像素28*28=784个像素点</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def forward(self, inputs):</span></span><br><span class="line"><span class="comment">#         outputs = self.fc(inputs)</span></span><br><span class="line"><span class="comment">#         return outputs</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNIST_CNN</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MNIST_CNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义卷积层</span></span><br><span class="line">        self.conv1 = paddle.nn.Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pool1 = paddle.nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = paddle.nn.Conv2D(in_channels=<span class="number">16</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pool2 = paddle.nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算全连接层的输入维度</span></span><br><span class="line">        self.fc_input_dim = <span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>  <span class="comment"># 根据卷积层和池化层输出的维度计算</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义全连接层</span></span><br><span class="line">        self.fc1 = paddle.nn.Linear(in_features=self.fc_input_dim, out_features=<span class="number">128</span>)</span><br><span class="line">        self.fc2 = paddle.nn.Linear(in_features=<span class="number">128</span>, out_features=<span class="number">10</span>)  <span class="comment"># 输出类别数量为10，适用于MNIST数据集</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        x = paddle.to_tensor(inputs)</span><br><span class="line">        x = paddle.reshape(x, [-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">        <span class="comment"># x = paddle.unsqueeze(x, axis=1)  # Add channel dimension</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.pool1(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.pool2(x)</span><br><span class="line"></span><br><span class="line">        x = paddle.flatten(x, start_axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MNIST_CNN()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;train:&#x27;</span>)</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 定义优化器，使用随机梯度下降SGD优化器，学习率设置为0.001</span></span><br><span class="line">    <span class="comment"># SGD的基本原理是在每一次迭代中，使用随机选择的小批量训练数据来计算梯度，并更新模型参数</span></span><br><span class="line">    opt = paddle.optimizer.SGD(learning_rate=<span class="number">0.001</span>, parameters=model.parameters())</span><br><span class="line">    EPOCH_NUM = <span class="number">5</span></span><br><span class="line">    <span class="keyword">for</span> epoch_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#x27;</span>, epoch_id)</span><br><span class="line">        <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">            images, labels = data</span><br><span class="line">            images = paddle.to_tensor(images).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            labels = paddle.to_tensor(labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            images = paddle.reshape(images, [images.shape[<span class="number">0</span>], images.shape[<span class="number">2</span>] * images.shape[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向计算的过程</span></span><br><span class="line">            predicts = model(images)</span><br><span class="line">            <span class="comment"># Convert labels data type to integer</span></span><br><span class="line">            labels_int = paddle.cast(labels, dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Convert labels to one-hot encoding</span></span><br><span class="line">            labels_onehot = paddle.nn.functional.one_hot(labels_int, num_classes=<span class="number">10</span>)</span><br><span class="line">            <span class="comment"># 计算损失，取一个批次样本损失的平均值</span></span><br><span class="line"></span><br><span class="line">            loss = paddle.nn.functional.square_error_cost(predicts, labels_onehot)</span><br><span class="line">            avg_loss = paddle.mean(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 每训练了200批次的数据，打印下当前Loss的情况</span></span><br><span class="line">            <span class="keyword">if</span> batch_id % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;epoch: &#123;&#125;, batch: &#123;&#125;, loss is: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch_id, batch_id, avg_loss.numpy()))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 后向传播，更新参数的过程</span></span><br><span class="line">            avg_loss.backward()</span><br><span class="line">            opt.step()</span><br><span class="line">            opt.clear_grad()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;create model:&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动训练过程</span></span><br><span class="line">train(model)</span><br><span class="line"><span class="comment"># # 保存模型参数，文件名为LR_model.pdparams</span></span><br><span class="line"><span class="comment"># paddle.save(model.state_dict(), &#x27;C:/Users/lxcqm/Desktop/model/modelhn.pdmodel&#x27;)</span></span><br><span class="line"><span class="comment"># print(&quot;模型保存成功，模型参数保存在C:/Users/lxcqm/Desktop/model/modelhn.pdmodel&quot;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># # 参数为保存模型参数的文件地址</span></span><br><span class="line"><span class="comment"># model_dict = paddle.load(&#x27;C:/Users/lxcqm/Desktop/model/modelhn.pdmodel&#x27;)</span></span><br><span class="line"><span class="comment"># model.load_dict(model_dict)</span></span><br><span class="line"><span class="comment"># model.eval()</span></span><br></pre></td></tr></table></figure><h1 id="task3-2（代码实现）-1"><a href="#task3-2（代码实现）-1" class="headerlink" title="task3.2（代码实现）"></a>task3.2（代码实现）</h1><h3 id="题目：卷积神经网络（CNN）分类-1"><a href="#题目：卷积神经网络（CNN）分类-1" class="headerlink" title="题目：卷积神经网络（CNN）分类"></a>题目：卷积神经网络（CNN）分类</h3><p>使用PaddlePaddle框架构建一个简单的卷积神经网络（CNN），用于对MNIST手写数字数据集进行分类。</p><p>(Paddle Pytorch Tensorflow等框架都可)</p><h4 id="提示-1"><a href="#提示-1" class="headerlink" title="提示"></a>提示</h4><p>构建一个包含卷积层、池化层和全连接层的CNN模型。<br>加载MNIST数据集，可以使用paddle.vision.datasets.MNIST。<br>定义损失函数和优化器。<br>训练模型以对手写数字进行分类。<br>评估模型性能并进行预测。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> Normalize</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义图像归一化处理方法,这里的CHW指图像格式需为 [C通道数,H图像高度,W图像宽度]</span></span><br><span class="line"></span><br><span class="line">transform = Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>], data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNISTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, datafile, mode=<span class="string">&#x27;train&#x27;</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.mode = mode</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;loading mnist dataset from &#123;&#125; ......&#x27;</span>.<span class="built_in">format</span>(datafile))</span><br><span class="line"></span><br><span class="line">        data = json.load(gzip.<span class="built_in">open</span>(datafile))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;mnist dataset load done&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取到的数据区分训练集,验证集,测试集</span></span><br><span class="line">        train_set, val_set, eval_set = data</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            <span class="comment"># 获得训练数据集</span></span><br><span class="line">            self.imgs, self.labels = train_set[<span class="number">0</span>], train_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;valid&#x27;</span>:</span><br><span class="line">            <span class="comment"># 获得验证数据集</span></span><br><span class="line">            self.imgs, self.labels = val_set[<span class="number">0</span>], val_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            <span class="comment"># 获得测试数据集</span></span><br><span class="line">            self.imgs, self.labels = eval_set[<span class="number">0</span>], eval_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;mode can only be one of [&#x27;train&#x27;, &#x27;valid&#x27;, &#x27;test&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        实现__getitem__方法，定义指定index时如何获取数据</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        data = self.imgs[index]</span><br><span class="line">        label = self.labels[index]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.transform(data), label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        实现__len__方法，返回数据集总数目</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.imgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datafile = <span class="string">&#x27;D:/paddlepaddle/paddlepaddle手写数字/mnist.json.gz&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载数据集并初始化 DataSet</span></span><br><span class="line">train_dataset = MNISTDataset(datafile, mode=<span class="string">&#x27;train&#x27;</span>, transform=transform)</span><br><span class="line">test_dataset = MNISTDataset(datafile, mode=<span class="string">&#x27;test&#x27;</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义并初始化数据读取器</span></span><br><span class="line">train_loader = paddle.io.DataLoader(train_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">test_loader = paddle.io.DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># train_loader = paddle.io.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)</span></span><br><span class="line"><span class="comment"># test_loader = paddle.io.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MNIST_CNN</span>(paddle.nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MNIST_CNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义卷积层</span></span><br><span class="line">        self.conv1 = paddle.nn.Conv2D(in_channels=<span class="number">1</span>, out_channels=<span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pool1 = paddle.nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = paddle.nn.Conv2D(in_channels=<span class="number">16</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pool2 = paddle.nn.MaxPool2D(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算全连接层的输入维度</span></span><br><span class="line">        self.fc_input_dim = <span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>  <span class="comment"># 根据卷积层和池化层输出的维度计算</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义全连接层</span></span><br><span class="line">        self.fc1 = paddle.nn.Linear(in_features=self.fc_input_dim, out_features=<span class="number">128</span>)</span><br><span class="line">        self.fc2 = paddle.nn.Linear(in_features=<span class="number">128</span>, out_features=<span class="number">10</span>)  <span class="comment"># 输出类别数量为10，适用于MNIST数据集</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        x = paddle.to_tensor(inputs)</span><br><span class="line">        x = paddle.reshape(x, [-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">        <span class="comment"># x = paddle.unsqueeze(x, axis=1)  # Add channel dimension</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.pool1(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.pool2(x)</span><br><span class="line"></span><br><span class="line">        x = paddle.flatten(x, start_axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MNIST_CNN()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;train:&#x27;</span>)</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 定义优化器</span></span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())</span></span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters())</span></span><br><span class="line">    <span class="comment"># opt = paddle.optimizer.Adagrad(learning_rate=0.001, parameters=model.parameters())</span></span><br><span class="line">    opt = paddle.optimizer.Adam(learning_rate=<span class="number">0.001</span>, parameters=model.parameters())</span><br><span class="line">    EPOCH_NUM = <span class="number">40</span></span><br><span class="line">    total_losses = []  <span class="comment"># 存储每个batch的损失值</span></span><br><span class="line">    <span class="keyword">for</span> epoch_id <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH_NUM):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#x27;</span>, epoch_id)</span><br><span class="line">        <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">            images, labels = data</span><br><span class="line">            images = paddle.to_tensor(images).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            labels = paddle.to_tensor(labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            images = paddle.reshape(images, [images.shape[<span class="number">0</span>], images.shape[<span class="number">2</span>] * images.shape[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向计算的过程</span></span><br><span class="line">            predicts = model(images)</span><br><span class="line">            <span class="comment"># Convert labels data type to integer</span></span><br><span class="line">            labels_int = paddle.cast(labels, dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Convert labels to one-hot encoding</span></span><br><span class="line">            labels_onehot = paddle.nn.functional.one_hot(labels_int, num_classes=<span class="number">10</span>)</span><br><span class="line">            <span class="comment"># 计算损失，取一个批次样本损失的平均值</span></span><br><span class="line"></span><br><span class="line">            loss = paddle.nn.functional.square_error_cost(predicts, labels_onehot)</span><br><span class="line">            avg_loss = paddle.mean(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算预测结果</span></span><br><span class="line">            probs = paddle.nn.functional.softmax(predicts, axis=<span class="number">1</span>)</span><br><span class="line">            predictions = paddle.argmax(probs, axis=<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 计算准确率</span></span><br><span class="line">            correct = paddle.<span class="built_in">sum</span>(paddle.cast(paddle.equal(predictions, labels_int), dtype=<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line">            accuracy = correct / images.shape[<span class="number">0</span>] * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> batch_id % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;epoch: &#123;&#125;, batch: &#123;&#125;, loss is: &#123;&#125;, accuracy is: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch_id, batch_id,</span><br><span class="line">                                                                                  avg_loss.numpy(),</span><br><span class="line">                                                                                  accuracy.numpy()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 后向传播，更新参数的过程</span></span><br><span class="line">            avg_loss.backward()</span><br><span class="line">            opt.step()</span><br><span class="line">            opt.clear_grad()</span><br><span class="line">            <span class="comment"># 保存每个batch的损失值</span></span><br><span class="line">            total_losses.append(avg_loss.numpy())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制总的损失曲线图</span></span><br><span class="line">    plt.plot(total_losses)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Batch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training Loss Curve&#x27;</span>)</span><br><span class="line">    plt.ylim(<span class="number">0</span>, <span class="number">0.1</span>)  <span class="comment"># 设置y轴范围为0到0.1</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;create model:&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动训练过程</span></span><br><span class="line">train(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型参数，文件名为modelhn.pdmodel</span></span><br><span class="line">paddle.save(model.state_dict(), <span class="string">&#x27;C:/Users/lxcqm/Desktop/model/modelhn.pdmodel&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型保存成功，模型参数保存在C:/Users/lxcqm/Desktop/model/modelhn.pdmodel&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数为保存模型参数的文件地址</span></span><br><span class="line"></span><br><span class="line">model_dict = paddle.load(<span class="string">&#x27;C:/Users/lxcqm/Desktop/model/modelhn.pdmodel&#x27;</span>)</span><br><span class="line">model.load_dict(model_dict)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">test_loader = paddle.io.DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">    images, labels = data</span><br><span class="line">    images = paddle.to_tensor(images).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    labels = paddle.to_tensor(labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    images = paddle.reshape(images, [images.shape[<span class="number">0</span>], images.shape[<span class="number">2</span>] * images.shape[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向计算的过程</span></span><br><span class="line">    predicts = model(images)</span><br><span class="line">    <span class="comment">#########################</span></span><br><span class="line">    <span class="comment"># 设置数据读取器，API自动读取MNIST数据测试集</span></span><br><span class="line">    test_dataset = paddle.vision.datasets.MNIST(mode=<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    test_data0 = np.array(test_dataset[batch_id][<span class="number">0</span>])</span><br><span class="line">    test_label_0 = np.array(test_dataset[batch_id][<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plt.figure(&quot;Image&quot;)  # 图像窗口名称</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    plt.imshow(test_data0, cmap=plt.cm.binary)</span><br><span class="line">    plt.axis(<span class="string">&#x27;on&#x27;</span>)  <span class="comment"># 关掉坐标轴为 off</span></span><br><span class="line">    plt.title(<span class="string">&#x27;image&#x27;</span>)  <span class="comment"># 图像题目</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印测试结果</span></span><br><span class="line"><span class="comment"># print(&quot;Inference result is &#123;&#125;, the corresponding label is &#123;&#125;&quot;.format(predicts, labels))</span></span><br><span class="line"></span><br><span class="line">predicts_np = predicts.numpy()</span><br><span class="line">labels_np = labels.numpy()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测各标签概率:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(predicts_np[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;实际标签:&quot;</span>, labels_np[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推理结果向量</span></span><br><span class="line">predictions = np.array(predicts_np[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到概率最高的标签</span></span><br><span class="line">predicted_label = np.argmax(predictions)</span><br><span class="line"><span class="comment"># print(predictions)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型认为概率最高的标签是:&quot;</span>, predicted_label)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># for batch_id, data in enumerate(test_loader):</span></span><br><span class="line"><span class="comment">#     images, labels = data</span></span><br><span class="line"><span class="comment">#     images = paddle.to_tensor(images).astype(&#x27;float32&#x27;)</span></span><br><span class="line"><span class="comment">#     labels = paddle.to_tensor(labels).astype(&#x27;float32&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     images = paddle.reshape(images, [images.shape[0], images.shape[2] * images.shape[3]])</span></span><br><span class="line"></span><br><span class="line">total_accuracy = <span class="number">0.0</span></span><br><span class="line">total_samples = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    images, labels = data</span><br><span class="line">    images = paddle.to_tensor(images).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    labels = paddle.to_tensor(labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    images = paddle.reshape(images, [images.shape[<span class="number">0</span>], images.shape[<span class="number">2</span>] * images.shape[<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向计算</span></span><br><span class="line">    predicts = model(images)</span><br><span class="line">    <span class="comment"># Convert labels data type to integer</span></span><br><span class="line">    labels_int = paddle.cast(labels, dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert labels to one-hot encoding</span></span><br><span class="line">    labels_onehot = paddle.nn.functional.one_hot(labels_int, num_classes=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 计算损失，取一个批次样本损失的平均值</span></span><br><span class="line"></span><br><span class="line">    loss = paddle.nn.functional.square_error_cost(predicts, labels_onehot)</span><br><span class="line">    avg_loss = paddle.mean(loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算预测结果</span></span><br><span class="line">    probs = paddle.nn.functional.softmax(predicts, axis=<span class="number">1</span>)</span><br><span class="line">    predictions = paddle.argmax(probs, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    correct = paddle.<span class="built_in">sum</span>(paddle.cast(paddle.equal(predictions, labels_int), dtype=<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line">    accuracy = correct / images.shape[<span class="number">0</span>] * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> batch_id % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; batch: &#123;&#125;, loss is: &#123;&#125;, accuracy is: &#123;&#125;&quot;</span>.<span class="built_in">format</span>( batch_id,</span><br><span class="line">                                                                          avg_loss.numpy(),</span><br><span class="line">                                                                          accuracy.numpy()))</span><br><span class="line">    <span class="comment"># 累加准确率值和样本数量</span></span><br><span class="line">    total_accuracy += accuracy.numpy() * images.shape[<span class="number">0</span>]</span><br><span class="line">    total_samples += images.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算平均准确率</span></span><br><span class="line">accuracy_total = total_accuracy / total_samples</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;- Total Accuracy: &#123;:.5f&#125;%&quot;</span>.<span class="built_in">format</span>(accuracy_total))</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;task1-1&quot;&gt;&lt;a href=&quot;#task1-1&quot; class=&quot;headerlink&quot; title=&quot;task1.1&quot;&gt;&lt;/a&gt;task1.1&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;对于你给出的解释，请给出相应的PaddlePaddle对应的函数，并尽可能</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    <category term="考核" scheme="http://tumytime.github.io/tags/%E8%80%83%E6%A0%B8/"/>
    
  </entry>
  
  <entry>
    <title>Python程序控制结构</title>
    <link href="http://tumytime.github.io/2024/03/10/Python%E7%A8%8B%E5%BA%8F%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/"/>
    <id>http://tumytime.github.io/2024/03/10/Python%E7%A8%8B%E5%BA%8F%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/</id>
    <published>2024-03-10T08:52:38.000Z</published>
    <updated>2024-03-10T09:51:50.224Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分支语句"><a href="#分支语句" class="headerlink" title="分支语句"></a>分支语句</h2><h3 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h3><p><strong>逻辑非：</strong><br>not x</p><h4 id="遍历循环"><a href="#遍历循环" class="headerlink" title="遍历循环"></a>遍历循环</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8z69tiu27o.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8z69tiu27o.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.86tebsepob.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.86tebsepob.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="条件循环"><a href="#条件循环" class="headerlink" title="条件循环"></a>条件循环</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=<span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">while</span> x &lt; <span class="number">10</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(x)</span><br><span class="line"><span class="meta">... </span>    x+=<span class="number">3</span></span><br><span class="line">...</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">9</span></span><br></pre></td></tr></table></figure><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4xuaf4vpql.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4xuaf4vpql.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="循环保留字-break和continue"><a href="#循环保留字-break和continue" class="headerlink" title="循环保留字: break和continue"></a>循环保留字: break和continue</h4><ul><li><p>作用：辅助控制循环执行：</p><ul><li><p>Break：来跳出当前层循环，脱离该循环后程序从循环<br>  后代码继续执行(多层循环中break语句只能跳出最内层循环)</p></li><li><p>Continue：结束当前层当次循环，即跳过循环体中下<br>  面尚未执行的语句，进行下一次循环，但不跳出当前层<br>  循环。</p></li></ul></li><li><p>在for循环和while循环中的else扩展用法中：</p><ul><li><p>Break和return语句被执行对else有影响</p></li><li><p>continue保留字对else没有影响</p></li></ul></li></ul><h2 id="程序的异常处理"><a href="#程序的异常处理" class="headerlink" title="程序的异常处理"></a>程序的异常处理</h2><h3 id="try-except-语句"><a href="#try-except-语句" class="headerlink" title="try-except()语句"></a>try-except()语句</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.99t3mopr9a.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.99t3mopr9a.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.39kxhygpgc.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.39kxhygpgc.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    &lt;语句块<span class="number">1</span>&gt;</span><br><span class="line"><span class="keyword">except</span> &lt;异常类型&gt;:</span><br><span class="line">    &lt;语句块<span class="number">2</span>&gt;</span><br></pre></td></tr></table></figure><p>可以有多个except<br>except语句没有指定任何错误类型时，表示它对应的语句块可以处理所有其他异常<br><strong>示例</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        Vol = <span class="built_in">eval</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入电池电压，单位V:&quot;</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;电池电压值：&quot;</span>, <span class="built_in">float</span>(Vol))</span><br><span class="line">        <span class="keyword">if</span> Vol &lt; <span class="number">10</span> <span class="keyword">or</span> Vol &gt; <span class="number">13</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;电压值不正常，请即使检查！&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> NameError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;输入错误！请输入一个数值！&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="random库"><a href="#random库" class="headerlink" title="random库"></a>random库</h2><p>random库是使用随机数的Python标准库</p><ul><li>random库主要用于生成随机数</li><li>伪随机数: 采用梅森旋转算法生成的(伪)随机序列中元素<div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.2ob9votxz1.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.2ob9votxz1.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>生成随机数之前可以通过seed()函数指定随机数种子，随机种子一般是一个整数，只要种子相同，每次生成的随机数序列也相同，这种方法便于测试和同步数据。</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> random <span class="keyword">import</span> *</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>seed(<span class="number">125</span>) <span class="comment"># 随机种子赋值125</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;&#125;.&#123;&#125;.&#123;&#125;&quot;</span>.<span class="built_in">format</span>(randint(<span class="number">1</span>,<span class="number">10</span>),randint(<span class="number">1</span>,<span class="number">10</span>),randint(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line"><span class="string">&#x27;4.4.10&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;&#125;.&#123;&#125;.&#123;&#125;&quot;</span>.<span class="built_in">format</span>(randint(<span class="number">1</span>,<span class="number">10</span>),randint(<span class="number">1</span>,<span class="number">10</span>),randint(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line"><span class="string">&#x27;5.10.3&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>seed(<span class="number">125</span>) <span class="comment"># 再次给随机种子赋值125</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;&#125;.&#123;&#125;.&#123;&#125;&quot;</span>.<span class="built_in">format</span>(randint(<span class="number">1</span>,<span class="number">10</span>),randint(<span class="number">1</span>,<span class="number">10</span>),randint(<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line"><span class="string">&#x27;4.4.10&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;分支语句&quot;&gt;&lt;a href=&quot;#分支语句&quot; class=&quot;headerlink&quot; title=&quot;分支语句&quot;&gt;&lt;/a&gt;分支语句&lt;/h2&gt;&lt;h3 id=&quot;if语句&quot;&gt;&lt;a href=&quot;#if语句&quot; class=&quot;headerlink&quot; title=&quot;if语句&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Python基本语法元素及数据类型</title>
    <link href="http://tumytime.github.io/2024/03/09/Python%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%85%83%E7%B4%A0%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>http://tumytime.github.io/2024/03/09/Python%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%85%83%E7%B4%A0%E5%8F%8A%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</id>
    <published>2024-03-09T11:00:39.000Z</published>
    <updated>2024-03-10T08:52:08.092Z</updated>
    
    <content type="html"><![CDATA[<h2 id="程序基本设计方法"><a href="#程序基本设计方法" class="headerlink" title="程序基本设计方法"></a>程序基本设计方法</h2><h3 id="RELU激活函数"><a href="#RELU激活函数" class="headerlink" title="RELU激活函数"></a>RELU激活函数</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8ad0871gq2.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8ad0871gq2.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="built_in">input</span>(<span class="string">&quot;请输入数值x:&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">eval</span>(x) &gt; <span class="number">0</span>: <span class="comment"># 从键盘输入的是字符串，eval() 函数接收一个数字表达式作为参数</span></span><br><span class="line">                <span class="comment"># 输出表达式的值</span></span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>一种输出：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">请输入数值x:<span class="number">1</span>+<span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><h3 id="智能车差速转向"><a href="#智能车差速转向" class="headerlink" title="智能车差速转向"></a>智能车差速转向</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.3nrd7ii95k.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.3nrd7ii95k.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line">speed = <span class="number">20</span>  <span class="comment">#设定车轮直线形式速度</span></span><br><span class="line">kx = <span class="number">0.85</span>   <span class="comment">#调节参数</span></span><br><span class="line"></span><br><span class="line">left_wheel = speed</span><br><span class="line">right_wheel = speed</span><br><span class="line"></span><br><span class="line">angle = <span class="built_in">eval</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入归一化后的角度:&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="number">0</span> &lt; <span class="built_in">eval</span>(angle) &lt;= <span class="number">1</span>:    <span class="comment">#右转向</span></span><br><span class="line">    right_wheel = (<span class="number">1</span> - angle * kx) * speed </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;right_wheel:&#123;&#125;;left_wheel:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(right_wheel,left_wheel)) </span><br><span class="line"></span><br><span class="line"><span class="keyword">elif</span> -<span class="number">1</span> &lt;= <span class="built_in">eval</span>(angle) &lt;= <span class="number">0</span>： <span class="comment">#左转向和直行</span></span><br><span class="line">    left_wheel = (<span class="number">1</span> - <span class="built_in">abs</span>(angle * kx)) * speed</span><br><span class="line">    <span class="comment"># abs() 函数返回数字的绝对值</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;right_wheel:&#123;&#125;;left_wheel:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(right_wheel,left_wheel))</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入的转角信息不是归一化数据&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="python基本语法元素"><a href="#python基本语法元素" class="headerlink" title="python基本语法元素"></a>python基本语法元素</h2><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>‘#’:单行注释<br>‘’’开头’’’结尾:多行注释</p><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>大小写敏感  首字符不可为数字</p><h3 id="赋值语句"><a href="#赋值语句" class="headerlink" title="赋值语句"></a>赋值语句</h3><p>x, y &#x3D; y, x</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span></span><br><span class="line">y = <span class="number">2</span></span><br><span class="line">x, y = y, x</span><br><span class="line"><span class="built_in">print</span>(x, y)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">2 </span><span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="基本输入输出函数"><a href="#基本输入输出函数" class="headerlink" title="基本输入输出函数"></a>基本输入输出函数</h3><p>&lt;变量&gt; &#x3D; input(&lt;提示性文字&gt;)<br>获取到的变量是字符串形式(不输入按回车是空字符串)<br>可以转换：float(a)</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.54xiafsp9p.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.54xiafsp9p.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p><strong>end参数</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=<span class="number">54</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a,end=<span class="string">&quot;.&quot;</span>)</span><br><span class="line"><span class="number">54.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a,end=<span class="string">&quot;%&quot;</span>)</span><br><span class="line"><span class="number">54</span>%</span><br></pre></td></tr></table></figure><h3 id="eval"><a href="#eval" class="headerlink" title="eval()"></a>eval()</h3><p>去掉字符串最外层的引号：<br>eval(‘1+2’) &#x3D; 3<br>eval(‘“1+2”‘) &#x3D; “1+2”<br>eval(‘print(“Hello”)’) &#x3D; print(“Hello”) #输出Hello</p><h3 id="功能库引用"><a href="#功能库引用" class="headerlink" title="功能库引用"></a>功能库引用</h3><ol><li><p>import&lt;库名&gt;<br> 使用：&lt;库名&gt;.&lt;函数名&gt;(&lt;函数参数&gt;)</p></li><li><ul><li>from&lt;库名&gt;import&lt;函数名，函数名，…&gt;</li><li>from&lt;库名&gt;import*  #*是通配符，表示所有函数<br> 使用：&lt;函数名&gt;(&lt;函数参数&gt;)</li></ul></li></ol><h2 id="python基本数据类型"><a href="#python基本数据类型" class="headerlink" title="python基本数据类型"></a>python基本数据类型</h2><h3 id="数字类型"><a href="#数字类型" class="headerlink" title="数字类型"></a>数字类型</h3><ol><li><p>整数类型<br>没有取值范围限制</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8hg84tnby2.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8hg84tnby2.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li><li><p>浮点数类型</p><ul><li><p>小数点一般形式<br> 123.456</p></li><li><p>科学计数法表示<br> 1.23456e2</p></li></ul> <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4g48qfnog8.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4g48qfnog8.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li><li><p>复数类型</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8ad09e8xe1.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8ad09e8xe1.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.39kxhu48yc.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.39kxhu48yc.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="数值运算操作符"><a href="#数值运算操作符" class="headerlink" title="数值运算操作符"></a>数值运算操作符</h3><ol><li>x&#x2F;y &#x3D; 0.3333333</li><li>x&#x2F;&#x2F;y x与y之整数商</li><li>x%y  x与y之商的余数</li><li>x**y x的y次幂</li></ol><h3 id="混合运算规则"><a href="#混合运算规则" class="headerlink" title="混合运算规则"></a>混合运算规则</h3><p>数字类型之间相互运算所生成的结果是“更宽”的类型，基本规则是：<br>◆整数之间运算，如果数学意义上的结果是小数结果是浮点数；<br>◆整数之间运算，如果数学意义上的结果是整数结果是整数；<br>◆整数和浮点数混合运算，输出结果是浮点数;<br>◆整数和浮点数混合运算，输出结果是浮点数;</p><h3 id="python内置数值运算函数"><a href="#python内置数值运算函数" class="headerlink" title="python内置数值运算函数"></a>python内置数值运算函数</h3><ul><li>abs()<br>  绝对值</li><li>divmod(x,y)<br>  (x&#x2F;&#x2F;y,x%y) 输出为二元组形式(也称为元组类型)<br>  divmod(10, 3) &#x3D; 3, 1</li><li>pow(x,y[,z])<br>  幂余：(x**y)%z,[…]表示该参数可以省略</li><li>round(x[,ndigits])<br>  对x四舍五入，保留ndigits位小数<br>  round(x)返回四舍五入后的整数值</li><li>max(x₁,x₂,….xₙ)<br>  n没有限定</li><li>min(x₁,x₂,….xₙ)<br>  n没有限定</li></ul><h3 id="数字类型的判断"><a href="#数字类型的判断" class="headerlink" title="数字类型的判断"></a>数字类型的判断</h3><p><strong>type(x)</strong><br>返回x的类型</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Python <span class="number">3.12</span><span class="number">.1</span> (tags/v3<span class="number">.12</span><span class="number">.1</span>:2305ca5, Dec  <span class="number">7</span> <span class="number">2023</span>, <span class="number">22</span>:03:<span class="number">25</span>) [MSC v<span class="number">.1937</span> <span class="number">64</span> bit (AMD64)] on win32</span><br><span class="line"><span class="type">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=<span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;int&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=<span class="number">0.1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;float&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x=<span class="number">1</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="built_in">type</span>() takes <span class="number">1</span> <span class="keyword">or</span> <span class="number">3</span> arguments</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=<span class="string">&#x27;a&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;str&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x=a</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">NameError: name <span class="string">&#x27;a&#x27;</span> <span class="keyword">is</span> <span class="keyword">not</span> defined</span><br></pre></td></tr></table></figure><h3 id="math库"><a href="#math库" class="headerlink" title="math库"></a>math库</h3><ul><li>不支持复数类型</li><li>一共提供了4个数学常数和44个函数<ul><li>四个数学常数  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7egitz8onh.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7egitz8onh.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li><li>44个函数共分为四类：<ol><li>16个数值表示函数</li><li>8个幂对数函数</li><li>16个三角对数函数</li><li>4个高等特殊函数  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.5xads8ai47.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.5xads8ai47.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.wib0o7nkk.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.wib0o7nkk.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4xuaf2dena.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4xuaf2dena.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div>  <div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4jnuo75s7e.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4jnuo75s7e.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div></li></ol></li></ul></li></ul><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4ckmsrqxrn.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4ckmsrqxrn.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="字符串的定位"><a href="#字符串的定位" class="headerlink" title="字符串的定位"></a>字符串的定位</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.231m9a8aoo.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.231m9a8aoo.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="字符串的切片"><a href="#字符串的切片" class="headerlink" title="字符串的切片"></a>字符串的切片</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.101wyefd6w.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.101wyefd6w.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="转义符"><a href="#转义符" class="headerlink" title="转义符"></a>转义符</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.lvh7j96v8.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.lvh7j96v8.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.26l870bw9g.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.26l870bw9g.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="字符串处理函数"><a href="#字符串处理函数" class="headerlink" title="字符串处理函数"></a>字符串处理函数</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4jnuo7sgoa.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4jnuo7sgoa.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="Unicode"><a href="#Unicode" class="headerlink" title="Unicode"></a>Unicode</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.9dcpkceonf.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.9dcpkceonf.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="字符的遍历"><a href="#字符的遍历" class="headerlink" title="字符的遍历"></a>字符的遍历</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.101wyez3tw.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.101wyez3tw.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h4 id="字符串处理方法"><a href="#字符串处理方法" class="headerlink" title="字符串处理方法"></a>字符串处理方法</h4><p>字符串变量自带的一些方法(即函数)</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.9rj5b7wvg3.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.9rj5b7wvg3.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7w6kilsc7t.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7w6kilsc7t.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;10,20,30&quot;</span>.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">[<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;* 12.3* &quot;</span>.strip(<span class="string">&quot;* &quot;</span>)</span><br><span class="line"><span class="string">&#x27;12.3&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;* 12*3* &quot;</span>.strip(<span class="string">&quot;* &quot;</span>)</span><br><span class="line"><span class="string">&#x27;12*3&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="字符串类型格式化控制"><a href="#字符串类型格式化控制" class="headerlink" title="字符串类型格式化控制"></a>字符串类型格式化控制</h3><p><strong>format()方法的格式控制</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.7ljqpgljeu.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.7ljqpgljeu.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4n7glygggs.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4n7glygggs.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.lvh7kdb3m.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.lvh7kdb3m.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.8dwm7796st.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.8dwm7796st.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h3 id="time库"><a href="#time库" class="headerlink" title="time库"></a>time库</h3><h4 id="时间获取"><a href="#时间获取" class="headerlink" title="时间获取"></a>时间获取</h4><ol><li><p><strong>time()</strong>:</p><ul><li>函数描述：返回当前时间的时间戳（以自1970年1月1日零时起的秒数浮点数形式）。</li><li>示例：<code>import time time.time()</code></li></ul></li><li><p><strong>ctime()</strong>:</p><ul><li>函数描述：将给定时间戳转换为字符串格式的可读时间。</li><li>示例：<code>import time time.ctime(time.time())</code></li></ul></li><li><p><strong>gmtime()</strong>:</p><ul><li>函数描述：将给定时间戳转换为UTC时区的时间元组。</li><li>示例：<code>import time time.gmtime(time.time())</code></li></ul></li></ol><h4 id="时间格式化"><a href="#时间格式化" class="headerlink" title="时间格式化"></a>时间格式化</h4><ol><li><p><strong>strftime()</strong>:</p><ul><li>函数描述：将时间元组格式化为指定格式的字符串。</li><li>示例：<code>import time time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())</code></li></ul></li><li><p><strong>strptime()</strong>:</p><ul><li>函数描述：将字符串解析为时间元组。</li><li>示例：<code>import time time.strptime(&quot;2024-03-09 19:36:30&quot;, &quot;%Y-%m-%d %H:%M:%S&quot;)</code></li></ul></li></ol><h4 id="程序计时"><a href="#程序计时" class="headerlink" title="程序计时"></a>程序计时</h4><ol><li><p><strong>sleep()</strong>:</p><ul><li>函数描述：暂停程序执行指定的秒数，可以用于模拟延迟、定时任务等。</li><li>示例：<code>import time time.sleep(5)</code></li></ul></li><li><p><strong>perf_counter()</strong>:</p><ul><li>函数描述：返回一个性能计数器的值，可用于测量瞬时时间。</li><li>示例：<code>import time start_time = time.perf_counter() # 执行代码 end_time = time.perf_counter() elapsed_time = end_time - start_time</code></li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;程序基本设计方法&quot;&gt;&lt;a href=&quot;#程序基本设计方法&quot; class=&quot;headerlink&quot; title=&quot;程序基本设计方法&quot;&gt;&lt;/a&gt;程序基本设计方法&lt;/h2&gt;&lt;h3 id=&quot;RELU激活函数&quot;&gt;&lt;a href=&quot;#RELU激活函数&quot; class=&quot;head</summary>
      
    
    
    
    <category term="智能车" scheme="http://tumytime.github.io/categories/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="智能车" scheme="http://tumytime.github.io/tags/%E6%99%BA%E8%83%BD%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>paddle.nn.Layer</title>
    <link href="http://tumytime.github.io/2024/03/09/paddle-nn-Layer/"/>
    <id>http://tumytime.github.io/2024/03/09/paddle-nn-Layer/</id>
    <published>2024-03-09T06:57:26.000Z</published>
    <updated>2024-03-09T06:59:19.824Z</updated>
    
    <content type="html"><![CDATA[<p><strong>class paddle.nn.Layer(name_scope&#x3D;None, dtype&#x3D;’float32’)</strong></p><p><a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Layer_cn.html">https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Layer_cn.html</a></p><div class="tagLink"><a class="link-card" title="API官方文档" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Layer_cn.html"><span class="link-card-backdrop" style="background-image: url(https://tumytime.github.io/picx-images-hosting/image.1754pq86xn.webp)"></span><div class="left"><img src="https://tumytime.github.io/picx-images-hosting/image.1754pq86xn.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.1754pq86xn.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">API官方文档</p><p class="url">https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Layer_cn.html</p></div></a></div>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;class paddle.nn.Layer(name_scope&amp;#x3D;None, dtype&amp;#x3D;’float32’)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.paddlepaddle.org.cn/docume</summary>
      
    
    
    
    <category term="深度学习" scheme="http://tumytime.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="paddlepaddle" scheme="http://tumytime.github.io/tags/paddlepaddle/"/>
    
  </entry>
  
  <entry>
    <title>paddlepaddle报错解决合集</title>
    <link href="http://tumytime.github.io/2024/03/09/paddlepaddle%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%90%88%E9%9B%86/"/>
    <id>http://tumytime.github.io/2024/03/09/paddlepaddle%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E5%90%88%E9%9B%86/</id>
    <published>2024-03-09T06:57:26.000Z</published>
    <updated>2024-03-09T07:32:44.422Z</updated>
    
    <content type="html"><![CDATA[<h2 id="“The-device-should-not-be-‘gpu’-“"><a href="#“The-device-should-not-be-‘gpu’-“" class="headerlink" title="“The device should not be ‘gpu’, “"></a>“The device should not be ‘gpu’, “</h2><p>“The device should not be ‘gpu’, “<br>ValueError: The device should not be ‘gpu’, since PaddlePaddle is not compiled with CUDA<br>当前情况：环境已为GPU，paddle.utils.run.checks()显示GPU正常，代码设置无误<br>问题：<br>在终端输入pip list<br>可以看到<br>同时装了paddlepaddle和paddlepaddle-gpu<br>解决方法：<br>先pip uninstall paddlepaddle和paddlepaddle-gpu(必须两个都删掉，只删paddlepaddle是不管用的)<br>然后重新pip install paddlepaddle-gpu<br>程序运行正常；<br>能跑通的list版本：<br>实在找不到原因就把跟这个版本不一样的包uninstall再install</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br></pre></td><td class="code"><pre><span class="line">aistudio@<span class="keyword">jupyter-9311933-7542288:~$ </span>pip list</span><br><span class="line">Package                        Version</span><br><span class="line">------------------------------ ---------------</span><br><span class="line">absl-py                        <span class="number">0</span>.<span class="number">8</span>.<span class="number">1</span></span><br><span class="line">aiofiles                       <span class="number">23</span>.<span class="number">2</span>.<span class="number">1</span></span><br><span class="line">aiohttp                        <span class="number">3</span>.<span class="number">8</span>.<span class="number">6</span></span><br><span class="line">aiosignal                      <span class="number">1</span>.<span class="number">3</span>.<span class="number">1</span></span><br><span class="line">alembic                        <span class="number">1</span>.<span class="number">8</span>.<span class="number">1</span></span><br><span class="line">altair                         <span class="number">4</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">annotated-types                <span class="number">0</span>.<span class="number">5</span>.<span class="number">0</span></span><br><span class="line">anyio                          <span class="number">3</span>.<span class="number">7</span>.<span class="number">1</span></span><br><span class="line">argon2-cffi                    <span class="number">21</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line">argon2-cffi-<span class="keyword">bindings </span>          <span class="number">21</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">aspy.yaml                      <span class="number">1</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line">astor                          <span class="number">0</span>.<span class="number">8</span>.<span class="number">1</span></span><br><span class="line">astroid                        <span class="number">2</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line">async-generator                <span class="number">1</span>.<span class="number">10</span></span><br><span class="line">async-timeout                  <span class="number">4</span>.<span class="number">0</span>.<span class="number">3</span></span><br><span class="line">asynctest                      <span class="number">0</span>.<span class="number">13</span>.<span class="number">0</span></span><br><span class="line">attrs                          <span class="number">22</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">audioread                      <span class="number">2</span>.<span class="number">1</span>.<span class="number">8</span></span><br><span class="line">autopep8                       <span class="number">1</span>.<span class="number">6</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">Babel </span>                         <span class="number">2</span>.<span class="number">8</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">backcall </span>                      <span class="number">0</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">backports.zoneinfo </span>            <span class="number">0</span>.<span class="number">2</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">bce-python-sdk </span>                <span class="number">0</span>.<span class="number">8</span>.<span class="number">53</span></span><br><span class="line"><span class="keyword">beautifulsoup4 </span>                <span class="number">4</span>.<span class="number">11</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">bleach </span>                        <span class="number">5</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">blinker </span>                       <span class="number">1</span>.<span class="number">6</span>.<span class="number">3</span></span><br><span class="line"><span class="keyword">cachetools </span>                    <span class="number">4</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">certifi                        <span class="number">2019</span>.<span class="number">9</span>.<span class="number">11</span></span><br><span class="line">certipy                        <span class="number">0</span>.<span class="number">1</span>.<span class="number">3</span></span><br><span class="line">cffi                           <span class="number">1</span>.<span class="number">15</span>.<span class="number">1</span></span><br><span class="line">cfgv                           <span class="number">2</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">chardet                        <span class="number">3</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line">charset-<span class="keyword">normalizer </span>            <span class="number">3</span>.<span class="number">3</span>.<span class="number">2</span></span><br><span class="line">Click                          <span class="number">7</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">cloudpickle </span>                   <span class="number">1</span>.<span class="number">6</span>.<span class="number">0</span></span><br><span class="line">cma                            <span class="number">2</span>.<span class="number">7</span>.<span class="number">0</span></span><br><span class="line">colorama                       <span class="number">0</span>.<span class="number">4</span>.<span class="number">4</span></span><br><span class="line">colorlog                       <span class="number">4</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">cryptography                   <span class="number">38</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">cycler                         <span class="number">0</span>.<span class="number">10</span>.<span class="number">0</span></span><br><span class="line">Cython                         <span class="number">0</span>.<span class="number">29</span></span><br><span class="line">debugpy                        <span class="number">1</span>.<span class="number">6</span>.<span class="number">0</span></span><br><span class="line">decorator                      <span class="number">4</span>.<span class="number">4</span>.<span class="number">2</span></span><br><span class="line">defusedxml                     <span class="number">0</span>.<span class="number">7</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">dill </span>                          <span class="number">0</span>.<span class="number">3</span>.<span class="number">3</span></span><br><span class="line">easydict                       <span class="number">1</span>.<span class="number">9</span></span><br><span class="line">entrypoints                    <span class="number">0</span>.<span class="number">4</span></span><br><span class="line">et-xmlfile                     <span class="number">1</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">exceptiongroup                 <span class="number">1</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">fastapi                        <span class="number">0</span>.<span class="number">85</span>.<span class="number">1</span></span><br><span class="line">fastjsonschema                 <span class="number">2</span>.<span class="number">16</span>.<span class="number">1</span></span><br><span class="line">ffmpy                          <span class="number">0</span>.<span class="number">3</span>.<span class="number">1</span></span><br><span class="line">filelock                       <span class="number">3</span>.<span class="number">0</span>.<span class="number">12</span></span><br><span class="line">flake8                         <span class="number">4</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">Flask                          <span class="number">1</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">Flask-<span class="keyword">Babel </span>                   <span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">Flask-Cors                     <span class="number">3</span>.<span class="number">0</span>.<span class="number">8</span></span><br><span class="line">forbiddenfruit                 <span class="number">0</span>.<span class="number">1</span>.<span class="number">3</span></span><br><span class="line">frozenlist                     <span class="number">1</span>.<span class="number">3</span>.<span class="number">3</span></span><br><span class="line">fsspec                         <span class="number">2023</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">funcsigs                       <span class="number">1</span>.<span class="number">0</span>.<span class="number">2</span></span><br><span class="line">future                         <span class="number">0</span>.<span class="number">18</span>.<span class="number">0</span></span><br><span class="line">gast                           <span class="number">0</span>.<span class="number">3</span>.<span class="number">3</span></span><br><span class="line">gitdb                          <span class="number">4</span>.<span class="number">0</span>.<span class="number">5</span></span><br><span class="line">GitPython                      <span class="number">3</span>.<span class="number">1</span>.<span class="number">14</span></span><br><span class="line">google-auth                    <span class="number">1</span>.<span class="number">10</span>.<span class="number">0</span></span><br><span class="line">google-auth-oauthlib           <span class="number">0</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line">gradio                         <span class="number">3</span>.<span class="number">34</span>.<span class="number">0</span></span><br><span class="line">gradio_client                  <span class="number">0</span>.<span class="number">2</span>.<span class="number">6</span></span><br><span class="line">graphviz                       <span class="number">0</span>.<span class="number">13</span></span><br><span class="line">greenlet                       <span class="number">1</span>.<span class="number">1</span>.<span class="number">3</span></span><br><span class="line">grpcio                         <span class="number">1</span>.<span class="number">35</span>.<span class="number">0</span></span><br><span class="line">gunicorn                       <span class="number">20</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line">gym                            <span class="number">0</span>.<span class="number">12</span>.<span class="number">1</span></span><br><span class="line">h11                            <span class="number">0</span>.<span class="number">14</span>.<span class="number">0</span></span><br><span class="line">h5py                           <span class="number">2</span>.<span class="number">9</span>.<span class="number">0</span></span><br><span class="line">httpcore                       <span class="number">0</span>.<span class="number">17</span>.<span class="number">3</span></span><br><span class="line">httpx                          <span class="number">0</span>.<span class="number">24</span>.<span class="number">1</span></span><br><span class="line">huggingface-hub                <span class="number">0</span>.<span class="number">16</span>.<span class="number">4</span></span><br><span class="line">identify                       <span class="number">1</span>.<span class="number">4</span>.<span class="number">10</span></span><br><span class="line">idna                           <span class="number">2</span>.<span class="number">8</span></span><br><span class="line">imageio                        <span class="number">2</span>.<span class="number">6</span>.<span class="number">1</span></span><br><span class="line">imageio-ffmpeg                 <span class="number">0</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line">imgaug                         <span class="number">0</span>.<span class="number">4</span>.<span class="number">0</span></span><br><span class="line">importlib-metadata             <span class="number">4</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">importlib-resources            <span class="number">5</span>.<span class="number">9</span>.<span class="number">0</span></span><br><span class="line">ipykernel                      <span class="number">6</span>.<span class="number">9</span>.<span class="number">1</span></span><br><span class="line">ipython                        <span class="number">7</span>.<span class="number">34</span>.<span class="number">0</span></span><br><span class="line">ipython-genutils               <span class="number">0</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">ipywidgets                     <span class="number">7</span>.<span class="number">6</span>.<span class="number">5</span></span><br><span class="line">isort                          <span class="number">4</span>.<span class="number">3</span>.<span class="number">21</span></span><br><span class="line">itsdangerous                   <span class="number">1</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">jdcal </span>                         <span class="number">1</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">jedi </span>                          <span class="number">0</span>.<span class="number">17</span>.<span class="number">2</span></span><br><span class="line"><span class="keyword">jieba </span>                         <span class="number">0</span>.<span class="number">42</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">Jinja2 </span>                        <span class="number">3</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">joblib </span>                        <span class="number">0</span>.<span class="number">14</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">JPype1 </span>                        <span class="number">0</span>.<span class="number">7</span>.<span class="number">2</span></span><br><span class="line"><span class="keyword">json5 </span>                         <span class="number">0</span>.<span class="number">9</span>.<span class="number">5</span></span><br><span class="line"><span class="keyword">jsonschema </span>                    <span class="number">4</span>.<span class="number">16</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">jupyter-archive </span>               <span class="number">3</span>.<span class="number">2</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">jupyter_client </span>                <span class="number">7</span>.<span class="number">3</span>.<span class="number">5</span></span><br><span class="line"><span class="keyword">jupyter-core </span>                  <span class="number">4</span>.<span class="number">11</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">jupyter-lsp </span>                   <span class="number">1</span>.<span class="number">5</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">jupyter-server </span>                <span class="number">1</span>.<span class="number">16</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">jupyter-telemetry </span>             <span class="number">0</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">jupyterhub </span>                    <span class="number">1</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">jupyterlab </span>                    <span class="number">3</span>.<span class="number">4</span>.<span class="number">5</span></span><br><span class="line"><span class="keyword">jupyterlab-language-pack-zh-CN </span><span class="number">3</span>.<span class="number">4</span>.post1</span><br><span class="line"><span class="keyword">jupyterlab-pygments </span>           <span class="number">0</span>.<span class="number">2</span>.<span class="number">2</span></span><br><span class="line"><span class="keyword">jupyterlab-server </span>             <span class="number">2</span>.<span class="number">10</span>.<span class="number">3</span></span><br><span class="line"><span class="keyword">jupyterlab-widgets </span>            <span class="number">3</span>.<span class="number">0</span>.<span class="number">3</span></span><br><span class="line">kiwisolver                     <span class="number">1</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">lap                            <span class="number">0</span>.<span class="number">4</span>.<span class="number">0</span></span><br><span class="line">lazy-object-proxy              <span class="number">1</span>.<span class="number">4</span>.<span class="number">3</span></span><br><span class="line">librosa                        <span class="number">0</span>.<span class="number">7</span>.<span class="number">2</span></span><br><span class="line">lightgbm                       <span class="number">3</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">linkify-it-py                  <span class="number">2</span>.<span class="number">0</span>.<span class="number">2</span></span><br><span class="line"><span class="keyword">llvmlite </span>                      <span class="number">0</span>.<span class="number">31</span>.<span class="number">0</span></span><br><span class="line">lxml                           <span class="number">4</span>.<span class="number">9</span>.<span class="number">1</span></span><br><span class="line">Mako                           <span class="number">1</span>.<span class="number">2</span>.<span class="number">2</span></span><br><span class="line">Markdown                       <span class="number">3</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">markdown-it-py                 <span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">MarkupSafe                     <span class="number">2</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">matplotlib                     <span class="number">2</span>.<span class="number">2</span>.<span class="number">3</span></span><br><span class="line">matplotlib-inline              <span class="number">0</span>.<span class="number">1</span>.<span class="number">6</span></span><br><span class="line">mccabe                         <span class="number">0</span>.<span class="number">6</span>.<span class="number">1</span></span><br><span class="line">mdit-py-plugins                <span class="number">0</span>.<span class="number">3</span>.<span class="number">3</span></span><br><span class="line">mdurl                          <span class="number">0</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">mistune                        <span class="number">0</span>.<span class="number">8</span>.<span class="number">4</span></span><br><span class="line">more-itertools                 <span class="number">7</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">motmetrics                     <span class="number">1</span>.<span class="number">4</span>.<span class="number">0</span></span><br><span class="line">moviepy                        <span class="number">1</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line"><span class="keyword">multidict </span>                     <span class="number">6</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line"><span class="keyword">multiprocess </span>                  <span class="number">0</span>.<span class="number">70</span>.<span class="number">11</span>.<span class="number">1</span></span><br><span class="line">nbclassic                      <span class="number">0</span>.<span class="number">3</span>.<span class="number">1</span></span><br><span class="line">nbclient                       <span class="number">0</span>.<span class="number">5</span>.<span class="number">13</span></span><br><span class="line">nbconvert                      <span class="number">6</span>.<span class="number">4</span>.<span class="number">4</span></span><br><span class="line">nbformat                       <span class="number">5</span>.<span class="number">5</span>.<span class="number">0</span></span><br><span class="line">nest-asyncio                   <span class="number">1</span>.<span class="number">5</span>.<span class="number">5</span></span><br><span class="line">netifaces                      <span class="number">0</span>.<span class="number">10</span>.<span class="number">9</span></span><br><span class="line">networkx                       <span class="number">2</span>.<span class="number">4</span></span><br><span class="line">nltk                           <span class="number">3</span>.<span class="number">4</span>.<span class="number">5</span></span><br><span class="line">nodeenv                        <span class="number">1</span>.<span class="number">3</span>.<span class="number">4</span></span><br><span class="line">notebook                       <span class="number">5</span>.<span class="number">7</span>.<span class="number">0</span></span><br><span class="line">numba                          <span class="number">0</span>.<span class="number">48</span>.<span class="number">0</span></span><br><span class="line">numpy                          <span class="number">1</span>.<span class="number">20</span>.<span class="number">3</span></span><br><span class="line">oauthlib                       <span class="number">3</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">objgraph                       <span class="number">3</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line">opencv-python                  <span class="number">4</span>.<span class="number">1</span>.<span class="number">1</span>.<span class="number">26</span></span><br><span class="line">openpyxl                       <span class="number">3</span>.<span class="number">0</span>.<span class="number">5</span></span><br><span class="line">opt-<span class="keyword">einsum </span>                    <span class="number">3</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">orjson </span>                        <span class="number">3</span>.<span class="number">9</span>.<span class="number">7</span></span><br><span class="line">packaging                      <span class="number">21</span>.<span class="number">3</span></span><br><span class="line">paddlehub                      <span class="number">2</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line">paddlenlp                      <span class="number">2</span>.<span class="number">0</span>.<span class="number">7</span></span><br><span class="line">paddlepaddle-gpu               <span class="number">2</span>.<span class="number">5</span>.<span class="number">2</span></span><br><span class="line">pamela                         <span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">pandas                         <span class="number">1</span>.<span class="number">1</span>.<span class="number">5</span></span><br><span class="line">pandocfilters                  <span class="number">1</span>.<span class="number">5</span>.<span class="number">0</span></span><br><span class="line">parl                           <span class="number">1</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line">parso                          <span class="number">0</span>.<span class="number">7</span>.<span class="number">1</span></span><br><span class="line">pathlib                        <span class="number">1</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">pexpect                        <span class="number">4</span>.<span class="number">7</span>.<span class="number">0</span></span><br><span class="line">pickleshare                    <span class="number">0</span>.<span class="number">7</span>.<span class="number">5</span></span><br><span class="line">Pillow                         <span class="number">8</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">pip                            <span class="number">22</span>.<span class="number">1</span>.<span class="number">2</span></span><br><span class="line">pkgutil_resolve_name           <span class="number">1</span>.<span class="number">3</span>.<span class="number">10</span></span><br><span class="line">plotly                         <span class="number">5</span>.<span class="number">8</span>.<span class="number">0</span></span><br><span class="line">pluggy                         <span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">pre-commit                     <span class="number">1</span>.<span class="number">21</span>.<span class="number">0</span></span><br><span class="line">prettytable                    <span class="number">0</span>.<span class="number">7</span>.<span class="number">2</span></span><br><span class="line">proglog                        <span class="number">0</span>.<span class="number">1</span>.<span class="number">9</span></span><br><span class="line">prometheus-client              <span class="number">0</span>.<span class="number">14</span>.<span class="number">1</span></span><br><span class="line">prompt-toolkit                 <span class="number">2</span>.<span class="number">0</span>.<span class="number">10</span></span><br><span class="line">protobuf                       <span class="number">4</span>.<span class="number">24</span>.<span class="number">4</span></span><br><span class="line">psutil                         <span class="number">5</span>.<span class="number">7</span>.<span class="number">2</span></span><br><span class="line">ptyprocess                     <span class="number">0</span>.<span class="number">7</span>.<span class="number">0</span></span><br><span class="line">py4j                           <span class="number">0</span>.<span class="number">10</span>.<span class="number">9</span>.<span class="number">2</span></span><br><span class="line">pyarrow                        <span class="number">12</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">pyasn1                         <span class="number">0</span>.<span class="number">4</span>.<span class="number">8</span></span><br><span class="line">pyasn1-modules                 <span class="number">0</span>.<span class="number">2</span>.<span class="number">7</span></span><br><span class="line">pycocotools                    <span class="number">2</span>.<span class="number">0</span>.<span class="number">7</span></span><br><span class="line">pycodestyle                    <span class="number">2</span>.<span class="number">8</span>.<span class="number">0</span></span><br><span class="line">pycparser                      <span class="number">2</span>.<span class="number">21</span></span><br><span class="line">pycryptodome                   <span class="number">3</span>.<span class="number">9</span>.<span class="number">9</span></span><br><span class="line">pydantic                       <span class="number">1</span>.<span class="number">10</span>.<span class="number">13</span></span><br><span class="line">pydantic_core                  <span class="number">2</span>.<span class="number">14</span>.<span class="number">6</span></span><br><span class="line">pydeck                         <span class="number">0</span>.<span class="number">8</span>.<span class="number">1</span>b0</span><br><span class="line">pydocstyle                     <span class="number">5</span>.<span class="number">0</span>.<span class="number">2</span></span><br><span class="line">pydub                          <span class="number">0</span>.<span class="number">25</span>.<span class="number">1</span></span><br><span class="line">pyflakes                       <span class="number">2</span>.<span class="number">4</span>.<span class="number">0</span></span><br><span class="line">pyglet                         <span class="number">1</span>.<span class="number">4</span>.<span class="number">5</span></span><br><span class="line">Pygments                       <span class="number">2</span>.<span class="number">13</span>.<span class="number">0</span></span><br><span class="line">pylint                         <span class="number">2</span>.<span class="number">5</span>.<span class="number">2</span></span><br><span class="line">Pympler                        <span class="number">1</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">pynvml                         <span class="number">8</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line">pyOpenSSL                      <span class="number">22</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">pyparsing                      <span class="number">3</span>.<span class="number">0</span>.<span class="number">9</span></span><br><span class="line">pypmml                         <span class="number">0</span>.<span class="number">9</span>.<span class="number">11</span></span><br><span class="line">pyrsistent                     <span class="number">0</span>.<span class="number">18</span>.<span class="number">1</span></span><br><span class="line">python-dateutil                <span class="number">2</span>.<span class="number">8</span>.<span class="number">2</span></span><br><span class="line">python-<span class="keyword">json-logger </span>            <span class="number">2</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line">python-<span class="keyword">jsonrpc-server </span>         <span class="number">0</span>.<span class="number">3</span>.<span class="number">4</span></span><br><span class="line">python-language-server         <span class="number">0</span>.<span class="number">33</span>.<span class="number">0</span></span><br><span class="line">python-lsp-<span class="keyword">jsonrpc </span>            <span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">python-lsp-server              <span class="number">1</span>.<span class="number">5</span>.<span class="number">0</span></span><br><span class="line">python-<span class="keyword">multipart </span>              <span class="number">0</span>.<span class="number">0</span>.<span class="number">6</span></span><br><span class="line">pytz                           <span class="number">2019</span>.<span class="number">3</span></span><br><span class="line">PyWavelets                     <span class="number">1</span>.<span class="number">4</span>.<span class="number">0</span></span><br><span class="line">PyYAML                         <span class="number">5</span>.<span class="number">1</span>.<span class="number">2</span></span><br><span class="line">pyzmq                          <span class="number">23</span>.<span class="number">2</span>.<span class="number">1</span></span><br><span class="line">rarfile                        <span class="number">3</span>.<span class="number">1</span></span><br><span class="line">recordio                       <span class="number">0</span>.<span class="number">1</span>.<span class="number">7</span></span><br><span class="line">requests                       <span class="number">2</span>.<span class="number">22</span>.<span class="number">0</span></span><br><span class="line">requests-oauthlib              <span class="number">1</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line">resampy                        <span class="number">0</span>.<span class="number">2</span>.<span class="number">2</span></span><br><span class="line">rich                           <span class="number">13</span>.<span class="number">7</span>.<span class="number">0</span></span><br><span class="line">rope                           <span class="number">0</span>.<span class="number">17</span>.<span class="number">0</span></span><br><span class="line">rsa                            <span class="number">4</span>.<span class="number">0</span></span><br><span class="line">ruamel.yaml                    <span class="number">0</span>.<span class="number">17</span>.<span class="number">21</span></span><br><span class="line">ruamel.yaml.clib               <span class="number">0</span>.<span class="number">2</span>.<span class="number">6</span></span><br><span class="line"><span class="keyword">scikit-image </span>                  <span class="number">0</span>.<span class="number">19</span>.<span class="number">3</span></span><br><span class="line"><span class="keyword">scikit-learn </span>                  <span class="number">0</span>.<span class="number">24</span>.<span class="number">2</span></span><br><span class="line"><span class="keyword">scipy </span>                         <span class="number">1</span>.<span class="number">6</span>.<span class="number">3</span></span><br><span class="line">seaborn                        <span class="number">0</span>.<span class="number">10</span>.<span class="number">0</span></span><br><span class="line">semantic-version               <span class="number">2</span>.<span class="number">10</span>.<span class="number">0</span></span><br><span class="line">semver                         <span class="number">3</span>.<span class="number">0</span>.<span class="number">2</span></span><br><span class="line">Send2Trash                     <span class="number">1</span>.<span class="number">8</span>.<span class="number">0</span></span><br><span class="line">sentencepiece                  <span class="number">0</span>.<span class="number">1</span>.<span class="number">85</span></span><br><span class="line">seqeval                        <span class="number">1</span>.<span class="number">2</span>.<span class="number">2</span></span><br><span class="line">setuptools                     <span class="number">56</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">shapely </span>                       <span class="number">2</span>.<span class="number">0</span>.<span class="number">3</span></span><br><span class="line"><span class="keyword">shellcheck-py </span>                 <span class="number">0</span>.<span class="number">7</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">simplegeneric                  <span class="number">0</span>.<span class="number">8</span>.<span class="number">1</span></span><br><span class="line">six                            <span class="number">1</span>.<span class="number">16</span>.<span class="number">0</span></span><br><span class="line">sklearn                        <span class="number">0</span>.<span class="number">0</span></span><br><span class="line">smmap                          <span class="number">3</span>.<span class="number">0</span>.<span class="number">5</span></span><br><span class="line">sniffio                        <span class="number">1</span>.<span class="number">3</span>.<span class="number">0</span></span><br><span class="line">snowballstemmer                <span class="number">2</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">SoundFile                      <span class="number">0</span>.<span class="number">10</span>.<span class="number">3</span>.post1</span><br><span class="line">soupsieve                      <span class="number">2</span>.<span class="number">3</span>.<span class="number">2</span>.post1</span><br><span class="line">SQLAlchemy                     <span class="number">1</span>.<span class="number">4</span>.<span class="number">41</span></span><br><span class="line">starlette                      <span class="number">0</span>.<span class="number">20</span>.<span class="number">4</span></span><br><span class="line">streamlit                      <span class="number">1</span>.<span class="number">13</span>.<span class="number">0</span></span><br><span class="line">streamlit-image-comparison     <span class="number">0</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line">tabulate                       <span class="number">0</span>.<span class="number">8</span>.<span class="number">3</span></span><br><span class="line">tb-nightly                     <span class="number">1</span>.<span class="number">15</span>.<span class="number">0</span>a20190801</span><br><span class="line">tb-paddle                      <span class="number">0</span>.<span class="number">3</span>.<span class="number">6</span></span><br><span class="line">tenacity                       <span class="number">8</span>.<span class="number">0</span>.<span class="number">1</span></span><br><span class="line">tensorboard                    <span class="number">2</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">tensorboardX                   <span class="number">1</span>.<span class="number">8</span></span><br><span class="line">termcolor                      <span class="number">1</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">terminado                      <span class="number">0</span>.<span class="number">15</span>.<span class="number">0</span></span><br><span class="line">testpath                       <span class="number">0</span>.<span class="number">4</span>.<span class="number">2</span></span><br><span class="line">threadpoolctl                  <span class="number">2</span>.<span class="number">1</span>.<span class="number">0</span></span><br><span class="line">tifffile                       <span class="number">2021</span>.<span class="number">11</span>.<span class="number">2</span></span><br><span class="line">tinycss2                       <span class="number">1</span>.<span class="number">1</span>.<span class="number">1</span></span><br><span class="line">toml                           <span class="number">0</span>.<span class="number">10</span>.<span class="number">0</span></span><br><span class="line">toolz                          <span class="number">0</span>.<span class="number">12</span>.<span class="number">0</span></span><br><span class="line">tornado                        <span class="number">6</span>.<span class="number">2</span></span><br><span class="line">tqdm                           <span class="number">4</span>.<span class="number">66</span>.<span class="number">1</span></span><br><span class="line">traitlets                      <span class="number">5</span>.<span class="number">4</span>.<span class="number">0</span></span><br><span class="line">typed-ast                      <span class="number">1</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line">typeguard                      <span class="number">4</span>.<span class="number">1</span>.<span class="number">2</span></span><br><span class="line">typing_extensions              <span class="number">4</span>.<span class="number">7</span>.<span class="number">1</span></span><br><span class="line">tzlocal                        <span class="number">5</span>.<span class="number">1</span></span><br><span class="line">uc-micro-py                    <span class="number">1</span>.<span class="number">0</span>.<span class="number">2</span></span><br><span class="line">ujson                          <span class="number">1</span>.<span class="number">35</span></span><br><span class="line">urllib3                        <span class="number">1</span>.<span class="number">25</span>.<span class="number">6</span></span><br><span class="line">uvicorn                        <span class="number">0</span>.<span class="number">22</span>.<span class="number">0</span></span><br><span class="line">validators                     <span class="number">0</span>.<span class="number">20</span>.<span class="number">0</span></span><br><span class="line">virtualenv                     <span class="number">16</span>.<span class="number">7</span>.<span class="number">9</span></span><br><span class="line">visualdl                       <span class="number">2</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">watchdog                       <span class="number">3</span>.<span class="number">0</span>.<span class="number">0</span></span><br><span class="line">wcwidth                        <span class="number">0</span>.<span class="number">1</span>.<span class="number">7</span></span><br><span class="line">webencodings                   <span class="number">0</span>.<span class="number">5</span>.<span class="number">1</span></span><br><span class="line">websocket-client               <span class="number">1</span>.<span class="number">4</span>.<span class="number">1</span></span><br><span class="line">websockets                     <span class="number">11</span>.<span class="number">0</span>.<span class="number">3</span></span><br><span class="line">Werkzeug                       <span class="number">0</span>.<span class="number">16</span>.<span class="number">0</span></span><br><span class="line">whatthepatch                   <span class="number">1</span>.<span class="number">0</span>.<span class="number">2</span></span><br><span class="line">wheel                          <span class="number">0</span>.<span class="number">36</span>.<span class="number">2</span></span><br><span class="line">widgetsnbextension             <span class="number">3</span>.<span class="number">5</span>.<span class="number">2</span></span><br><span class="line">wrapt                          <span class="number">1</span>.<span class="number">12</span>.<span class="number">1</span></span><br><span class="line">xarray                         <span class="number">0</span>.<span class="number">16</span>.<span class="number">2</span></span><br><span class="line">xgboost                        <span class="number">1</span>.<span class="number">3</span>.<span class="number">3</span></span><br><span class="line">xlrd                           <span class="number">1</span>.<span class="number">2</span>.<span class="number">0</span></span><br><span class="line">xmltodict                      <span class="number">0</span>.<span class="number">13</span>.<span class="number">0</span></span><br><span class="line">yapf                           <span class="number">0</span>.<span class="number">26</span>.<span class="number">0</span></span><br><span class="line">yarl                           <span class="number">1</span>.<span class="number">9</span>.<span class="number">4</span></span><br><span class="line">zipp                           <span class="number">3</span>.<span class="number">8</span>.<span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="ModuleNotFoundError-No-module-named-‘paddle-profiler’"><a href="#ModuleNotFoundError-No-module-named-‘paddle-profiler’" class="headerlink" title="ModuleNotFoundError: No module named ‘paddle.profiler’"></a>ModuleNotFoundError: No module named ‘paddle.profiler’</h2><p>问题：paddlepaddle-gpu版本低，uninstall再install就ok</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;“The-device-should-not-be-‘gpu’-“&quot;&gt;&lt;a href=&quot;#“The-device-should-not-be-‘gpu’-“&quot; class=&quot;headerlink&quot; title=&quot;“The device should not be </summary>
      
    
    
    
    <category term="深度学习" scheme="http://tumytime.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="paddlepaddle" scheme="http://tumytime.github.io/tags/paddlepaddle/"/>
    
  </entry>
  
  <entry>
    <title>paddle学习笔记</title>
    <link href="http://tumytime.github.io/2024/03/08/paddle%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://tumytime.github.io/2024/03/08/paddle%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2024-03-08T11:32:04.000Z</published>
    <updated>2024-03-08T14:00:16.821Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p>特征选取，避免被不相关的特征干扰：</p><div class="tagLink"><a class="link-card" title="机器学习入门讲解：什么是特征（Feature）和特征选择(Feature Selection)?" href="https://zhuanlan.zhihu.com/p/30404850"><span class="link-card-backdrop" style="background-image: url(https://pic1.zhimg.com/70/v2-9f98ca58f649f01f9bf5739ac0ad8239_1440w.avis?source=172ae18b&biz_tag=Post)"></span><div class="left"><img src="https://pic1.zhimg.com/70/v2-9f98ca58f649f01f9bf5739ac0ad8239_1440w.avis?source=172ae18b&biz_tag=Post" class="lazyload placeholder" data-srcset="https://pic1.zhimg.com/70/v2-9f98ca58f649f01f9bf5739ac0ad8239_1440w.avis?source=172ae18b&biz_tag=Post" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">机器学习入门讲解：什么是特征（Feature）和特征选择(Feature Selection)?</p><p class="url">https://zhuanlan.zhihu.com/p/30404850</p></div></a></div><p>可以明显的看到，不同的特征，结果还是差别很大的，如果我只用选取上图准确率最高的一类特征来训练模型，80.32%测试结果将比使用全部特征作为训练数据71%好不少，这个DWT-Approx(4-14Hz) db2,k&#x3D;1 特征就相当于我们第一个例子中找正方体的‘形状’特征，即主要特征。那么针对未来的训练，我们可以尝试提取表现最好的几个特征就好了；为什么选最好的几个特征，只选最好的那一个不是更高吗</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">在特征选择时，选择几个表现最好的特征通常比只选一个最好的特征更可靠和有效。以下是一些原因：</span><br><span class="line"></span><br><span class="line"><span class="bullet">1.</span> <span class="strong">**信息丰富性**</span>：使用多个好的特征可以提供更多关于数据集的信息，有助于更好地描述数据之间的关系。这可以提高模型的泛化能力。</span><br><span class="line"></span><br><span class="line"><span class="bullet">2.</span> <span class="strong">**冗余性**</span>：有时候一个单一最好的特征可能会包含某些冗余信息，而使用多个表现良好且互补的特征可以帮助消除冗余性，提高模型的鲁棒性。</span><br><span class="line"></span><br><span class="line"><span class="bullet">3.</span> <span class="strong">**模型稳定性**</span>：过于依赖一个最好的特征可能使得模型对于噪声和异常数据更为敏感。多个好的特征可以增加模型的稳定性，降低对噪声的敏感度。</span><br><span class="line"></span><br><span class="line"><span class="bullet">4.</span> <span class="strong">**综合考量**</span>：不同的特征可能会捕捉到数据不同方面的信息，综合利用多个表现良好的特征有利于更全面地学习数据的规律，提高模型的性能。</span><br><span class="line"></span><br><span class="line">因此，一般情况下，选择数个表现良好且互补的特征比单个最好的特征更为合适。当然，具体选择多少个特征取决于实际应用场景和数据集的特点。</span><br></pre></td></tr></table></figure><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><div class="tagLink"><a class="link-card" title="机器学习入门：重要的概念---信息熵（Shannon’s Entropy Model）" href="https://zhuanlan.zhihu.com/p/30854084"><span class="link-card-backdrop" style="background-image: url(https://pic1.zhimg.com/70/v2-5e7917bb0bf5604630f732379e70c8e3_1440w.avis?source=172ae18b&biz_tag=Post)"></span><div class="left"><img src="https://pic1.zhimg.com/70/v2-5e7917bb0bf5604630f732379e70c8e3_1440w.avis?source=172ae18b&biz_tag=Post" class="lazyload placeholder" data-srcset="https://pic1.zhimg.com/70/v2-5e7917bb0bf5604630f732379e70c8e3_1440w.avis?source=172ae18b&biz_tag=Post" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">机器学习入门：重要的概念---信息熵（Shannon’s Entropy Model）</p><p class="url">https://zhuanlan.zhihu.com/p/30854084</p></div></a></div><h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><div class="tagLink"><a class="link-card" title="CNN 入门讲解：什么是卷积（Convolution）?" href="https://zhuanlan.zhihu.com/p/30994790"><span class="link-card-backdrop" style="background-image: url(https://pic1.zhimg.com/70/v2-5e7917bb0bf5604630f732379e70c8e3_1440w.avis?source=172ae18b&biz_tag=Post)"></span><div class="left"><img src="https://pic1.zhimg.com/70/v2-5e7917bb0bf5604630f732379e70c8e3_1440w.avis?source=172ae18b&biz_tag=Post" class="lazyload placeholder" data-srcset="https://pic1.zhimg.com/70/v2-5e7917bb0bf5604630f732379e70c8e3_1440w.avis?source=172ae18b&biz_tag=Post" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">CNN 入门讲解：什么是卷积（Convolution）?</p><p class="url">https://zhuanlan.zhihu.com/p/30994790</p></div></a></div><h2 id="4"><a href="#4" class="headerlink" title="4"></a>4</h2><div class="tagLink"><a class="link-card" title="CNN入门讲解：如何理解卷积神经网络的结构（Structure）？" href="https://zhuanlan.zhihu.com/p/31249821"><span class="link-card-backdrop" style="background-image: url(https://pica.zhimg.com/70/v2-7a147703c5181ff9737b41afa6ea6bce_1440w.avis?source=172ae18b&biz_tag=Post)"></span><div class="left"><img src="https://pica.zhimg.com/70/v2-7a147703c5181ff9737b41afa6ea6bce_1440w.avis?source=172ae18b&biz_tag=Post" class="lazyload placeholder" data-srcset="https://pica.zhimg.com/70/v2-7a147703c5181ff9737b41afa6ea6bce_1440w.avis?source=172ae18b&biz_tag=Post" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">CNN入门讲解：如何理解卷积神经网络的结构（Structure）？</p><p class="url">https://zhuanlan.zhihu.com/p/31249821</p></div></a></div><div class="tagLink"><a class="link-card" title="10分钟数据降维入门" href="https://zhuanlan.zhihu.com/p/237718243"><span class="link-card-backdrop" style="background-image: url(https://picx.zhimg.com/70/v2-3679db615987147578a84986d7947580_1440w.avis?source=172ae18b&biz_tag=Post)"></span><div class="left"><img src="https://picx.zhimg.com/70/v2-3679db615987147578a84986d7947580_1440w.avis?source=172ae18b&biz_tag=Post" class="lazyload placeholder" data-srcset="https://picx.zhimg.com/70/v2-3679db615987147578a84986d7947580_1440w.avis?source=172ae18b&biz_tag=Post" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">10分钟数据降维入门</p><p class="url">https://zhuanlan.zhihu.com/p/237718243</p></div></a></div><iframe src="//player.bilibili.com/player.html?aid=549558824&bvid=BV1Di4y1o7vX&cid=453635246&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>现在知道乘客每次乘坐出租车的公里数，也知道乘客每次下车的时候支付给出租车司机的总费用。但是并不知道乘车的起步价，以及每公里行驶费用是多少。希望让机器从这些数据当中学习出来计算总费用的规则。</p><p>更具体的，想要让机器学习程序通过数据学习出来下面的公式当中的参数 w 和参数 b（这是一个非常简单的示例，所以w和b都是浮点数，随着对深度学习了解的深入，你将会知道w和b通常情况下会是矩阵和向量）。这样，当下次乘车的时候，知道了行驶里程distance_travelled的时候，就可以估算出来用户的总费用total_fee了。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">total_fee</span> = w * distance_travelled + b</span><br></pre></td></tr></table></figure><p>在这个机器学习任务中，已经知道了乘客的行驶里程distance_travelled，和对应的，这些乘客的总费用total_fee。</p><p>通常情况下，在机器学习任务中，像distance_travelled这样的输入值，一般被称为x（或者特征feature），像total_fee这样的输出值，一般被称为y（或者标签label)。</p><p>可以用paddle.to_tensor把示例数据转换为paddle的Tensor数据。</p><details open><summary pointer> tensor </summary>              <div class='content'>              <p>飞桨使用张量（Tensor） 来表示神经网络中传递的数据，Tensor 可以理解为多维数组，类似于 Numpy 数组（ndarray） 的概念。与 Numpy 数组相比，Tensor 除了支持运行在 CPU 上，还支持运行在 GPU 及各种 AI 芯片上，以实现计算加速；此外，飞桨基于 Tensor，实现了深度学习所必须的反向传播功能和多种多样的组网算子，从而可更快捷地实现深度学习组网与训练等功能。两者具体异同点可参见下文 Tensor 与 Numpy 数组相互转换。</p><p>在飞桨框架中，神经网络的输入、输出数据，以及网络中的参数均采用 Tensor 数据结构，示例如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model</span>):</span><br><span class="line">    <span class="comment"># 首先定义了一个函数train(model)，该函数的作用是进行神经网络模型的训练。在函数内部，调用了模型的train()方法，将模型设置为训练模式。</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 设置了训练的轮数epochs为2</span></span><br><span class="line">    epochs = <span class="number">2</span></span><br><span class="line">    <span class="comment"># 初始化了优化器optim，使用了Adam优化器，学习率为0.001，并传入了模型的参数model.parameters()</span></span><br><span class="line">    <span class="comment"># model.parameters()返回一个包含模型所有参数的迭代器或列表，</span></span><br><span class="line">    <span class="comment"># 这些参数是需要根据训练数据进行调整的。</span></span><br><span class="line">    <span class="comment"># 在优化器中，可以将这些参数传递给优化器，使得优化器能够根据损失函数的梯度来更新这些参数，从而不断优化模型以实现更好的性能。</span></span><br><span class="line">    optim = paddle.optimizer.Adam(learning_rate=<span class="number">0.001</span>, parameters=model.parameters())</span><br><span class="line">    <span class="comment"># 模型训练的两层循环</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">            x_data = data[<span class="number">0</span>]</span><br><span class="line">            y_data = data[<span class="number">1</span>]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;x_data: &quot;</span>, x_data[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]) <span class="comment"># 打印神经网络的输入：批数据中的第一个数据的第一个元素</span></span><br><span class="line">            predicts = model(x_data)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;predicts: &quot;</span>, predicts[<span class="number">0</span>]) <span class="comment"># 打印神经网络的输出：批数据中的第一个数据的第一个元素</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;weight: &quot;</span>, model.linear1.weight[<span class="number">0</span>][<span class="number">0</span>]) <span class="comment"># 打印神经网络的权重：linear1 层的 weight 中的第一个元素</span></span><br><span class="line">            loss = F.cross_entropy(predicts, y_data)</span><br><span class="line">            acc = paddle.metric.accuracy(predicts, y_data)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optim.step()</span><br><span class="line">            optim.clear_grad()</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">model = LeNet()</span><br><span class="line">train(model)</span><br></pre></td></tr></table></figure><details ><summary pointer> model.train() </summary>              <div class='content'>              <p>在训练开始之前写上 model.trian() ，在测试时写上 model.eval()。<br>在使用PyTorch构建神经网络进行训练时，我们通常会在训练过程中的代码中添加model.train()这一句，以确保启用Batch Normalization（BN）和Dropout层的功能。</p><details ><summary pointer> 批标准化 (Batch Normalization) </summary>              <div class='content'>              <pre><code>          &lt;/div&gt;        &lt;/details&gt;</code></pre>              </div>            </details>              </div>            </details>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1&quot;&gt;&lt;a href=&quot;#1&quot; class=&quot;headerlink&quot; title=&quot;1&quot;&gt;&lt;/a&gt;1&lt;/h2&gt;&lt;p&gt;特征选取，避免被不相关的特征干扰：&lt;/p&gt;
&lt;div class=&quot;tagLink&quot;&gt;&lt;a class=&quot;link-card&quot; title=&quot;机器学</summary>
      
    
    
    
    <category term="深度学习" scheme="http://tumytime.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://tumytime.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="paddlepaddle" scheme="http://tumytime.github.io/tags/paddlepaddle/"/>
    
  </entry>
  
  <entry>
    <title>图像处理笔记</title>
    <link href="http://tumytime.github.io/2024/03/05/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/"/>
    <id>http://tumytime.github.io/2024/03/05/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/</id>
    <published>2024-03-05T09:56:46.000Z</published>
    <updated>2024-03-05T10:04:46.611Z</updated>
    
    <content type="html"><![CDATA[<div class="tagLink"><a class="link-card" title="阅读原文" href="https://blog.csdn.net/hello15617900040/article/details/127590000"><span class="link-card-backdrop" style="background-image: url(https://tumytime.github.io/picx-images-hosting/image.70a2w3jj5h.webp)"></span><div class="left"><img src="https://tumytime.github.io/picx-images-hosting/image.70a2w3jj5h.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.70a2w3jj5h.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div><div class="right"><p class="text">阅读原文</p><p class="url">https://blog.csdn.net/hello15617900040/article/details/127590000</p></div></a></div><h2 id="图像统计特征"><a href="#图像统计特征" class="headerlink" title="图像统计特征"></a>图像统计特征</h2><h3 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h3><p>用于度量图像所具有的信息量，它反映了图像中纹理的紊乱度或复杂程度。熵值越大，说明纹理越复杂；熵值越小，说明纹理越平滑。</p><h3 id="均值"><a href="#均值" class="headerlink" title="均值"></a>均值</h3><p>灰度均值是对区域内亮度的一个度量，可以用来反应图像的明暗程度。</p><h3 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h3><p>方差就是数据的分散程度（偏离均值）。</p><h3 id="对比度"><a href="#对比度" class="headerlink" title="对比度"></a>对比度</h3><p>反映了图像的清晰度和纹理沟纹深浅的程度。纹理沟纹越深，其对比度越大，视觉效果越清晰；反之，对比度小，则沟纹浅，效果模糊。</p><h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.70a2w3jj5h.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.70a2w3jj5h.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>测试图片-从均值、方差做对比</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.231m296ifg.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.231m296ifg.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.4qr2clzz71.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.4qr2clzz71.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><p>对于第一组六张图片，图片越辆均值越大，但方差不会改变（同一张图片只改变亮度）<br>对于第二组图片，对比度不做调节，只调节亮度的情况下，偏离均值的离散度会变大</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.67x7ed4tb5.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.67x7ed4tb5.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="测试图片-从对比度出发"><a href="#测试图片-从对比度出发" class="headerlink" title="测试图片-从对比度出发"></a>测试图片-从对比度出发</h2><p>对比度越大 视觉效果越清晰；纹理越深对比度越大</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.58h4173k6m.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.58h4173k6m.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.ibv2scax2.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.ibv2scax2.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><h2 id="测试图片-从熵出发"><a href="#测试图片-从熵出发" class="headerlink" title="测试图片-从熵出发"></a>测试图片-从熵出发</h2><p>熵值越大，说明纹理越复杂；熵值越小，说明纹理越平滑。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.3ye6uvmvwg.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.3ye6uvmvwg.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://tumytime.github.io/picx-images-hosting/image.6bgtc318lv.webp" class="lazyload placeholder" data-srcset="https://tumytime.github.io/picx-images-hosting/image.6bgtc318lv.webp" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"/></div></div><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">img_1</span> = cv2.imread(&#x27;office_1.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_2</span> = cv2.imread(&#x27;office_2.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_3</span> = cv2.imread(&#x27;office_3.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_4</span> = cv2.imread(&#x27;office_4.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_5</span> = cv2.imread(&#x27;office_5.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_6</span> = cv2.imread(&#x27;office_6.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_7</span> = cv2.imread(&#x27;dalishi.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_8</span> = cv2.imread(&#x27;wall.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_9</span> = cv2.imread(&#x27;muwen.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_10</span> = cv2.imread(&#x27;shuiniwen.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_11</span> = cv2.imread(&#x27;<span class="number">400</span>x400_zhi_wenli.jpg&#x27;)</span><br><span class="line"><span class="attribute">img_12</span> = cv2.imread(&#x27;<span class="number">400</span>x400_zhi_zhezhouwenli.jpg&#x27;)</span><br><span class="line"><span class="attribute">imgs</span> =<span class="meta"> [img_1,img_2,img_3,img_4,img_5,img_6]</span></span><br><span class="line"><span class="attribute">titles</span> =<span class="meta"> [&#x27;office_1.jpg&#x27;,&#x27;office_2.jpg&#x27;,&#x27;office_3.jpg&#x27;,&#x27;office_4.jpg&#x27;,&#x27;office_5.jpg&#x27;,&#x27;office_6.jpg&#x27;]</span></span><br><span class="line"><span class="attribute">for</span> m in range(<span class="number">6</span>):</span><br><span class="line">    <span class="attribute">plt</span>.subplot(<span class="number">2</span>,<span class="number">3</span>,m + <span class="number">1</span>)</span><br><span class="line">    <span class="attribute">plt</span>.imshow(imgs[m])</span><br><span class="line">    <span class="attribute">plt</span>.title(titles[m])</span><br><span class="line"><span class="attribute">def</span> rgb2gray(img):</span><br><span class="line">    <span class="attribute">h</span> = img.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="attribute">w</span> = img.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="attribute">gray</span> = np.uint8(np.zeros((h,w)))</span><br><span class="line">    <span class="attribute">for</span> i in range(h):</span><br><span class="line">        <span class="attribute">for</span> j in range(w):</span><br><span class="line">            <span class="attribute">gray</span>[i,j] = <span class="number">0</span>.<span class="number">144</span> * img[i,j,<span class="number">0</span>] + <span class="number">0</span>.<span class="number">587</span> * img[i,j,<span class="number">1</span>] + <span class="number">0</span>.<span class="number">299</span> * img[i,j,<span class="number">2</span>]  # BGR</span><br><span class="line">    <span class="attribute">return</span> gray</span><br><span class="line"><span class="attribute">def</span> average(img):</span><br><span class="line">    <span class="attribute">img1</span> = rgb2gray(img)</span><br><span class="line">    <span class="attribute">height</span>,width = img1.shape</span><br><span class="line">    <span class="attribute">size</span> = img1.size</span><br><span class="line">    <span class="attribute">ave</span> = <span class="number">0</span></span><br><span class="line">    <span class="attribute">for</span> i in range(height):</span><br><span class="line">        <span class="attribute">for</span> j in range(width):</span><br><span class="line">            <span class="attribute">ave</span> += img1[i][j] / size</span><br><span class="line">    <span class="attribute">return</span> ave</span><br><span class="line"><span class="attribute">def</span> contrast(img):</span><br><span class="line">    <span class="attribute">img1</span> = rgb2gray(img)</span><br><span class="line">    <span class="attribute">m</span>,n = img1.shape</span><br><span class="line">    <span class="comment"># 图片矩阵向外扩展一个像素</span></span><br><span class="line">    <span class="attribute">img1_ext</span>=cv2.copyMakeBorder(img1,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,cv2.BORDER_REPLICATE)  # 用边界颜色填充</span><br><span class="line">    <span class="attribute">height</span>,width = img1_ext.shape</span><br><span class="line">    <span class="attribute">b</span> = <span class="number">0</span>.<span class="number">0</span></span><br><span class="line">    <span class="attribute">for</span> i in range(<span class="number">1</span>,height - <span class="number">1</span>):</span><br><span class="line">        <span class="attribute">for</span> j in range(<span class="number">1</span>,width - <span class="number">1</span>):</span><br><span class="line">            <span class="attribute">b</span> += (int((img1_ext[i,j]) - int(img1_ext[i,j + <span class="number">1</span>])) ** <span class="number">2</span> + (</span><br><span class="line">                    <span class="attribute">int</span>(img1_ext[i,j]) - int(img1_ext[i,j - <span class="number">1</span>])) ** <span class="number">2</span> + (</span><br><span class="line">                          <span class="attribute">int</span>(img1_ext[i,j]) - int(img1_ext[i + <span class="number">1</span>,j])) ** <span class="number">2</span> + (</span><br><span class="line">                          <span class="attribute">int</span>(img1_ext[i,j]) - int(img1_ext[i - <span class="number">1</span>,j])) ** <span class="number">2</span>)</span><br><span class="line">    <span class="attribute">cg</span> = b / (<span class="number">4</span> * (m - <span class="number">2</span>) * (n - <span class="number">2</span>) + <span class="number">3</span> * (<span class="number">2</span> * (m - <span class="number">2</span>) + <span class="number">2</span> * (n - <span class="number">2</span>)) + <span class="number">2</span> * <span class="number">4</span>)  #</span><br><span class="line">    <span class="attribute">return</span> cg</span><br><span class="line"><span class="attribute">def</span> variance(img):</span><br><span class="line">    <span class="attribute">img1</span> = rgb2gray(img)</span><br><span class="line">    <span class="attribute">height</span>,width = img1.shape</span><br><span class="line">    <span class="attribute">var</span> = <span class="number">0</span></span><br><span class="line">    <span class="attribute">size</span> = img1.size</span><br><span class="line">    <span class="attribute">average</span> = <span class="number">0</span></span><br><span class="line">    <span class="attribute">for</span> i in range(height):</span><br><span class="line">        <span class="attribute">for</span> j in range(width):</span><br><span class="line">            <span class="attribute">average</span> += img1[i][j] / size</span><br><span class="line">    <span class="attribute">for</span> i in range(height):</span><br><span class="line">        <span class="attribute">for</span> j in range(width):</span><br><span class="line">            <span class="attribute">var</span> += img1[i,j] * (i - average) ** <span class="number">2</span></span><br><span class="line">    <span class="attribute">return</span> var</span><br><span class="line"><span class="attribute">def</span> Contrast_and_Brightness(alpha,bete,img):  </span><br><span class="line">    <span class="attribute">blank</span> = np.zeros(img.shape,img.dtype)</span><br><span class="line">    <span class="attribute">dst</span> = cv2.addWeighted(img,alpha,blank,<span class="number">1</span> - alpha,bete)</span><br><span class="line">    <span class="attribute">return</span> dst</span><br><span class="line"><span class="attribute">def</span> dec2bin(p):</span><br><span class="line">    <span class="attribute">floatbinstr</span> = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attribute">if</span> p == <span class="number">0</span>:</span><br><span class="line">        <span class="attribute">return</span> floatbinstr</span><br><span class="line">    <span class="attribute">for</span> kk in range(len(str(p)) - <span class="number">2</span>):</span><br><span class="line">        <span class="attribute">p</span> *= <span class="number">2</span></span><br><span class="line">        <span class="attribute">if</span> p &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="attribute">floatbinstr</span> += <span class="string">&quot;1&quot;</span></span><br><span class="line">            <span class="attribute">p</span> = p - int(p)</span><br><span class="line">        <span class="attribute">else</span>:</span><br><span class="line">            <span class="attribute">floatbinstr</span> += <span class="string">&quot;0&quot;</span></span><br><span class="line">        <span class="attribute">if</span> p == <span class="number">0</span>:</span><br><span class="line">            <span class="attribute">break</span></span><br><span class="line">        <span class="attribute">return</span> str(floatbinstr)</span><br><span class="line"><span class="attribute">def</span> total_entropy(img):</span><br><span class="line">    <span class="attribute">n</span> =<span class="meta"> []</span></span><br><span class="line">    <span class="attribute">P</span> =<span class="meta"> []</span></span><br><span class="line">    <span class="attribute">lenavg</span> =<span class="meta"> []</span></span><br><span class="line">    <span class="attribute">avg_sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="attribute">grey_lvl</span> = <span class="number">0</span></span><br><span class="line">    <span class="attribute">k</span> = <span class="number">0</span></span><br><span class="line">    <span class="attribute">res</span> = <span class="number">0</span></span><br><span class="line">    <span class="comment"># test = [[5,4,3,2,1]]</span></span><br><span class="line">    <span class="attribute">weight</span> = img.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="attribute">height</span> = img.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="attribute">total</span> = weight * height</span><br><span class="line">    <span class="attribute">for</span> i in range(<span class="number">256</span>):</span><br><span class="line">        <span class="attribute">n</span>.append(<span class="number">0</span>)</span><br><span class="line">    <span class="attribute">for</span> i in range(weight):</span><br><span class="line">        <span class="attribute">for</span> j in range(height):</span><br><span class="line">            <span class="attribute">grey_lvl</span> = img[i][j]</span><br><span class="line">            <span class="attribute">n</span>[grey_lvl] = float(n[grey_lvl] + <span class="number">1</span>)</span><br><span class="line">            <span class="attribute">k</span> = float(k + <span class="number">1</span>)</span><br><span class="line">    <span class="attribute">for</span> i in range(<span class="number">256</span>):</span><br><span class="line">        <span class="attribute">P</span>.append(<span class="number">0</span>)</span><br><span class="line">    <span class="attribute">P</span> = n</span><br><span class="line">    <span class="attribute">for</span> i in range(len(n)):</span><br><span class="line">        <span class="attribute">P</span>[i] = (n[i] / k)</span><br><span class="line">    <span class="attribute">for</span> i in range(<span class="number">256</span>):</span><br><span class="line">        <span class="attribute">lenavg</span>.append(<span class="number">0</span>)</span><br><span class="line">    <span class="attribute">lenavg</span> = P</span><br><span class="line">    <span class="attribute">for</span> i in range(len(n)):</span><br><span class="line">        <span class="attribute">if</span> P[i] == <span class="number">0</span>.<span class="number">0</span>:</span><br><span class="line">            <span class="attribute">continue</span></span><br><span class="line">        <span class="attribute">lenavg</span>[i] = lenavg[i] * len(dec2bin(lenavg[i]))</span><br><span class="line">        <span class="attribute">avg_sum</span> = lenavg[i] + avg_sum</span><br><span class="line">    <span class="attribute">for</span> i in range(len(n)):</span><br><span class="line">        <span class="attribute">if</span> (P[i] == <span class="number">0</span>):</span><br><span class="line">            <span class="attribute">res</span> = res</span><br><span class="line">        <span class="attribute">else</span>:</span><br><span class="line">            <span class="attribute">res</span> = float(res - P[i] * (math.log(P[i]) / math.log(<span class="number">2</span>.<span class="number">0</span>)))</span><br><span class="line">    <span class="attribute">return</span> res</span><br><span class="line"><span class="attribute">if</span> __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    <span class="attribute">if</span> input(keyboard.wait(&#x27;A&#x27;)):</span><br><span class="line">        <span class="attribute">for</span> i in range(<span class="number">6</span>):</span><br><span class="line">            <span class="attribute">ave_1</span> = average(imgs[i])</span><br><span class="line">            <span class="attribute">ave_1</span> = Decimal(ave_1).quantize(Decimal(<span class="string">&quot;0.000&quot;</span>))</span><br><span class="line">            <span class="attribute">print</span>(<span class="string">&quot;average_office&quot;</span> + <span class="string">&quot;_&quot;</span> + <span class="string">&quot;123456&quot;</span>[i],ave_1)</span><br><span class="line">            <span class="attribute">with</span> open(&#x27;E:\\untitled12\\image_practice\\entropy.txt&#x27;,&#x27;a&#x27;,encoding=&#x27;utf-<span class="number">8</span>&#x27;) as f:</span><br><span class="line">                <span class="attribute">f</span>.write(&#x27;&#123;:^<span class="number">30</span>&#125;\n&#x27;.format(str(ave_1)))</span><br><span class="line">                <span class="attribute">f</span>.close()</span><br><span class="line">        <span class="attribute">plt</span>.show()</span><br><span class="line">    <span class="attribute">if</span> input(keyboard.wait(&#x27;V&#x27;)):</span><br><span class="line">        <span class="attribute">for</span> i in range(<span class="number">6</span>):</span><br><span class="line">            <span class="attribute">var_1</span> = variance(img_1)</span><br><span class="line">            <span class="attribute">var_1</span> = Decimal(var_1).quantize(Decimal(<span class="string">&quot;0.000&quot;</span>))</span><br><span class="line">            <span class="attribute">print</span>(<span class="string">&quot;variance_office&quot;</span> + <span class="string">&quot;_&quot;</span> + <span class="string">&quot;123456&quot;</span>[i],var_1)</span><br><span class="line">        <span class="attribute">img_contrast</span> = Contrast_and_Brightness(<span class="number">2</span>.<span class="number">0</span>,<span class="number">0</span>,img_1)</span><br><span class="line">        <span class="attribute">var_orign</span> = variance(img_1)</span><br><span class="line">        <span class="attribute">var_con</span> = variance(img_contrast)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;原图：       &quot;</span>,var_orign)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;原图调节对比：&quot;</span>,var_con)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),plt.imshow(img_1),plt.title(&#x27;img_1&#x27;)   plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),plt.imshow(img_contrast),plt.title(&#x27;img_contrast&#x27;)</span><br><span class="line">    <span class="attribute">plt</span>.show()</span><br><span class="line">    <span class="attribute">if</span> input(keyboard.wait(&#x27;C&#x27;)):</span><br><span class="line">        <span class="attribute">con_1</span> = contrast(img_1)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>),plt.imshow(img_1),plt.title(&#x27;bangong&#x27;)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">img_GAUSS</span> = cv2.GaussianBlur(img_1,(<span class="number">9</span>,<span class="number">9</span>),<span class="number">0</span>)</span><br><span class="line">        <span class="attribute">con_2</span> = contrast(img_GAUSS)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>),plt.imshow(img_GAUSS),plt.title(&#x27;bangong_GUSS&#x27;)</span><br><span class="line">        <span class="attribute">con_3</span> = contrast(img_9)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>),plt.imshow(img_9),plt.title(&#x27;mu_wen&#x27;)</span><br><span class="line">        <span class="attribute">con_4</span> = contrast(img_10)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>),plt.imshow(img_10),plt.title(&#x27;shui_ni_wen&#x27;)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">con_1</span> = Decimal(con_1).quantize(Decimal(<span class="string">&quot;0.000&quot;</span>))</span><br><span class="line">        <span class="attribute">con_2</span> = Decimal(con_2).quantize(Decimal(<span class="string">&quot;0.000&quot;</span>))</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;contrast_office&quot;</span> + <span class="string">&quot;_oringel&quot;</span>,con_1)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;contrast_office&quot;</span> + <span class="string">&quot;_GAUSS  &quot;</span>,con_2)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">con_3</span> = Decimal(con_3).quantize(Decimal(<span class="string">&quot;0.000&quot;</span>))</span><br><span class="line">        <span class="attribute">con_4</span> = Decimal(con_4).quantize(Decimal(<span class="string">&quot;0.000&quot;</span>))</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;木纹  &quot;</span>,con_3)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;水泥纹&quot;</span>,con_4)</span><br><span class="line">    <span class="attribute">plt</span>.show()</span><br><span class="line"></span><br><span class="line">    <span class="attribute">if</span> input(keyboard.wait(&#x27;E&#x27;)):</span><br><span class="line">        <span class="attribute">img_grey</span> = cv2.imread(&#x27;dalishi.jpg&#x27;,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        <span class="attribute">img_grey1</span> = cv2.imread(&#x27;wall.jpg&#x27;,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        <span class="attribute">img_grey2</span> = cv2.imread(&#x27;muwen.jpg&#x27;,cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">img_wenli</span> = cv2.imread(&#x27;<span class="number">400</span>x400_zhi_wenli.jpg&#x27;,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        <span class="attribute">img_wenli1</span> = cv2.imread(&#x27;<span class="number">400</span>x400_zhi_zhezhouwenli.jpg&#x27;,cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">ent_dalishi</span> = total_entropy(img_grey)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>),plt.imshow(img_7)</span><br><span class="line">        <span class="attribute">ent_wall</span> = total_entropy(img_grey1)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>),plt.imshow(img_8)</span><br><span class="line">        <span class="attribute">ent_muwen</span> = total_entropy(img_grey2)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>),plt.imshow(img_9)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">ent_wenli</span> = total_entropy(img_wenli)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),plt.imshow(img_11),plt.title(&#x27;junyun_weli&#x27;)</span><br><span class="line">        <span class="attribute">ent_wenli1</span> = total_entropy(img_wenli1)</span><br><span class="line">        <span class="attribute">plt</span>.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>),plt.imshow(img_12),plt.title(&#x27;not_junrun_wen&#x27;)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;entropy_dalishi&quot;</span>,ent_dalishi)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;entropy_wall   &quot;</span>,ent_wall)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;entrop_muwen   &quot;</span>,ent_muwen)</span><br><span class="line"></span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;E_junrun_wenli:        &quot;</span>,ent_wenli)</span><br><span class="line">        <span class="attribute">print</span>(<span class="string">&quot;E_NOT_junrun_wenli1:   &quot;</span>,ent_wenli1)</span><br><span class="line">    <span class="attribute">plt</span>.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;tagLink&quot;&gt;&lt;a class=&quot;link-card&quot; title=&quot;阅读原文&quot; href=&quot;https://blog.csdn.net/hello15617900040/article/details/127590000&quot;&gt;&lt;span class=&quot;</summary>
      
    
    
    
    <category term="图像处理" scheme="http://tumytime.github.io/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    
    <category term="Python" scheme="http://tumytime.github.io/tags/Python/"/>
    
    <category term="图像处理" scheme="http://tumytime.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
</feed>
